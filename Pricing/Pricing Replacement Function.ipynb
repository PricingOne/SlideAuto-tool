{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885060c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ca86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedca4e",
   "metadata": {},
   "source": [
    "## Price Positioning  Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96109af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricepositionSummary(prs, data, numOfDuplication, dfGroup,slideby, position=0):\n",
    "    \"\"\"\n",
    "    Update PowerPoint presentation with Promo Sales per Retailer data.\n",
    "\n",
    "    Parameters:\n",
    "    prs (Presentation): PowerPoint presentation object to modify.\n",
    "    endOfWeek (dict): Dictionary containing end of week data.\n",
    "    numOfDuplicates (int): Number of slides to duplicate and update.\n",
    "    dfGroup (list): List containing dataframes grouped for each slide.\n",
    "    position (int, optional): Starting slide position in the presentation. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "    Replace the slides with new data\n",
    "    \"\"\"\n",
    "    # Define dictionaries to map chart numbers to chart order\n",
    "    ch1 = {0: 0}\n",
    "    ch2 = {0: 0, 1: 1}\n",
    "    ch3 = {0: 0, 1: 1, 2: 2}\n",
    "    ch4 = {0: 0, 1:1 , 2: 2, 3: 3}\n",
    "    # Iterate through each slide to update\n",
    "    i =0\n",
    "    updated_dfGroup = []\n",
    "\n",
    "    for group in dfGroup:\n",
    "        # If the group has more than 6 rows, split it into chunks of size 6\n",
    "        if len(group) > 5:\n",
    "            for i in range(0, len(group),4 ):\n",
    "                updated_dfGroup.append(group[i:i+4])  # Add chunks to the updated list\n",
    "        else:\n",
    "            updated_dfGroup.append(group)  # Add the group as is if it's 6 or fewer rows\n",
    "\n",
    "    numOfDuplicates = len(updated_dfGroup)\n",
    "    \n",
    "    for slide_num in range(numOfDuplicates):\n",
    "        actual_slide_index = slide_num + numOfDuplication\n",
    "        dfs = updated_dfGroup[slide_num]        \n",
    "        shapes = prs.slides[actual_slide_index].shapes\n",
    "        cat= dfs[0].split(' | ')[0]     \n",
    "        retailer_ = dfs[0].split(' | ')[1]    \n",
    "        # shapes = prs.slides[slide_num+ position].shapes\n",
    "\n",
    "        # # Find and update title shape\n",
    "        titleNumber = get_shape_number(shapes,'Brand Price & Index vs Market | Bubble Size by Value Sales | Category | National | P12M')\n",
    "        datasourcenum = get_shape_number(shapes, \"DATA SOURCE: Trade Panel/Retailer Data | Ending Sep 2022\")\n",
    "        headerNumber = get_shape_number(shapes,'Price Positioning Summary (Replace with SO WHAT)')\n",
    "        avgbox = get_shape_number(shapes,\"Avg Price / Unit\")\n",
    "\n",
    "        if titleNumber is not None:\n",
    "            shapes[datasourcenum].text = data_source\n",
    "            shapes[titleNumber].text = f'Brand Price & Index vs Market | Bubble Size by Value Sales | {slideby} | {retailer_} | P12M'\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "\n",
    "        # Create table and chart objects\n",
    "        tables, charts = createTableAndChart(shapes)\n",
    "        # Determine the appropriate chart order dictionary based on the number of charts\n",
    "        chDic = ch2 if len(charts) == 2 else ch3 if len(charts) == 3 else ch4 if len(charts) == 4 else ch1\n",
    "\n",
    "\n",
    "        for chartNum in range(min(len(charts), len(dfs))):\n",
    "            chart = charts[chDic[chartNum]].chart\n",
    "\n",
    "            chart_data = BubbleChartData()            \n",
    "            key = dfs[chartNum]\n",
    "            chart_df = data[key]\n",
    "            \n",
    "            chart_data.categories = chart_df['Av Price/Unit'].unique().tolist()\n",
    "            series = chart_data.add_series(\"Relative Price Index\")\n",
    "            series.has_data_labels = True\n",
    "            # Add data points to the bubble chart\n",
    "            for i in range(chart_df.shape[0]):\n",
    "                series.add_data_point(chart_df['Av Price/Unit'].iloc[i], chart_df['Relative Price'].iloc[i], chart_df['Value Sales'].iloc[i])\n",
    "            chart.replace_data(chart_data)\n",
    "            \n",
    "            category_axis = chart.category_axis\n",
    "            category_axis.tick_labels.number_format = '#,##0.00'  if decimals == 2 else '#,##0'\n",
    "            currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "            shapes[avgbox].text = f\"Avg Price/Unit ({currencywithoutspace})\"  # Set the axis title text\n",
    "            shapes[avgbox].text_frame.paragraphs[0].font.size = Pt(8)\n",
    "            shapes[avgbox].text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "            shapes[avgbox].text_frame.paragraphs[0].runs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set text color to white\n",
    "            shapes[avgbox].text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "            category_axis.auto_axis = True\n",
    "            min_value = chart_df['Av Price/Unit'].min()\n",
    "            max_value = chart_df['Av Price/Unit'].max()\n",
    "\n",
    "            # Set X-axis min to 80% of min_value and max to 120% of max_value\n",
    "            category_axis.minimum_scale = round(min_value * 0.8)\n",
    "            category_axis.maximum_scale =round(max_value * 1.2)\n",
    "            \n",
    "            value_axis = chart.value_axis\n",
    "            value_axis.tick_labels.number_format = '0%'\n",
    "            value_axis = chart.value_axis\n",
    "            # value_axis.auto_axis = True\n",
    "            value_axis.minimum_scale = 0\n",
    "            \n",
    "            \n",
    "            xlsx_file=BytesIO()\n",
    "            with chart_data._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "                chart_data._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "                worksheet.write(0, 4, f'{BrandOrTopB}')\n",
    "                worksheet.write_column(1, 4, chart_df[f'{BrandOrTopB}'], None)\n",
    "\n",
    "            chart._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "        \n",
    "            table = tables[0].table\n",
    "            for i, row in enumerate(table.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    if i < len(dfs):  # Ensure you're within bounds of dfs\n",
    "                        category = dfs[i].split(' | ')[0]\n",
    "                        row.cells[i].text = category\n",
    "                        i=i+1\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n",
    "                        cell.text_frame.paragraphs[0].font.size = Pt(11)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set text color to white\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e82860",
   "metadata": {},
   "source": [
    "# Pricing Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricePositioning(prs,modified_price_positioning_sorted,numOfDuplicates,position=0,slideby=\"\"):\n",
    "    \"\"\"\n",
    "    Generate slides for price positioning analysis and bubble chart visualization.\n",
    "\n",
    "    Args:\n",
    "        prs: PowerPoint presentation object.\n",
    "        modified_price_positioning_sorted: Dictionary containing sorted price positioning dataframes.\n",
    "        numOfDuplicates: Number of duplicate slides to generate.\n",
    "        position: Position index to start adding slides (default is 0).\n",
    "    \"\"\"\n",
    "\n",
    "    markets = list(modified_price_positioning_sorted.keys())\n",
    "    for slidenum in range(min(numOfDuplicates, len(markets))):\n",
    "        market = markets[slidenum]\n",
    "        df = modified_price_positioning_sorted[market].reset_index(drop=True).copy()\n",
    "        rel_price = pd.to_numeric(df['Relative Price'], errors='coerce')\n",
    "\n",
    "        df = df.fillna({c: 0 for c in df.select_dtypes(include='number').columns})\n",
    "\n",
    "        slide = prs.slides[slidenum + position]\n",
    "        shapes = slide.shapes\n",
    "\n",
    "        headerNumber = get_shape_number(shapes, \"Price Positioning Analysis (Replace with SO WHAT)\")\n",
    "        titleNumber = get_shape_number(shapes, \"Brand Price & Index vs Market | Bubble Size by Value Sales | Category | National | P12M\")\n",
    "        shapes[titleNumber-1].text = data_source\n",
    "        shapes[titleNumber].text = (\n",
    "            f'Brand Price & Index vs Market | Bubble Size by Value Sales | {market} | P12M'\n",
    "            if slideby == f'{BrandOrTopB}'\n",
    "            else f'Manufactory Price & Index vs Market | Bubble Size by Value Sales | {market} | P12M'\n",
    "        )\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "\n",
    "        chart_shape = None\n",
    "        for shape in shapes:\n",
    "            if getattr(shape, \"has_chart\", False):\n",
    "                chart_shape = shape\n",
    "                break\n",
    "        if chart_shape is None:\n",
    "            continue\n",
    "        chart = chart_shape.chart\n",
    "        chart_shape.left = Inches(0.57)\n",
    "\n",
    "        # Build the bubble chart data\n",
    "        chart_data = BubbleChartData()\n",
    "        chart_data.categories = df['Av Price/Unit'].unique().tolist()\n",
    "\n",
    "        series = chart_data.add_series(\"Relative Price Index\") \n",
    "        series.has_data_labels = True\n",
    "\n",
    "        # Add data points to the bubble chart\n",
    "        for i in range(df.shape[0]):\n",
    "            series.add_data_point(df['Av Price/Unit'].iloc[i], df['Relative Price'].iloc[i], df['Value Sales'].iloc[i])\n",
    "        chart.replace_data(chart_data)\n",
    "\n",
    "        # Update chart formatting\n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"labels\")\n",
    "            worksheet.write_column(1, 4, df[slideby], None)\n",
    "\n",
    "        chart._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "\n",
    "        category_axis = chart.category_axis\n",
    "        category_axis.tick_labels.number_format = '#,##0.00' if decimals == 2 else '#,##0'\n",
    "        currencywithoutspace = currency.strip()\n",
    "        category_axis.axis_title.text_frame.text = f\"Avg Price/Unit ({currencywithoutspace})\"\n",
    "        category_axis.axis_title.text_frame.paragraphs[0].font.size = Pt(8)\n",
    "        category_axis.axis_title.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "        category_axis.auto_axis = True\n",
    "\n",
    "        min_value = df['Av Price/Unit'].min()\n",
    "        max_value = df['Av Price/Unit'].max()\n",
    "        # Set X-axis min to 80% of min_value and max to 120% of max_value\n",
    "        category_axis.minimum_scale = round(min_value * 0.8)\n",
    "        category_axis.maximum_scale =round(max_value * 1.2)\n",
    "\n",
    "        value_axis = chart.value_axis\n",
    "        value_axis.tick_labels.number_format = '0%'\n",
    "        value_axis.minimum_scale = 0\n",
    "\n",
    "        ymin = value_axis.minimum_scale\n",
    "        ymax = value_axis.maximum_scale\n",
    "\n",
    "            \n",
    "        ymax = float(rel_price.max()+0.2) # add margin above max data point\n",
    "        value_axis.maximum_scale = ymax\n",
    "\n",
    "        # Tier constraints and bounds\n",
    "        tier_constraints = {\n",
    "            \"Low-Tier\":        lambda s: (s < 0.79),\n",
    "            \"Mid-Tier\":        lambda s: (s >= 0.8) & (s <= 1.19),\n",
    "            \"Premium\":         lambda s: (s > 1.2) & (s <= 1.79),\n",
    "            \"Super Premium\":   lambda s: (s > 1.8),\n",
    "        }\n",
    "\n",
    "        tier_bounds = {\n",
    "            \"Low-Tier\":      (ymin, 0.79),\n",
    "            \"Mid-Tier\":      (0.8, 1.19),\n",
    "            \"Premium\":       (1.2, min(1.79, ymax)),\n",
    "            \"Super Premium\": (min(1.8, ymax), ymax),\n",
    "        }\n",
    "\n",
    "        has_brands = {}\n",
    "        for tier, constraint in tier_constraints.items():\n",
    "            has_brands[tier] = constraint(rel_price.fillna(pd.NA)).fillna(False).any()\n",
    "\n",
    "        tier_shapes = {}\n",
    "        for shp in list(shapes):\n",
    "            if getattr(shp, \"has_text_frame\", False):\n",
    "                name = shp.text_frame.text.strip()\n",
    "        \n",
    "                if name in tier_constraints:\n",
    "                    keep = False\n",
    "                    if has_brands[name]:\n",
    "                        keep = True\n",
    "                    else:\n",
    "                        if name == \"Mid-Tier\":\n",
    "                            if has_brands.get(\"Low-Tier\", False) and has_brands.get(\"Premium\", False):\n",
    "                                keep = True\n",
    "                        elif name == \"Premium\":\n",
    "                            if has_brands.get(\"Mid-Tier\", False) and has_brands.get(\"Super Premium\", False):\n",
    "                                keep = True\n",
    "                    if keep:\n",
    "                        tier_shapes[name] = shp\n",
    "                    else:\n",
    "                        shp.element.getparent().remove(shp.element)\n",
    "\n",
    "        # Plot box for positioning tier rectangles\n",
    "        plot_box = None\n",
    "        for shp in slide.shapes:\n",
    "            if shp.name == \"PlotAreaBox\":\n",
    "                plot_box = shp\n",
    "                break\n",
    "\n",
    "        plot_top = plot_box.top\n",
    "        plot_height = plot_box.height\n",
    "\n",
    "        def val_to_slide_y(val):\n",
    "            # Convert axis value to slide Y coordinate\n",
    "            val = max(min(val, ymax), ymin)\n",
    "            rel_pos = (val - ymin) / (ymax - ymin) if ymax > ymin else 0\n",
    "            return plot_top + plot_height - (rel_pos * plot_height)\n",
    "\n",
    "        for name, shp in list(tier_shapes.items()):\n",
    "            low, high = tier_bounds[name]\n",
    "            low_clip = max(low, ymin)\n",
    "            high_clip = min(high, ymax)\n",
    "            if high_clip <= low_clip:\n",
    "                shp.element.getparent().remove(shp.element)\n",
    "                continue\n",
    "            top_y = val_to_slide_y(high_clip)\n",
    "            bottom_y = val_to_slide_y(low_clip)\n",
    "            shp.top = int(top_y)\n",
    "            shp.height = int(bottom_y - top_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e5c34",
   "metadata": {},
   "source": [
    "# Sector/Segment Leadership Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def leadership_table1(prs,modified_price_positioning_sorted,sharGrowthDf_sec,modified_sector_total_leadership, position=0,Inscope=\" \",slideby=\" \"):\n",
    "    \n",
    "#     slide_num = 0\n",
    "#     for key in sharGrowthDf_sec.keys():\n",
    "#         slide = prs.slides[slide_num +position]\n",
    "#         tables, charts = createTableAndChart(slide.shapes)\n",
    "\n",
    "#         shapes = slide.shapes\n",
    "#         titleNumber = get_shape_number(shapes, \"Share and Growth By Brands | By Category | National | P12M\")\n",
    "#         headerNumber = get_shape_number(shapes, \"Sector/Segment Leadership Table (Replace with SO WHAT)\")\n",
    "\n",
    "#         shapes[titleNumber-1].text = data_source # Set data source information\n",
    "#             # Set title for the slide\n",
    "#         shapes[titleNumber].text = f'Share and Growth By {slideby} | By {Inscope} | {categories[0]} | {key} | P12M'\n",
    "#         shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "#         shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "#         # shapes[headerNumber].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "#         # shapes[headerNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "#         i =1\n",
    "#         no_of_tables =len(sharGrowthDf_sec[key])\n",
    "#         for sec in sharGrowthDf_sec[key]:\n",
    "#             if i >= len(tables):\n",
    "#                 continue\n",
    "#             df = modified_price_positioning_sorted[key + ' | '+sec]\n",
    "#             df = df[df['Value Share'] >0.01].reset_index(drop=True)\n",
    "#             table1 = tables[i].table\n",
    "#             num_rows_to_remove = len(table1.rows) - df.shape[0] - 1\n",
    "#             table1 = removeRowFromTable(table1, num_rows_to_remove, rowToExclude=1)\n",
    "#             for row_number, row in enumerate(table1.rows, start=0):\n",
    "#                 for column_num, cell in enumerate(row.cells):\n",
    "#                     if row_number ==0 and column_num ==0:\n",
    "#                         # r=  round(modified_sector_total_leadership[key].loc[modified_sector_total_leadership[key][Inscope] == sec, \"WoB %\"] * 100)\n",
    "#                         wob_series = modified_sector_total_leadership[key].loc[\n",
    "#                             modified_sector_total_leadership[key][Inscope] == sec, \"WoB %\"\n",
    "#                         ].fillna(0)\n",
    "\n",
    "#                         # Ensure there is at least one value before accessing\n",
    "#                         if not wob_series.empty:\n",
    "#                             catwob = int(round(wob_series.iloc[0] * 100, 0))\n",
    "#                         else:\n",
    "#                             catwob = 0             \n",
    "#                         cell.text = f\"{sec} ({catwob}%)\"\n",
    "#                         set_cell_font(cell, 'Nexa Bold', 8)\n",
    "#                         cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "#                         cell.text_frame.paragraphs[0].font.bold = True\n",
    "#                         cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "#                     if row_number ==0 and column_num ==3:\n",
    "#                         currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "#                         cell.text = f\"Avg Price /Kg ({currencywithoutspace})\"\n",
    "#                         set_cell_font(cell, 'Nexa Bold', 8)\n",
    "#                         cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "#                         cell.text_frame.paragraphs[0].font.bold = True\n",
    "#                         cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "\n",
    "#                     if row_number >0 and column_num == 0:\n",
    "#                         cell.text = df[slideby][row_number -1]\n",
    "#                         set_cell_font(cell, 'Nexa Bold', 8)\n",
    "#                     elif row_number >0 and column_num == 1:\n",
    "#                         cell.text = str(format_number(df['Value Share'][row_number -1]*100, use_decimals=True, decimals=1))+'%'\n",
    "#                         set_cell_font(cell, 'Nexa Book', 7)\n",
    "#                     elif row_number >0 and column_num == 2:\n",
    "#                         value = float(format_number(df['Value Share DYA'][row_number -1]*100, use_decimals=True, decimals=1))\n",
    "#                         if  value > 0.2:\n",
    "#                              cell.text = str(value) +'%'\n",
    "#                              cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(0, 160, 151)\n",
    "#                         elif value < - 0.2:\n",
    "#                             cell.text = str(value) +'%'\n",
    "#                             cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(192, 0, 0)\n",
    "#                         else:\n",
    "#                             cell.text = str(value) +'%'\n",
    "#                             cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(14, 40, 65)\n",
    "                            \n",
    "#                         set_cell_font(cell, 'Nexa Book', 7)\n",
    "#                     elif row_number >0 and column_num == 3:\n",
    "#                         cell.text = str(format_number(df['Av Price/KG'][row_number -1], use_decimals=True, decimals=2))\n",
    "#                         set_cell_font(cell, 'Nexa Book', 7)\n",
    "#                     elif row_number >0 and column_num == 4:\n",
    "#                         price = df['IYA Price/KG'][row_number - 1]\n",
    "#                         if pd.isna(price):\n",
    "#                             cell.text = \"\"\n",
    "#                         else:\n",
    "#                             cell.text = str(round(df['IYA Price/KG'][row_number -1]*100))\n",
    "#                         set_cell_font(cell, 'Nexa Book', 7) \n",
    "#             i+=1\n",
    "#             for table_index in range(len(tables),no_of_tables,-1):\n",
    "#                 remove_specific_table_from_slide(slide, table_index)\n",
    "\n",
    "#         slide_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leadership_table1(prs, modified_price_positioning_sorted, sharGrowthDf_sec,\n",
    "                      modified_sector_total_leadership, position=0, Inscope=\" \", slideby=\" \"):\n",
    "    \n",
    "    keys = list(sharGrowthDf_sec.keys())\n",
    "\n",
    "    slide_num = 0  # Used to shift through slides\n",
    "    for key in keys:\n",
    "        grouped_subsegments = sharGrowthDf_sec[key]  # e.g. [['A', 'B'], ['C', 'D']]\n",
    "        for group in grouped_subsegments:\n",
    "            # Each group gets its own slide\n",
    "            slide = prs.slides[slide_num + position]\n",
    "            tables, charts = createTableAndChart(slide.shapes)\n",
    "            shapes = slide.shapes\n",
    "\n",
    "            titleNumber = get_shape_number(shapes, \"Share and Growth By Brands | By Category | National | P12M\")\n",
    "            headerNumber = get_shape_number(shapes, \"Sector/Segment Leadership Table (Replace with SO WHAT)\")\n",
    "\n",
    "            shapes[titleNumber - 1].text = data_source\n",
    "            shapes[titleNumber].text = f'Share and Growth By {slideby} | By {Inscope} | {categories[0]} | {key} | P12M'\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "\n",
    "            i = 1\n",
    "            for sec in group:\n",
    "                if i >= len(tables):\n",
    "                    continue\n",
    "\n",
    "                df_key = sec + ' | ' + key\n",
    "                if df_key not in modified_price_positioning_sorted:\n",
    "                    continue\n",
    "\n",
    "                df = modified_price_positioning_sorted[df_key]\n",
    "                df = df[df['Value Share'] > 0.01].reset_index(drop=True)\n",
    "\n",
    "                table1 = tables[i].table\n",
    "                num_rows_to_remove = len(table1.rows) - df.shape[0] - 1\n",
    "                table1 = removeRowFromTable(table1, num_rows_to_remove, rowToExclude=1)\n",
    "\n",
    "                for row_number, row in enumerate(table1.rows, start=0):\n",
    "                    for column_num, cell in enumerate(row.cells):\n",
    "                        if row_number == 0 and column_num == 0:\n",
    "                            wob_series = modified_sector_total_leadership[key].loc[\n",
    "                                modified_sector_total_leadership[key][Inscope] == sec, \"WoB %\"\n",
    "                            ].fillna(0)\n",
    "                            catwob = int(round(wob_series.iloc[0] * 100, 0)) if not wob_series.empty else 0\n",
    "                            cell.text = f\"{sec} ({catwob}%)\"\n",
    "                            set_cell_font(cell, 'Nexa Bold', 8)\n",
    "                            cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                            cell.text_frame.paragraphs[0].font.bold = True\n",
    "                            cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "\n",
    "                        elif row_number == 0 and column_num == 3:\n",
    "                            currencywithoutspace = currency.strip()\n",
    "                            cell.text = f\"Avg Price /Vol ({currencywithoutspace})\"\n",
    "                            set_cell_font(cell, 'Nexa Bold', 8)\n",
    "                            cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                            cell.text_frame.paragraphs[0].font.bold = True\n",
    "                            cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "\n",
    "                        elif row_number == 0 and column_num == 4:\n",
    "                            currencywithoutspace = currency.strip()\n",
    "                            cell.text = f\"IYA Price /Vol ({currencywithoutspace})\"\n",
    "                            set_cell_font(cell, 'Nexa Bold', 8)\n",
    "                            cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                            cell.text_frame.paragraphs[0].font.bold = True\n",
    "                            cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "\n",
    "                        elif row_number > 0:\n",
    "                            if column_num == 0:\n",
    "                                cell.text = df[slideby][row_number - 1]\n",
    "                                set_cell_font(cell, 'Nexa Bold', 8)\n",
    "                            elif column_num == 1:\n",
    "                                cell.text = str(format_number(df['Value Share'][row_number - 1] * 100, use_decimals=True, decimals=1)) + '%'\n",
    "                                set_cell_font(cell, 'Nexa Book', 7)\n",
    "                            elif column_num == 2:\n",
    "                                value = float(format_number(df['Value Share DYA'][row_number - 1] * 100, use_decimals=True, decimals=1))\n",
    "                                sign = \"+\" if value > 0 else \"\"\n",
    "                                cell.text = f\"{sign}{value}%\"\n",
    "                                if value > 0.2:\n",
    "                                    cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(0, 160, 151)\n",
    "                                elif value < -0.2:\n",
    "                                    cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(192, 0, 0)\n",
    "                                else:\n",
    "                                    cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(14, 40, 65)\n",
    "                                set_cell_font(cell, 'Nexa Book', 7)\n",
    "                            elif column_num == 3:\n",
    "                                cell.text = str(format_number(df['Av Price/KG'][row_number - 1], use_decimals=True, decimals=2))\n",
    "                                set_cell_font(cell, 'Nexa Book', 7)\n",
    "                            elif column_num == 4:\n",
    "                                price = df['IYA Price/KG'][row_number - 1]\n",
    "                                cell.text = \"\" if pd.isna(price) else str(round(price * 100))\n",
    "                                set_cell_font(cell, 'Nexa Book', 7)\n",
    "                i += 1\n",
    "\n",
    "            # Delete any extra unused tables from the slide\n",
    "            for table_index in range(len(tables), len(group), -1):\n",
    "                remove_specific_table_from_slide(slide, table_index)\n",
    "\n",
    "            slide_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86897787",
   "metadata": {},
   "source": [
    "# Sector Segment Leadership Analysis 2 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalSegmentLeadership(prs,numOfDuplicates,totalDf,brandDf,segmentInScope,position=0, parent = 'Sector', child = 'Segment',slideby=\"\"):\n",
    "    \"\"\"\n",
    "    Generate slides for total segment leadership analysis.\n",
    "\n",
    "    Args:\n",
    "        prs: PowerPoint presentation object.\n",
    "        numOfDuplicates: Number of duplicate slides to generate.\n",
    "        totalDf: DataFrame containing total segment data.\n",
    "        brandDf: Dictionary containing brand-specific segment data.\n",
    "        segmentInScope: List of segments to include in the analysis.\n",
    "        position: Position index to start adding slides (default is 0).\n",
    "    \"\"\"\n",
    "    for slidenum in range(numOfDuplicates):\n",
    "        # Extract market and total market name\n",
    "        market=list(brandDf.keys())[slidenum]\n",
    "\n",
    "        totalMarket=market.split(' | ')[1]\n",
    "        # Access shapes in the slide\n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        titleNumber = get_shape_number(shapes, \"Segments Value Sales & Avg Price Per Liter | Category vs. Brand A | National | P12M\")\n",
    "        headerNumber = get_shape_number(shapes, \"Segment Leadership Analysis (Replace with So What) \")\n",
    "        # Update text boxes in the slide\n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "\n",
    "        shapes[8].text = f\"Value Sales \\n (M {currencywithoutspace})\"\n",
    "        shapes[9].text = f\"Av. Price/Vol \\n ({currencywithoutspace})\"\n",
    "\n",
    "        # Access the text frame and iterate over all paragraphs\n",
    "        text_frame = shapes[8].text_frame\n",
    "        text1_frame = shapes[9].text_frame\n",
    "        # Iterate over all paragraphs in both text frames\n",
    "        for frame in [text_frame, text1_frame]:\n",
    "            for paragraph in frame.paragraphs:\n",
    "                # Set font properties for each paragraph\n",
    "                paragraph.font.size = Pt(8)\n",
    "                paragraph.font.bold = True\n",
    "                paragraph.font.name = 'Nexa Bold'  # Set font to 'Nexa Bold'\n",
    "                paragraph.font.color.rgb = RGBColor(87, 85, 85)  # Set color to gray\n",
    "\n",
    "                # Set text alignment based on the text frame\n",
    "                if frame is text_frame:\n",
    "                    paragraph.alignment = PP_ALIGN.RIGHT\n",
    "                else:\n",
    "                    paragraph.alignment = PP_ALIGN.LEFT\n",
    "        shapes[titleNumber-1].text = data_source\n",
    "\n",
    "        shapes[titleNumber].text = f'{child} Value Sales & Avg Price Per Vol | Category vs. '+market.split(' | ')[0]+' | '+totalMarket+' |  P12M' \n",
    "    \n",
    "        # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'     \n",
    "        tables,charts=createTableAndChart(shapes)\n",
    "        \n",
    "        totalDf[totalMarket]=totalDf[totalMarket][totalDf[totalMarket][child].isin(segmentInScope)]\n",
    "        \n",
    "        brandDf[market]=brandDf[market][brandDf[market][child].isin(segmentInScope)]\n",
    "        #if \"National\" not in market: print(brandDf[totalMarket])\n",
    "\n",
    "        rest=totalDf[totalMarket][~totalDf[totalMarket][child].isin(brandDf[market][child])]\n",
    "        rest[['Value Sales','Av Price/KG','WoB %','Gross Margin %']]=0\n",
    "        df=pd.concat([rest,brandDf[market]]).sort_values(by=[f'{parent}',f'{child}'])\n",
    "        df=df[df[child].isin(segmentInScope)]\n",
    "        df=totalDf[totalMarket].merge(df,on=[f'{parent}',f'{child}'],suffixes=('','_Brand'),how='left').sort_values(by=[f'{parent}','Value Sales',f'{child}'],ascending=[True,False,True]).reset_index(drop=True)\n",
    "        df = df.replace([np.nan, np.inf, -np.inf], 0)\n",
    "\n",
    "        dfTotal=df[[f'{parent}',f'{child}', 'Value Sales', 'Av Price/KG', 'WoB %','Gross Margin %']]\n",
    "        dfBrand=df[[f'{parent}',f'{child}', 'Value Sales_Brand', 'Av Price/KG_Brand','WoB %_Brand', 'Gross Margin %_Brand']]\n",
    "        dfBrand.columns=dfBrand.columns.str.replace('_Brand','')\n",
    "        table=tables[0].table\n",
    "        num_columns_to_remove = (len(table.columns) - dfTotal.shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "        table_width = Inches(8.49)  # Specify the desired table height\n",
    "        \n",
    "\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,dfTotal)\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    "\n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if slideby==\"Top Companies\":\n",
    "                    if j==0 and i==1:\n",
    "                        cell.text=\"Company WoB%\"\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.color.rgb = RGBColor(255, 255, 255)  # Set text color to white\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                if j!=0:\n",
    "                    if i==0:\n",
    "                        cell.text = str((round(dfTotal['WoB %'].iloc[j-1]*100,1)))+'%' if round(dfTotal['WoB %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    else:\n",
    "                        if len(dfBrand['WoB %'])<j:\n",
    "                            cell.text=''\n",
    "                        else:\n",
    "                            cell.text = str((round(dfBrand['WoB %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['WoB %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    if cell.text!='':\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n",
    "\n",
    "        table=tables[1].table\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,dfTotal)\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    "\n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if slideby==f\"{ManufOrTopC}\":\n",
    "                    if j==0 and i==0:\n",
    "                        cell.text=\"Company GM%\"\n",
    "                        # cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.color.rgb = RGBColor(255, 255, 255)  # Set text color to white\n",
    "\n",
    "                if j!=0:\n",
    "                    if i==0:\n",
    "                        cell.text = str((round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    else:\n",
    "                        if len(dfBrand['Gross Margin %'])<j:\n",
    "                            cell.text=''\n",
    "                        else:\n",
    "                            cell.text = str((round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)!=0 else ''\n",
    "\n",
    "                    if cell.text!='':\n",
    "\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n",
    "        \n",
    "        chart=charts[0].chart\n",
    "\n",
    "        catLevelOne=['Total']+[market.split(' | ')[0]]\n",
    "        secLevels=dfTotal.groupby([f'{parent}'])[f'{child}'].unique().reset_index()\n",
    "        secLevels=dict(zip(secLevels[parent],secLevels[child]))\n",
    "        catLevels=secLevels.copy()\n",
    "\n",
    "        chart_data = CategoryChartData()\n",
    "        categories = chart_data.categories\n",
    "        for level3 in catLevels.keys():\n",
    "            category_3 = categories.add_category(level3)\n",
    "            for level2 in catLevels[level3]:\n",
    "                \n",
    "                category_2=category_3.add_sub_category(level2)\n",
    "                for level1 in catLevelOne:\n",
    "                    \n",
    "                    category_2.add_sub_category(level1)\n",
    "        vs=[[df['Value Sales'][i],df['Value Sales_Brand'][i]] for i in range(len(df['Value Sales_Brand']))]\n",
    "        vs= [round(float(item)/10**6,1) for sublist in vs for item in sublist]\n",
    "\n",
    "        av=[[df['Av Price/KG'].replace(np.nan,0)[i],df['Av Price/KG_Brand'].replace(np.nan,0)[i]] for i in range(len(df['Av Price/KG_Brand']))]\n",
    "        av= [float(item) for sublist in av for item in sublist]\n",
    "\n",
    "        chart_data.add_series('Value Sales',vs) \n",
    "        chart_data.add_series('Av Price/KG',av)\n",
    "        chart.replace_data(chart_data)\n",
    "        \n",
    "        for i,series in enumerate(chart.series):\n",
    "            if series.name=='Av Price/KG':\n",
    "                for j, point in enumerate(series.points):\n",
    "                    data_label = point.data_label\n",
    "                    data_label.position=XL_LABEL_POSITION.ABOVE\n",
    "                    data_label.has_text_frame = True\n",
    "                    data_label.text_frame.text =str(round(series.values[j], decimals))\n",
    "\n",
    "        secondary_value_axis = chart.value_axis\n",
    "        if decimals == 2:\n",
    "            secondary_value_axis.tick_labels.number_format = f'#,##0.00'\n",
    "        else:\n",
    "            secondary_value_axis.tick_labels.number_format = f'#,##0'\n",
    "            \n",
    "        secondary_value_axis.auto_axis = True\n",
    "\n",
    "        for j, point in enumerate(chart.series[0].points):\n",
    "            if j>len(df['Value Sales'])-1:\n",
    "                    break\n",
    "            point.format.fill.solid()\n",
    "            if j%2==0:\n",
    "                #Gray Total\n",
    "                point.format.fill.fore_color.rgb = RGBColor(174, 171, 171)\n",
    "                \n",
    "            else:\n",
    "                # Brand Color\n",
    "                point.format.fill.fore_color.rgb = RGBColor(203, 234, 231)\n",
    "        chart.replace_data(chart_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a05e12",
   "metadata": {},
   "source": [
    "# Sector Segment Leadership Analysis 1 level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brandSegmentLeadership(prs,numOfDuplicates,totalDf,brandDf,segmentInScope,position=0, slide_by = 'Sectors', child = 'Segment'):\n",
    "    \"\"\"\n",
    "    Generate slides for brand segment leadership analysis.\n",
    "    Args:\n",
    "        prs: PowerPoint presentation object.\n",
    "        numOfDuplicates: Number of duplicate slides to generate.\n",
    "        totalDf: DataFrame containing total segment data.\n",
    "        brandDf: Dictionary containing brand-specific segment data.\n",
    "        segmentInScope: List of segments to include in the analysis.\n",
    "        position: Position index to start adding slides (default is 0).\n",
    "        slide_by: Type of segmentation for the analysis (default is 'Sectors').\n",
    "    \"\"\"\n",
    "    for slidenum in range(numOfDuplicates):\n",
    "         # Extract market and total market name\n",
    "        market=list(brandDf.keys())[slidenum]\n",
    "        totalMarket=market.split(' | ')[1]\n",
    "\n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        titleNumber = get_shape_number(shapes, \"Sectors Value Sales & Avg Price Per Liter | Category vs. Brand A | National | P12M\")\n",
    "        headerNumber = get_shape_number(shapes, \"Sectors Leadership Analysis (Replace with So What)\")\n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "\n",
    "        shapes[8].text = f\"Value Sales \\n (M {currencywithoutspace})\"\n",
    "        shapes[9].text = f\"Av. Price/Vol \\n ({currencywithoutspace})\"\n",
    "\n",
    "        # Access the text frame and iterate over all paragraphs\n",
    "        text_frame = shapes[8].text_frame\n",
    "        text1_frame = shapes[9].text_frame\n",
    "\n",
    "\n",
    "        # Iterate over all paragraphs in both text frames\n",
    "        for frame in [text_frame, text1_frame]:\n",
    "            for paragraph in frame.paragraphs:\n",
    "                # Set font properties for each paragraph\n",
    "                paragraph.font.size = Pt(8)\n",
    "                paragraph.font.bold = True\n",
    "                paragraph.font.name = 'Nexa Bold'  # Set font to 'Nexa Bold'\n",
    "                paragraph.font.color.rgb = RGBColor(87, 85, 85)  # Set color to gray\n",
    "\n",
    "                # Set text alignment based on the text frame\n",
    "                if frame is text_frame:\n",
    "                    paragraph.alignment = PP_ALIGN.RIGHT\n",
    "                else:\n",
    "                    paragraph.alignment = PP_ALIGN.LEFT\n",
    "        shapes[titleNumber-1].text = data_source\n",
    "        shapes[titleNumber].text = f'{slide_by} Value Sales & Avg Price Per Vol | Category vs. '+market.split(' | ')[0]+' | '+totalMarket+' |  P12M' \n",
    "        shapes[headerNumber].text = f\"{slide_by} Leadership Analysis\"\n",
    "        # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'         # Extract tables and charts from shapes\n",
    "        tables,charts=createTableAndChart(shapes)\n",
    "       \n",
    "        table=tables[0].table\n",
    "        rest=totalDf[totalMarket][~totalDf[totalMarket][child].isin(brandDf[market][child])]\n",
    "        rest[['Value Sales','Av Price/KG','WoB %','Gross Margin %']]=0\n",
    "        df=pd.concat([rest,brandDf[market]]).sort_values(by=[f'{child}'])\n",
    "        df = df.replace([np.nan, np.inf, -np.inf], 0)\n",
    "        # Merge total and brand-specific dataframes\n",
    "        df=totalDf[totalMarket].merge(df,on=[f'{child}'],suffixes=('','_Brand'),how='left').sort_values(by=['Value Sales'],ascending=[False]).reset_index(drop=True)\n",
    "        dfTotal=df[[f'{child}', 'Value Sales', 'Av Price/KG', 'WoB %','Gross Margin %']]\n",
    "        \n",
    "        dfBrand=df[[f'{child}', 'Value Sales_Brand', 'Av Price/KG_Brand','WoB %_Brand', 'Gross Margin %_Brand']]\n",
    "        \n",
    "        dfBrand[['Value Sales_Brand', 'Av Price/KG_Brand','WoB %_Brand', 'Gross Margin %_Brand']]=dfBrand[['Value Sales_Brand', 'Av Price/KG_Brand','WoB %_Brand', 'Gross Margin %_Brand']].replace(np.nan,0)\n",
    "        dfTotal[['Value Sales', 'Av Price/KG','WoB %', 'Gross Margin %']]=dfTotal[['Value Sales', 'Av Price/KG','WoB %', 'Gross Margin %']].replace(np.nan,0)\n",
    "        dfBrand.columns=dfBrand.columns.str.replace('_Brand','')\n",
    "        num_columns_to_remove = (len(table.columns) - dfTotal.shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "        table_width = Inches(8.51)  # Specify the desired table height\n",
    "\n",
    "\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,dfTotal)\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    "\n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if j!=0:\n",
    "                    if i==0:\n",
    "                        cell.text = str((round(dfTotal['WoB %'].iloc[j-1]*100,1)))+'%' if round(dfTotal['WoB %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    else:\n",
    "                        if len(dfBrand['WoB %'])<j:\n",
    "                            cell.text=''\n",
    "                        else:\n",
    "                            cell.text = str((round(dfBrand['WoB %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['WoB %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    if cell.text!='':\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n",
    "\n",
    "        table=tables[1].table\n",
    "        num_columns_to_remove = (len(table.columns) - dfTotal.shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,dfTotal)\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    "\n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if j!=0:\n",
    "                    if i==0:\n",
    "                        cell.text = str((round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)!=0 else ''\n",
    "                    else:\n",
    "                        if len(dfBrand['Gross Margin %'])<j:\n",
    "                            cell.text=''\n",
    "                        else:\n",
    "                            cell.text = str((round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)))+'%' if round(dfBrand['Gross Margin %'].iloc[j-1]*100,1)!=0 else ''\n",
    "\n",
    "                    if cell.text!='':\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'\n",
    "        chart=charts[0].chart\n",
    "\n",
    "        catLevelOne=['Total']+[market.split(' | ')[0]]\n",
    "        \n",
    "        \n",
    "        secLevels=dfTotal[child].unique()\n",
    "        catLevels=secLevels.copy()\n",
    "        chart_data = CategoryChartData()\n",
    "        categories = chart_data.categories\n",
    "        for level3 in catLevels:\n",
    "            category_3 = categories.add_category(level3)\n",
    "            for level2 in catLevelOne:\n",
    "                category_2=category_3.add_sub_category(level2)\n",
    "                \n",
    "        df=df.replace(np.nan,'0')\n",
    "        vs=[[df['Value Sales'][i],df['Value Sales_Brand'][i]] for i in range(len(df['Value Sales_Brand']))]\n",
    "        vs= [round(float(item)/10**6,1) for sublist in vs for item in sublist]\n",
    "        av=[[df['Av Price/KG'][i],df['Av Price/KG_Brand'][i]] for i in range(len(df['Av Price/KG_Brand']))]\n",
    "        av= [float(item) for sublist in av for item in sublist]\n",
    "        \n",
    "        chart_data.add_series('Value Sales',vs) \n",
    "        chart_data.add_series('Av Price/KG',av)\n",
    "        chart.replace_data(chart_data)\n",
    "        \n",
    "        for i,series in enumerate(chart.series):\n",
    "            if series.name=='Av Price/KG':\n",
    "                for j, point in enumerate(series.points):      \n",
    "                    data_label = point.data_label\n",
    "                    data_label.has_text_frame = True\n",
    "                    data_label.text_frame.text = str(round(series.values[j], decimals))\n",
    "                        \n",
    "                    data_label.position=XL_LABEL_POSITION.ABOVE\n",
    "        chart.secondary_value_axis = chart.value_axis\n",
    "        \n",
    "        # Now you can set properties for the secondary axis\n",
    "        secondary_value_axis = chart.secondary_value_axis\n",
    "        secondary_value_axis.tick_labels.number_format = f'#,##0.00' if decimals == 2 else f'#,##0'\n",
    "        secondary_value_axis.auto_axis = True\n",
    "\n",
    "        for j, point in enumerate(chart.series[0].points):\n",
    "            if j>len(df['Value Sales'])-1:\n",
    "                    break\n",
    "            point.format.fill.solid()\n",
    "            if j%2==0:\n",
    "                #Gray Total\n",
    "                point.format.fill.fore_color.rgb = RGBColor(174, 171, 171)\n",
    "                \n",
    "            else:\n",
    "                # Brand Color\n",
    "                point.format.fill.fore_color.rgb = RGBColor(203, 234, 231)\n",
    "\n",
    "\n",
    "        chart.replace_data(chart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587ea74",
   "metadata": {},
   "source": [
    "# Shelf price/ vol & Avg price/ vol Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ecf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shelfPrice_AvgPrice(prs,all_brands,numOfDuplicates,salesColumn,sec_seg='Sector',position=0,brandORmanuf=\"\"):\n",
    "        \"\"\"\n",
    "        Add average price/volume charts and tables to PowerPoint slides.\n",
    "\n",
    "        Args:\n",
    "        - prs (Presentation): PowerPoint presentation object.\n",
    "        - all_brands (dict): A dictionary where each key is a string indicating the market or category name, and the value is a DataFrame containing brand information.\n",
    "        - numOfDuplicates (int): Number of duplicate slides.\n",
    "        - salesColumn (str): Name of the column containing sales data.\n",
    "        - sec_seg (str, optional): The name of the column representing the sector or segment. Defaults to 'Sector'.\n",
    "        - position (int, optional): Position of the slide. Defaults to 0.\n",
    "        \"\"\"\n",
    "        for slidenum in range(numOfDuplicates):\n",
    "            # Extract market and brand from keys in all_brands dictionary\n",
    "            market=list(all_brands.keys())[slidenum].split(\" | \",1)[1]\n",
    "            brandInScope = list(all_brands.keys())[slidenum].split(\" | \")[0]\n",
    "             # Access slide shapes\n",
    "\n",
    "            shapes = prs.slides[slidenum+position].shapes\n",
    "            footerNumber = get_shape_number(shapes,\"Ix = Price Positioning vs leader brand by Sector\")\n",
    "            if brandORmanuf==f'{BrandOrTopB}':\n",
    "                shapes[footerNumber].text=f\"Ix = Price Positioning vs leader brand by {sec_seg}\" \n",
    "            else:\n",
    "                shapes[footerNumber].text=f\"Ix = Price Positioning vs leader Company by {sec_seg}\" \n",
    "\n",
    "            titleNumber = get_shape_number(shapes,\"Avg Price/Vol ($) | By Sector | Brand vs. Competition | P12M | National\")\n",
    "            currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "            if titleNumber is None :\n",
    "                titleNumber = get_shape_number(shapes,\"Shelf Price/Vol ($) | By Sector | Brand vs. Competition | P12M | National\")\n",
    "                shapes[titleNumber].text = f\"Shelf Price/Vol ({currencywithoutspace}) | By {sec_seg} | {brandInScope} vs. Competition | P12M | {market}\"\n",
    "            else:\n",
    "                shapes[titleNumber].text = f\"Avg Price/Vol ({currencywithoutspace}) | By {sec_seg} | {brandInScope} vs. Competition | P12M | {market}\"\n",
    "\n",
    "            headerNumber = get_shape_number(shapes, \"Avg Price/Vol Comparison (Replace with SO WHAT\"or\"Shelf Price/Vol Comparison (Replace with SO WHAT)\")\n",
    "            shapes[titleNumber-1].text = data_source\n",
    "            # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'            # Create table and chart objects\n",
    "            tables,charts=createTableAndChart(shapes)\n",
    "            chart=charts[0].chart\n",
    "            chart_shape = charts[0]\n",
    "            chart_shape.width = Inches(9.43)  # Set desired width\n",
    "\n",
    "            chart_data = CategoryChartData()\n",
    "            df = all_brands[list(all_brands.keys())[slidenum]]\n",
    "\n",
    "            # Filter the DataFrame to include only rows where 'Top Brands' is in client_brands\n",
    "            if brandORmanuf==f'{ManufOrTopC}':\n",
    "                    client_brand_rows = df[df[brandORmanuf].isin(client_manuf)]\n",
    "            else :\n",
    "                client_brand_rows = df[df[brandORmanuf].isin(client_brands)]\n",
    "            # print(client_brand_rows)\n",
    "            # # Create a list of 'Ix' values where 'Top Brands' matches client brands\n",
    "            ix_list = client_brand_rows[f'Ix_{salesColumn}'].tolist()\n",
    "            if  not ix_list :\n",
    "                ix_list = ['']  # Set ix_list to an empty string\n",
    "\n",
    "            # # You can now use this list for chart_data.categories or any other purpose\n",
    "            # chart_data.categories = ix_list\n",
    "            chart_data.categories =ix_list\n",
    "\n",
    "            df = all_brands[list(all_brands.keys())[slidenum]]\n",
    "            if brandORmanuf==f'{BrandOrTopB}':\n",
    "                chart_data.add_series('All brands',round(all_brands[list(all_brands.keys())[slidenum]][all_brands[list(all_brands.keys())[slidenum]][brandORmanuf]=='Total'][salesColumn].astype(float),decimals).replace({np.nan: None, 0: None}))\n",
    "            else:\n",
    "                \n",
    "                chart_data.add_series('All Companies',round(all_brands[list(all_brands.keys())[slidenum]][all_brands[list(all_brands.keys())[slidenum]][brandORmanuf]=='Total'][salesColumn].astype(float),decimals).replace({np.nan: None, 0: None}))\n",
    "\n",
    "            # Add client brand first if it exists\n",
    "            if brandInScope in df[brandORmanuf].unique():\n",
    "                chart_data.add_series(brandInScope, round(df[df[brandORmanuf] == brandInScope][salesColumn].astype(float), decimals).replace({np.nan: None, 0: None}))\n",
    "\n",
    "            # Add remaining brands excluding 'Total' and the client brand\n",
    "            for brand in df[brandORmanuf].unique():\n",
    "                if brand == 'Total' or brand == brandInScope:\n",
    "                    continue\n",
    "                chart_data.add_series(brand, round(df[df[brandORmanuf] == brand][salesColumn].astype(float), decimals).replace({np.nan: None, 0: None}))\n",
    "            \n",
    "            value_axis = chart.value_axis\n",
    "            value_axis.maximum_scale= df[salesColumn].astype(float).max()+0.5\n",
    "            value_axis.minimum_scale=  df[salesColumn].astype(float).min()- 0.5\n",
    "\n",
    "            chart.replace_data(chart_data)\n",
    "            xlsx_file=BytesIO()\n",
    "            with chart_data._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "                chart_data._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "                worksheet.write(0, 7, sec_seg)\n",
    "                worksheet.write_column(1, 7, df[sec_seg].unique(), None)\n",
    "\n",
    "            chart._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "\n",
    "            series1 = chart.series[1]\n",
    "            # x= client_brands+client_manuf\n",
    "            for j, point in enumerate(series1.points):      \n",
    "                data_label = point.data_label\n",
    "                data_label.position = -4131  # Left position for most chart types\n",
    "\n",
    "                for brand in df[brandORmanuf].unique():\n",
    "                        data_label.text_frame.text = f'{str(ix_list[j])}\\n{str(series1.values[j])}'\n",
    "               \n",
    "\n",
    "            # # Access all series in the chart\n",
    "            # all_series = chart.series\n",
    "\n",
    "            # # Create series2 which will exclude series[0]\n",
    "            # series2 = [series for i, series in enumerate(all_series) if i != 1]  \n",
    "            # for series in series2:\n",
    "            #     for j, point in enumerate(series.points):      \n",
    "            #         data_label = point.data_label\n",
    "            #         for brand in df[brandORmanuf].unique():\n",
    "            #             data_label.text_frame.text =f'{str(series.values[j])}'\n",
    "           \n",
    "\n",
    "\n",
    "            # Table #\n",
    "            table=tables[0].table\n",
    "            # Filter dataframesbin\n",
    "            dfTotal=all_brands[list(all_brands.keys())[slidenum]][all_brands[list(all_brands.keys())[slidenum]][brandORmanuf]=='Total']\n",
    "            dfTotal=dfTotal.replace({np.nan: None})\n",
    "            dfBrandInScope=all_brands[list(all_brands.keys())[slidenum]][all_brands[list(all_brands.keys())[slidenum]][brandORmanuf]==brandInScope]\n",
    "            dfBrandInScope=dfBrandInScope.replace({np.nan: None})\n",
    "            if dfBrandInScope.empty:\n",
    "                columns_to_fill = [sec_seg, 'Sort_Value']  \n",
    "                for col in columns_to_fill:\n",
    "                    if col in dfTotal.columns and col in dfBrandInScope.columns:\n",
    "                        dfBrandInScope[col] = dfTotal[col]\n",
    "                dfBrandInScope[brandORmanuf] = brandInScope\n",
    "                        \n",
    "                dfBrandInScope.fillna(0, inplace=True)\n",
    "            num_columns_to_remove = (len(table.columns) - dfTotal.shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "            table_width = Inches(9.43)  # Specify the desired table height\n",
    "            table.columns[0].width= Inches(1.1)#524500\n",
    "\n",
    "            # table=col_cell_remove(table,num_columns_to_remove,table_width,dfTotal)\n",
    "            table=col_cell_remove(table,num_columns_to_remove)\n",
    "            total_col_width = table_width - table.columns[0].width\n",
    "            num_columns = len(table.columns) - 1  # Exclude the first row\n",
    "\n",
    "            if num_columns > 0:\n",
    "                cell_width = total_col_width / num_columns\n",
    "                for col in range(1, table.columns.__len__()):\n",
    "                    table.columns[col].width = int(cell_width)\n",
    "                    \n",
    "            for i, row in enumerate(table.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    if j==0:\n",
    "                        if i ==0:\n",
    "                            cell.text =\" \"\n",
    "                        elif(i==1):\n",
    "                            cell.text=f\"{sec_seg} WoB | DYA\"\n",
    "                        elif (i == 2): \n",
    "                            if brandORmanuf==f'{ManufOrTopC}':\n",
    "                                cell.text = f\"Company {sec_seg} Share | DYA\"\n",
    "                            else: \n",
    "                                cell.text = f\"Brand {sec_seg} Share | DYA\"\n",
    "    \n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "                        cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)\n",
    "                        cell.text_frame.paragraphs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.LEFT\n",
    "                    else:\n",
    "                        if i==0:\n",
    "                            unique_values = df[sec_seg].unique()\n",
    "                            if j - 1 < len(unique_values):  # Check if the index is within bounds\n",
    "                                cell.text = str(unique_values[j - 1])\n",
    "                            else:\n",
    "                                cell.text = \"\"  # or any default value you want                            # all_brands[list(all_brands.keys())[slidenum]][sec_seg].unique()\n",
    "\n",
    "                        if i==1:\n",
    "                            t1=\"\" if dfTotal['Value Share'].iloc[j-1] is None else str((round(dfTotal['Value Share'].iloc[j-1]*100,1)))+'%' if (round(dfTotal['Value Share'].iloc[j-1]*100,1))!=0 else \" \"\n",
    "                            value2 = dfTotal['Value Share DYA'].iloc[j-1]\n",
    "                            if value2 is None:\n",
    "                                t2 = \"\"\n",
    "                            else:\n",
    "                                value2 = round(float(value2) * 100, 1)\n",
    "                                t2 = f\"+{value2}%\" if value2 > 0 else f\"{value2}%\" if value2 < 0 else \"0.0%\"\n",
    "                            # t2=\"\" if dfTotal['Value Share DYA'].iloc[j-1] is None  else str((round(dfTotal['Value Share DYA'].iloc[j-1]*100,1)))+'%' if (round(dfTotal['Value Share DYA'].iloc[j-1]*100,1))!=0 else \"0.0%\"\n",
    "                            cell.text = \" \" if f\"{t1} and {t2}\" is None else f\"{t1} | {t2}\"\n",
    "                        elif (i==2):\n",
    "                            t3=\"\" if dfBrandInScope['Value Share'].iloc[j-1] is None  else str((round(dfBrandInScope['Value Share'].astype(float).iloc[j-1]*100,1)))+'%' if (round(dfBrandInScope['Value Share'].astype(float).iloc[j-1]*100,1))!=0 else \" \"\n",
    "                            value4 = dfBrandInScope['Value Share DYA'].iloc[j-1]\n",
    "                            if value4 is None:\n",
    "                                t4 = \"\"\n",
    "                            else:\n",
    "                                value4 = round(float(value4) * 100, 1)\n",
    "                                t4 = f\"+{value4}%\" if value4 > 0 else f\"{value4}%\" if value4 < 0 else \"0.0%\"\n",
    "                            # t4=\"\" if dfBrandInScope['Value Share DYA'].iloc[j-1] is None else str((round(dfBrandInScope['Value Share DYA'].astype(float).iloc[j-1]*100,1)))+'%' if (round(dfBrandInScope['Value Share DYA'].astype(float).iloc[j-1]*100,1))!=0 else \"0.0%\"                           \n",
    "                            cell.text = \" \" if t3 == \"\" and t4 == \"\" else f\"{t3} | {t4}\"\n",
    "\n",
    "                        if cell.text!='':\n",
    "                            cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                            cell.text_frame.paragraphs[0].font.name = 'Nexa Book'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5b9e3",
   "metadata": {},
   "source": [
    "# Price Point Distribution Analysis by product P3M P12M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricePoint(prs,sectorPD,numOfDuplicates,months='P12M',sec_seg='Sector',position=0):\n",
    "     \"\"\"\n",
    "        Generate slides displaying price point distribution.\n",
    " \n",
    "        Args:\n",
    "        - prs: PowerPoint presentation object.\n",
    "        - sectorPD (dict): Dictionary containing DataFrames with price point information for each sector.\n",
    "        - brandInScope (str): Name of the brand in focus.\n",
    "        - numOfDuplicates (int): Number of duplicate slides to generate.\n",
    "        - months (str): Time period for the data.\n",
    "        - sec_seg (str): The name of the column representing the sector or segment.\n",
    "        - position (int): Position of the slide in the presentation.\n",
    "        \"\"\"\n",
    "     for slidenum in range(numOfDuplicates):\n",
    "        dfName=list(sectorPD.keys())[slidenum]\n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        titleNumber = get_shape_number(shapes, \"Price Point Distribution | Brand | Category | National | P12M\")\n",
    "        headerNumber = get_shape_number(shapes, \"Price Point Distribution Analysis by product (Replace with SO WHAT)\")\n",
    "        axistitle=get_shape_number(shapes,\"Base Price/Unit ($)\")\n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "        shapes[axistitle].text=f'Base Price/Unit ({currencywithoutspace})'\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.size = Pt(8)\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set color to black\n",
    " \n",
    "        shapes[titleNumber-1].text = data_source # Set data source information\n",
    "        # Set title for the slide\n",
    "        shapes[titleNumber].text = \"Price Point Distribution | \" + list(sectorPD.keys())[slidenum] + \" | \" + months\n",
    "        # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'    \n",
    "        tables,charts=createTableAndChart(shapes)\n",
    "        chart=charts[0].chart\n",
    "        chart_data = CategoryChartData()\n",
    "        chart_data.categories = sectorPD[dfName][prodORitem].unique()\n",
    "        # formatted_prices = sectorPD[dfName]['Base Price/Unit'].apply(lambda x: f\"{currency}{round(x, decimals):,.2f}\")\n",
    "        # chart_data.add_series('Base Price/Unit', formatted_prices)\n",
    "       \n",
    "        chart_data.add_series('Base Price/Unit', round(sectorPD[dfName]['Base Price/Unit'].astype(float),decimals))\n",
    "        chart.replace_data(chart_data)\n",
    "        chart.has_title = False\n",
    " \n",
    "        for i,series in enumerate(chart.series):\n",
    "                for j, point in enumerate(series.points):      \n",
    "                    data_label = point.data_label\n",
    "                    data_label.has_text_frame = True\n",
    "                    data_label.text_frame.text = str(round(series.values[j], decimals))\n",
    "                    data_label.position = XL_LABEL_POSITION.ABOVE  # Set the position above the point\n",
    " \n",
    "        value_axis = chart.value_axis\n",
    "        value_axis.auto_axis = True\n",
    "        value_axis.minimum_scale = None\n",
    "        value_axis.major_unit = None\n",
    "        value_axis.minor_unit = None\n",
    "        value_axis.axis_title.text_frame.text=''\n",
    "        value_axis.tick_labels.number_format = \"#,##0.00\" if decimals ==2 else \"#,##0\"\n",
    " \n",
    "        # Table #\n",
    "        table=tables[0].table\n",
    " \n",
    "        num_columns_to_remove = (len(table.columns) - sectorPD[dfName].shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "        table_width = Inches(8.89)  # Specify the desired table height\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,sectorPD[dfName])\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    " \n",
    "       \n",
    "       \n",
    "        total_col_width = table_width - table.columns[0].width\n",
    "        num_columns = len(table.columns) - 1  # Exclude the first row\n",
    " \n",
    "        if num_columns > 0:\n",
    "            cell_width = total_col_width / num_columns\n",
    "            for col in range(1, table.columns.__len__()):\n",
    "                table.columns[col].width = int(cell_width)\n",
    " \n",
    "        mergedCellDf = sectorPD[dfName][sec_seg].value_counts().reset_index()\n",
    "        mergedCellDf = mergedCellDf.rename(columns = {\"index\":f'{sec_seg}'})\n",
    "        mergedCellDf=mergedCellDf.merge(sectorPD[dfName][[sec_seg,'Sort_Value']].drop_duplicates()).sort_values(['Sort_Value'])\n",
    " \n",
    "        mergedCellDf['mergedCell']=mergedCellDf['count'].cumsum()\n",
    "        count=1\n",
    "        for mergedCell in mergedCellDf['mergedCell'].unique():\n",
    "            table.cell(0,count).merge(table.cell(0,mergedCell))\n",
    "            count=mergedCell+1\n",
    " \n",
    "        table.height = Inches(1.54)\n",
    "       \n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if j == 0:\n",
    "                    if i == 3:\n",
    "                        cell.text=f\"Base Price/Vol ({currencywithoutspace})\"\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "                    continue\n",
    "               \n",
    "                if i==0:\n",
    "                    cell.text=sectorPD[dfName][sec_seg].iloc[j-1]\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(8)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                elif (i==1):\n",
    "                    cell.text=sectorPD[dfName][f\"{prodORitem}\"].iloc[j-1]\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                elif (i==2):\n",
    "                    cell.text=sectorPD[dfName]['Total Size'].iloc[j-1]\n",
    "                elif (i==3):\n",
    "                    cell.text=str(round(sectorPD[dfName]['Base Price/KG'].astype(float).iloc[j-1],decimals))\n",
    "                       \n",
    "                elif (i==4):\n",
    "                    cell.text=str(int(round(sectorPD[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0)))+'%' if int(round(sectorPD[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0))!=0 else ''\n",
    "                if cell.text!='' and i!=0 and i!=1:\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Book'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e3d1b",
   "metadata": {},
   "source": [
    "# Price Point Comparison Analysis by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricepoint_comparison(prs, merged_dict, position,slideby=\"Top Brand\"):\n",
    "    for slidenum in range(len(merged_dict)):\n",
    "            dfName=list(merged_dict.keys())[slidenum]\n",
    "            market=list(merged_dict.keys())[slidenum].split(' | ')[2]\n",
    "            category=list(merged_dict.keys())[slidenum].split(' | ')[0]\n",
    "            # Access shapes in the slide\n",
    "            shapes = prs.slides[slidenum+position].shapes\n",
    "            titleNumber = get_shape_number(shapes, \"Price Point Distribution | Brand Vs. Competition | Category | National | P3M\")\n",
    "            headerNumber = get_shape_number(shapes, \"Price Point Comparison Analysis by Product\")\n",
    "            axistitle=get_shape_number(shapes,\"Base Price/Unit ($)\")\n",
    "            currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "            shapes[axistitle].text=f'Base Price/Unit ({currencywithoutspace})'\n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.size = Pt(8)\n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.name = 'Nexa Bold' \n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set color to black\n",
    "\n",
    "            shapes[5].text = data_source # Set data source information\n",
    "            # Set title for the slide\n",
    "            shapes[6].text = \"Price Point Distribution | \" + list(merged_dict.keys())[slidenum].split(' | ')[2] + \" Vs. Competition | \"+ list(merged_dict.keys())[slidenum].split(' | ')[0]+ ' | ' + list(merged_dict.keys())[slidenum].split(' | ')[1]+ ' | P3M'\n",
    "            # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "            shapes[6].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[6].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "\n",
    "            tables,charts=createTableAndChart(shapes)\n",
    "            chart=charts[0].chart\n",
    "            chart_data = CategoryChartData()\n",
    "            chart_data.categories = merged_dict[dfName][f'{prodORitem}'].unique()        \n",
    "            chart_data.add_series('Base Price/Unit', round(merged_dict[dfName]['Base Price/Unit'].astype(float),decimals))\n",
    "            chart.replace_data(chart_data) \n",
    "            chart.has_title = False\n",
    "                \n",
    "            for i,series in enumerate(chart.series):\n",
    "                    for j, point in enumerate(series.points):      \n",
    "                        data_label = point.data_label\n",
    "                        data_label.has_text_frame = True\n",
    "                        data_label.text_frame.text = str(round(series.values[j], decimals)) \n",
    "                            \n",
    "            value_axis = chart.value_axis\n",
    "            value_axis.auto_axis = True\n",
    "            value_axis.minimum_scale = None\n",
    "            value_axis.major_unit = None\n",
    "            value_axis.minor_unit = None\n",
    "            value_axis.axis_title.text_frame.text=''\n",
    "            value_axis.tick_labels.number_format = \"#,##0.00\" if decimals ==2 else \"#,##0\"\n",
    "\n",
    "            # Table #\n",
    "            table=tables[0].table\n",
    "            num_columns_to_remove = (len(table.columns) - merged_dict[dfName].shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "            table_width = Inches(8.89)  # Specify the desired table height\n",
    "            # table=col_cell_remove(table,num_columns_to_remove,table_width,sectorPD[dfName])\n",
    "            table=col_cell_remove(table,num_columns_to_remove)\n",
    "            \n",
    "            \n",
    "            total_col_width = table_width - table.columns[0].width\n",
    "            num_columns = len(table.columns) - 1  # Exclude the first row\n",
    "            if num_columns > 0:\n",
    "                cell_width = total_col_width / num_columns\n",
    "                for col in range(1, table.columns.__len__()):\n",
    "                    table.columns[col].width = int(cell_width)\n",
    "            if slideby==f'{BrandOrTopB}' :   \n",
    "                mergedCellDf = merged_dict[dfName][f'{BrandOrTopB}'].value_counts().reset_index()\n",
    "                #mergedCellDf = mergedCellDf.rename(columns = {\"index\":f'{sec_seg}', f'{sec_seg}':'count'})\n",
    "                #mergedCellDf=mergedCellDf.merge(merged_dict[dfName][['Top Brands','Value Share']].drop_duplicates()).sort_values(['Value Share'], ascending= False)\n",
    "\n",
    "                client_row = mergedCellDf[mergedCellDf[f'{BrandOrTopB}'].isin(client_brands)]\n",
    "                if not client_row.empty:\n",
    "                    client_row = client_row.iloc[0]\n",
    "                    mergedCellDf = mergedCellDf[~mergedCellDf[f'{BrandOrTopB}'].isin(client_brands)]\n",
    "                    mergedCellDf = pd.concat([pd.DataFrame([client_row]), mergedCellDf], ignore_index=True)\n",
    "            \n",
    "            else:        \n",
    "                mergedCellDf = merged_dict[dfName][slideby].value_counts().reset_index()\n",
    "\n",
    "                client_row = mergedCellDf[mergedCellDf[slideby].isin(client_manuf)]\n",
    "                if not client_row.empty:\n",
    "                    client_row = client_row.iloc[0]\n",
    "                    mergedCellDf = mergedCellDf[~mergedCellDf[slideby].isin(client_manuf)]\n",
    "                    mergedCellDf = pd.concat([pd.DataFrame([client_row]), mergedCellDf], ignore_index=True)\n",
    "\n",
    "            mergedCellDf['mergedCell']=mergedCellDf['count'].cumsum()\n",
    "            count=1\n",
    "            for mergedCell in mergedCellDf['mergedCell'].unique():\n",
    "                \n",
    "                table.cell(0,count).merge(table.cell(0,mergedCell))\n",
    "                count=mergedCell+1\n",
    "\n",
    "            table.height = Inches(1.54)\n",
    "            \n",
    "            for i, row in enumerate(table.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    if j == 0:\n",
    "                        if i == 3:    \n",
    "                            cell.text=f\"Base Price/Vol ({currencywithoutspace})\"\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                            cell.text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "                        continue\n",
    "                    if i==0:\n",
    "                        cell.text=merged_dict[dfName][slideby].iloc[j-1]\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(8)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                    elif (i==1):\n",
    "                        product =merged_dict[dfName][f\"{prodORitem}\"].iloc[j-1]\n",
    "                        cell.text=product\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                    elif (i==2):\n",
    "                        cell.text=merged_dict[dfName]['Total Size'].iloc[j-1]\n",
    "                    elif (i==3):\n",
    "                        cell.text=str(round(merged_dict[dfName]['Base Price/KG'].astype(float).iloc[j-1],decimals))\n",
    "                            \n",
    "                    elif (i==4):\n",
    "                        if int(round(merged_dict[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0))!=0:\n",
    "                             cell.text = str(int(round(merged_dict[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0)))+'%' \n",
    "                        else:\n",
    "                            cell.text = ''\n",
    "                    if cell.text!='' and i!=0 and i!=1:\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59251c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricepoint_comparison_scraped(prs, merged_dict, position,slideby=\"Top Brand\"):\n",
    "    for slidenum in range(len(merged_dict)):\n",
    "            dfName=list(merged_dict.keys())[slidenum]\n",
    "            market=list(merged_dict.keys())[slidenum].split(' | ')[2]\n",
    "            category=list(merged_dict.keys())[slidenum].split(' | ')[0]\n",
    "            # Access shapes in the slide\n",
    "            if (slidenum + position) >= len(prs.slides):\n",
    "                print(f\"Slide index {slidenum + position} out of range. Skipping.\")\n",
    "                continue\n",
    "            shapes = prs.slides[slidenum+position].shapes\n",
    "            titleNumber = get_shape_number(shapes, \"Price Point Distribution | Brand Vs. Competition | Category | National | P3M\")\n",
    "            headerNumber = get_shape_number(shapes, \"Price Point Comparison Analysis by Product\")\n",
    "            axistitle=get_shape_number(shapes,\"Base Price/Unit ($)\")\n",
    "            currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "            shapes[axistitle].text=f'Scraped Av. Price/Unit ({currencywithoutspace})'\n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.size = Pt(8)\n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.name = 'Nexa Bold' \n",
    "            shapes[axistitle].text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set color to black\n",
    "\n",
    "            shapes[5].text = data_source # Set data source information\n",
    "            # Set title for the slide\n",
    "            shapes[6].text = \"Price Point Distribution | \" + list(merged_dict.keys())[slidenum].split(' | ')[2] + \" Vs. Competition | \"+ list(merged_dict.keys())[slidenum].split(' | ')[0]+ ' | ' + list(merged_dict.keys())[slidenum].split(' | ')[1]+ ' | P3M'\n",
    "            # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "            shapes[6].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[6].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "\n",
    "            tables,charts=createTableAndChart(shapes)\n",
    "            chart=charts[0].chart\n",
    "            chart_data = CategoryChartData()\n",
    "            chart_data.categories = merged_dict[dfName][f'{prodORitem}'].unique()        \n",
    "            chart_data.add_series('Scraped Av. Price/Unit', round(merged_dict[dfName]['Scraped Av. Price/Unit'].astype(float),decimals))\n",
    "            chart.replace_data(chart_data) \n",
    "            chart.has_title = False\n",
    "                \n",
    "            for i,series in enumerate(chart.series):\n",
    "                    for j, point in enumerate(series.points):      \n",
    "                        data_label = point.data_label\n",
    "                        data_label.has_text_frame = True\n",
    "                        data_label.text_frame.text = str(round(series.values[j], decimals)) \n",
    "                            \n",
    "            value_axis = chart.value_axis\n",
    "            value_axis.auto_axis = True\n",
    "            value_axis.minimum_scale = None\n",
    "            value_axis.major_unit = None\n",
    "            value_axis.minor_unit = None\n",
    "            value_axis.axis_title.text_frame.text=''\n",
    "            value_axis.tick_labels.number_format = \"#,##0.00\" if decimals ==2 else \"#,##0\"\n",
    "\n",
    "            # Table #\n",
    "            table=tables[0].table\n",
    "            num_columns_to_remove = (len(table.columns) - merged_dict[dfName].shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "            table_width = Inches(8.89)  # Specify the desired table height\n",
    "            # table=col_cell_remove(table,num_columns_to_remove,table_width,sectorPD[dfName])\n",
    "            table=col_cell_remove(table,num_columns_to_remove)\n",
    "            \n",
    "            \n",
    "            total_col_width = table_width - table.columns[0].width\n",
    "            num_columns = len(table.columns) - 1  # Exclude the first row\n",
    "            if num_columns > 0:\n",
    "                cell_width = total_col_width / num_columns\n",
    "                for col in range(1, table.columns.__len__()):\n",
    "                    table.columns[col].width = int(cell_width)\n",
    "            if slideby==f'{BrandOrTopB}' :   \n",
    "                mergedCellDf = merged_dict[dfName][f'{BrandOrTopB}'].value_counts().reset_index()\n",
    "                # print(dfName, mergedCellDf)\n",
    "                #mergedCellDf = mergedCellDf.rename(columns = {\"index\":f'{sec_seg}', f'{sec_seg}':'count'})\n",
    "                #mergedCellDf=mergedCellDf.merge(merged_dict[dfName][['Top Brands','Value Share']].drop_duplicates()).sort_values(['Value Share'], ascending= False)\n",
    "\n",
    "                client_row = mergedCellDf[mergedCellDf[f'{BrandOrTopB}'].isin(client_brands)]\n",
    "                if not client_row.empty:\n",
    "                    client_row = client_row.iloc[0]\n",
    "                    mergedCellDf = mergedCellDf[~mergedCellDf[f'{BrandOrTopB}'].isin(client_brands)]\n",
    "                    mergedCellDf = pd.concat([pd.DataFrame([client_row]), mergedCellDf], ignore_index=True)\n",
    "            \n",
    "            else:        \n",
    "                mergedCellDf = merged_dict[dfName][slideby].value_counts().reset_index()\n",
    "\n",
    "                client_row = mergedCellDf[mergedCellDf[slideby].isin(client_manuf)]\n",
    "                if not client_row.empty:\n",
    "                    client_row = client_row.iloc[0]\n",
    "                    mergedCellDf = mergedCellDf[~mergedCellDf[slideby].isin(client_manuf)]\n",
    "                    mergedCellDf = pd.concat([pd.DataFrame([client_row]), mergedCellDf], ignore_index=True)\n",
    "\n",
    "            mergedCellDf['mergedCell']=mergedCellDf['count'].cumsum()\n",
    "            count=1\n",
    "            # print(dfName,mergedCellDf['mergedCell'].unique())\n",
    "            num_cols = len(table.columns)\n",
    "\n",
    "            for mergedCell in mergedCellDf['mergedCell'].unique():\n",
    "                if count < num_cols and mergedCell < num_cols:\n",
    "                    table.cell(0, count).merge(table.cell(0, mergedCell))\n",
    "                count = mergedCell + 1\n",
    "\n",
    "            table.height = Inches(1.54)\n",
    "            \n",
    "            for i, row in enumerate(table.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    if j == 0:\n",
    "                        if i == 3:    \n",
    "                            cell.text=f\"Scraped Av. Price/Vol ({currencywithoutspace})\"\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                            cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                            cell.text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "                        continue\n",
    "                    if i==0:\n",
    "                        cell.text=merged_dict[dfName][slideby].iloc[j-1]\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(8)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                    elif (i==1):\n",
    "                        product =merged_dict[dfName][f\"{prodORitem}\"].iloc[j-1]\n",
    "                        cell.text=product\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                    elif (i==2):\n",
    "                        value = merged_dict[dfName]['Total Size'].iloc[j-1]\n",
    "                        cell.text = \"\" if pd.isna(value) else str(value)\n",
    "                    elif (i==3):\n",
    "                        val = merged_dict[dfName]['Scraped Av. Price/KG'].iloc[j-1]\n",
    "                        if pd.isna(val) or float(val) == 0.0:\n",
    "                            cell.text = ''\n",
    "                        else:\n",
    "                            cell.text = str(round(float(val), decimals))\n",
    "                            \n",
    "                    elif (i==4):\n",
    "                        if int(round(merged_dict[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0))!=0:\n",
    "                             cell.text = str(int(round(merged_dict[dfName]['Gross Margin %'].replace(np.nan,'0').astype(float).iloc[j-1]*100,0)))+'%' \n",
    "                        else:\n",
    "                            cell.text = ''\n",
    "                    if cell.text!='' and i!=0 and i!=1:\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa Book'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1410267",
   "metadata": {},
   "source": [
    "# Price Distribution By Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brandPriceDistributionPPTX(prs,brandPriceDistribution,numOfDuplicates,currency='',position=0):\n",
    "        \"\"\"\n",
    "        Generate PowerPoint slides with brand price distribution data.\n",
    "\n",
    "        Args:\n",
    "        - prs: PowerPoint presentation object.\n",
    "        - brandPriceDistribution (dict): Dictionary containing DataFrames with brand price distribution information.\n",
    "        - numOfDuplicates (int): Number of slides to generate.\n",
    "        - currency (str): Currency symbol.\n",
    "        - position (int): Position index for inserting slides.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"        \n",
    "        for slidenum in range(numOfDuplicates):\n",
    "            dfName=list(brandPriceDistribution.keys())[slidenum]\n",
    "            market=dfName.split(' | ')[1]\n",
    "            cat=dfName.split(' | ')[0]\n",
    "            \n",
    "            shapes = prs.slides[slidenum+position].shapes\n",
    "            titleNumber = get_shape_number(shapes, \"Price Distribution By Brand | Total | National | P12M\")\n",
    "            headerNumber = get_shape_number(shapes, \"Price Point Distribution Analysis by brand (Replace with SO WHAT)\")\n",
    "            \n",
    "            currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "            shapes[7].text=f'Avg Price\\nPer Unit ({currencywithoutspace})'\n",
    "            for paragraph in shapes[7].text_frame.paragraphs:\n",
    "                paragraph.font.size = Pt(8)\n",
    "                paragraph.font.name = 'Nexa Bold'\n",
    "                paragraph.font.color.rgb = RGBColor(87, 85, 85)\n",
    "            shapes[titleNumber-1].text = data_source\n",
    "            shapes[titleNumber].text=shapes[4].text.replace('National',market)\n",
    "            shapes[titleNumber].text=shapes[4].text.replace('Total',cat)\n",
    "            \n",
    "\n",
    "            # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'    \n",
    "            tables,charts=createTableAndChart(shapes)\n",
    "\n",
    "            chart=charts[0].chart\n",
    "\n",
    "            chart_data = CategoryChartData()\n",
    "            chart_data.categories =brandPriceDistribution[dfName][f'{BrandOrTopB}'].unique()\n",
    "\n",
    "            for size in brandPriceDistribution[dfName]['Pack Size'].unique():\n",
    "                chart_data.add_series(size,brandPriceDistribution[dfName][brandPriceDistribution[dfName]['Pack Size']==size]['Av Price/Unit'].replace({np.nan: None, 0: None}))\n",
    "            \n",
    "            chart.replace_data(chart_data)\n",
    "        \n",
    "            for series in chart.series:\n",
    "                series.data_labels.show_series_name = True  # Show data labels\n",
    "                series.data_labels.font.size=Pt(8)\n",
    "                series.data_labels.font.name='Nexa Book'\n",
    "            chart.has_title=False    \n",
    "            value_axis = chart.value_axis\n",
    "            value_axis.tick_labels.number_format =  f'#,##0.00'  if decimals == 2 else f'#,##0'\n",
    "                \n",
    "            value_axis.has_title=False\n",
    "\n",
    "            chart.replace_data(chart_data)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fe4dc",
   "metadata": {},
   "source": [
    "# Price Distribution By Brands by sec/seg/subseg/subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2b1a7-223e-4348-9d5d-0db3e5025c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brandSectorPriceDistributionPPTX(prs,brandPriceDistribution,numOfDuplicates,sec_seg='Sector',currency='',position=0):\n",
    "    \"\"\"\n",
    "    Generate PowerPoint slides for brand price distribution by sector.\n",
    "\n",
    "    Args:\n",
    "    - prs: PowerPoint presentation object\n",
    "    - brandPriceDistribution (dict): Dictionary containing DataFrames with brand price distribution information.\n",
    "    - numOfDuplicates (int): Number of duplicate slides to generate.\n",
    "    - sec_seg (str): Name of the segmentation column.\n",
    "    - currency (str): Currency symbol.\n",
    "    - position (int): Position index.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    for slidenum in range(numOfDuplicates):\n",
    "        dfName=list(brandPriceDistribution.keys())[slidenum]\n",
    "        \n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        titleNumber = get_shape_number(shapes, \"Price Distribution By Brand | Sector | National | P12M\")\n",
    "        headerNumber = get_shape_number(shapes, \"Price Point Distribution by brand by Sector (Replace with SO WHAT)\")\n",
    "        shapes[headerNumber].text = f\"Price Point Distribution by brand by {sec_seg}\"\n",
    "        shapes[titleNumber-1].text = data_source\n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "        shapes[7].text=f'Avg Price\\nPer Unit ({currencywithoutspace})'\n",
    "        for paragraph in shapes[7].text_frame.paragraphs:\n",
    "            paragraph.font.size = Pt(8)\n",
    "            paragraph.font.name = 'Nexa Bold'\n",
    "            paragraph.font.color.rgb = RGBColor(87, 85, 85)\n",
    "\n",
    "        shapes[titleNumber].text=shapes[4].text.replace('National',dfName).replace('Sector',sec_seg)\n",
    "        # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'    \n",
    "        tables,charts=createTableAndChart(shapes)\n",
    "        chart=charts[0].chart\n",
    "\n",
    "        chart_data = CategoryChartData()\n",
    "\n",
    "        categories = chart_data.categories\n",
    "        df=brandPriceDistribution[dfName]\n",
    "        for brand in df[f'{BrandOrTopB}'].unique():\n",
    "            category_1 = categories.add_category(brand)\n",
    "            for segment in df[df[f'{BrandOrTopB}']==brand][sec_seg].unique():\n",
    "                category_1.add_sub_category(segment)\n",
    "        uniqueSizes=df['Pack Size'].unique()\n",
    "        for packSize in uniqueSizes:\n",
    "            chart_data.add_series(packSize,df[df['Pack Size']==packSize]['Av Price/Unit'].replace({np.nan: None, 0: None}) )\n",
    "        for series in chart.series:\n",
    "            series.data_labels.show_series_name = True  # Show data labels\n",
    "            series.data_labels.font.size=Pt(8)\n",
    "            series.data_labels.font.name='Nexa Book'\n",
    "        chart.has_title=False    \n",
    "        value_axis = chart.value_axis\n",
    "        \n",
    "        value_axis.tick_labels.number_format =  f'#,##0.00'  if decimals == 2 else f'#,##0'\n",
    "            \n",
    "        value_axis.has_title=False\n",
    "        chart.replace_data(chart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4897224f",
   "metadata": {},
   "source": [
    "# Price Correlation Analysis P3Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_correlation_p3y(prs, modified_price, modified_price_p12m, categories_dict_P3M, position=0):\n",
    "    slide_num = 0\n",
    "    for key, df in modified_price.items():\n",
    "        df.fillna(0, inplace=True)\n",
    "        slide = prs.slides[slide_num + position]\n",
    "        # print(key)\n",
    "        shapes = slide.shapes\n",
    "        # Update title shape\n",
    "        # title_text = f\"Price Correlation | {key.split(' | ')[2]} vs {key.split(' | ')[3]} | {key.split(' | ')[0]} | {key.split(' | ')[1]} | Weekly Price vs. Share analysis | P3Y\"\n",
    "        shapes[4].text = data_source  # Make sure the index is correct (5 - 1 = 4)\n",
    "        shapes[5].text = (\"Price Correlation | \" + key.split(' | ')[2] + \" vs \" + key.split(' | ')[3] +\n",
    "                          \" | \" + key.split(' | ')[0] + \" | \" + key.split(' | ')[1] +\n",
    "                          \" | Weekly Price vs. Share analysis\\n\" \"   P3Y        P12M\")\n",
    "        shapes[5].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[5].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "        shapes[6].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "        shapes[6].text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "       \n",
    "        # Create table and chart objects\n",
    "        tables, charts = createTableAndChart(slide.shapes)\n",
    "        chart1 = charts[0].chart  # First chart\n",
    "        chart2 = charts[1].chart  # Second chart\n",
    "       \n",
    "        # Extract data for charts\n",
    "        category = df[f'{BrandOrTopB}_client'].tolist()\n",
    "        x_values_price = df['Price lx vs PL'].tolist()\n",
    "        x_values_av = df['Av Price/KG_client'].tolist()\n",
    "        y_values = df['Volume Share_client'].tolist()\n",
    "       \n",
    "        ###################Chart1#################\n",
    "        chart_data1 = XyChartData()\n",
    "        series_P3Y = chart_data1.add_series('P3Y Points')\n",
    "        series_P12M = chart_data1.add_series('P12M Points')\n",
    " \n",
    "        for i in range(len(category)):\n",
    "            point = (x_values_price[i], y_values[i])\n",
    "            is_matched = False\n",
    "            if key in modified_price_p12m:\n",
    "                if point in zip(\n",
    "                        modified_price_p12m[key]['Price lx vs PL'],\n",
    "                        modified_price_p12m[key]['Volume Share_client']):\n",
    "                    is_matched = True\n",
    " \n",
    "            if is_matched:\n",
    "                series_P12M.add_data_point(x_values_price[i], y_values[i])\n",
    "            else:\n",
    "                series_P3Y.add_data_point(x_values_price[i], y_values[i])\n",
    "   # Calculate slope and intercept for series_P12M\n",
    "        x_values_P12M = []\n",
    "        y_values_P12M= []\n",
    "        for point in series_P12M:  \n",
    "            x_values_P12M.append(point.x)\n",
    "            y_values_P12M.append(point.y)\n",
    "        intercept = 0  # Default value\n",
    "        slope = 1  # Default slope to avoid division by zero\n",
    "\n",
    "        if len(x_values_P12M) > 1 and len(y_values_P12M) > 1 and len(set(x_values_P12M)) > 1:\n",
    "            slope, intercept = np.polyfit(x_values_P12M, y_values_P12M, 1)  # Linear fit (degree 1)\n",
    "            # print(intercept,slope)\n",
    "        category_axis = chart1.category_axis\n",
    "        category_axis.auto_axis = True\n",
    "        min_xvalue1 =min(x_values_price)\n",
    "        max_xvalue1= max(x_values_price)\n",
    " \n",
    "        ###############P3yQ Line#################\n",
    "        df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "        # Create columns for Year and Quarter\n",
    "        df['Year'] = df['End of Week'].dt.year\n",
    "        df['Quarter'] = df['End of Week'].dt.to_period('Q')\n",
    "        # Group by Year and Quarter, then calculate averages for numerical columns\n",
    "        avg_df = df.groupby(['Year', 'Quarter']).agg({\n",
    "            'Volume Share_client': 'mean'}).reset_index()\n",
    "        max_volume_share_row = avg_df.loc[avg_df['Volume Share_client'].idxmax()]\n",
    "        z=(max_volume_share_row['Volume Share_client']-intercept)/slope\n",
    "        line_series = chart_data1.add_series('Custom Linep3yQ')\n",
    "        line_series.add_data_point(0, max_volume_share_row['Volume Share_client'])\n",
    "        line_series.add_data_point(z,  max_volume_share_row['Volume Share_client'])\n",
    "        line2_series = chart_data1.add_series(\"Custom Line2p3yQ\")\n",
    "        line2_series.add_data_point(z,  max_volume_share_row['Volume Share_client'])\n",
    "        line2_series.add_data_point(z, 0)\n",
    "        ###############P12MQ Line#################\n",
    "        if key in modified_price_p12m :\n",
    "            df12m=modified_price_p12m[key]\n",
    "            df12m['End of Week'] = pd.to_datetime(df12m['End of Week'])\n",
    "            # Create columns for Year and Quarter\n",
    "            df12m['Year'] = df12m['End of Week'].dt.year\n",
    "            df12m['Quarter'] = df12m['End of Week'].dt.to_period('Q')\n",
    "            # Group by Year and Quarter, then calculate averages for numerical columns\n",
    "            avg_df12m = df12m.groupby(['Year', 'Quarter']).agg({\n",
    "                'Volume Share_client': 'mean'}).reset_index()\n",
    "            max_volume_share_row12m = avg_df12m.loc[avg_df12m['Volume Share_client'].idxmax()]\n",
    "            p12m=(max_volume_share_row12m['Volume Share_client']-intercept)/slope\n",
    "            line_series = chart_data1.add_series('Custom Linep12mQ')\n",
    "            line_series.add_data_point(0, max_volume_share_row12m['Volume Share_client'])\n",
    "            line_series.add_data_point(p12m,  max_volume_share_row12m['Volume Share_client'])\n",
    "            line2_series = chart_data1.add_series(\"Custom Line2p12mQ\")\n",
    "            line2_series.add_data_point(p12m,  max_volume_share_row12m['Volume Share_client'])\n",
    "            line2_series.add_data_point(p12m, 0)      \n",
    "        else:\n",
    "            p12m=0\n",
    "            max_volume_share_row12m = {'Volume Share_client': None}  # Handle missing data gracefully\n",
    "        ###############P3M Line#################\n",
    "        if key in categories_dict_P3M and not categories_dict_P3M[key].empty:\n",
    "            # Calculate the average volume share\n",
    "            avg_volume_share = categories_dict_P3M[key][\"Volume Share_client\"].mean()\n",
    "            x=(avg_volume_share-intercept)/slope\n",
    "            line_series = chart_data1.add_series('Custom Linep3m')\n",
    "            line_series.add_data_point(0, avg_volume_share)\n",
    "            line_series.add_data_point(x, avg_volume_share)\n",
    " \n",
    "            line2_series = chart_data1.add_series('Custom Line2p3m')\n",
    "            line2_series.add_data_point(x, avg_volume_share)\n",
    "            line2_series.add_data_point(x, 0)\n",
    "        else:\n",
    "            x=0\n",
    "            avg_volume_share=0\n",
    "        x_values_P12M.append(p12m)\n",
    "        x_values_P12M.append(z)\n",
    "        x_values_P12M.append(x)    \n",
    "        ###############Regression line####################\n",
    "        smallest = min(min_xvalue1, x, p12m, z)\n",
    "        largest = max(max_xvalue1, x, p12m, z)\n",
    "        # print(\"min_xvalue1:\",min_xvalue1,\"x:\",x,\"p12m:\",p12m,\"z:\",z,\"smallest\",smallest)\n",
    "        if smallest <0:\n",
    "            smallest =0\n",
    "        category_axis.minimum_scale=round(smallest*0.8)\n",
    "        category_axis.maximum_scale=round(largest*1.2)\n",
    "   # Initialize series_Y_hat\n",
    "        series_Y_Hat = chart_data1.add_series(\"Y_Hat\")\n",
    "        for x in x_values_P12M:\n",
    "            y_hat = slope * x + intercept\n",
    "            series_Y_Hat.add_data_point(x, y_hat)\n",
    " \n",
    "        if key in modified_price_p12m:\n",
    "            unique_in_df1 = df[~df['End of Week'].isin(modified_price_p12m[key]['End of Week'])]\n",
    "        else:\n",
    "            unique_in_df1 = pd.DataFrame(columns=df.columns)  # Initialize as an empty DataFrame with the same columns\n",
    "        chart1.replace_data(chart_data1)\n",
    "\n",
    "        unique_in_df1['End of Week'] = pd.to_datetime(unique_in_df1['End of Week'], errors='coerce').dt.strftime('%Y/%m/%d')\n",
    " \n",
    "        min_yvalue =min(y_values)\n",
    "        max_yvalue =max(y_values)\n",
    " \n",
    "        value_axis = chart1.value_axis\n",
    "        value_axis.minimum_scale = (min_yvalue * 0.8)\n",
    "        value_axis.maximum_scale = (max_yvalue * 1.2)\n",
    "       \n",
    "        chart1.category_axis.axis_title.text_frame.text=  'Price Ix vs. '+ key.split(' | ')[3]\n",
    "        chart1.category_axis.axis_title.text_frame.paragraphs[0].font.size = Pt(8)\n",
    "        chart1.category_axis.axis_title.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "        chart1.category_axis.axis_title.text_frame.paragraphs[0].font.bold = False\n",
    "        chart1.category_axis.axis_title.text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)\n",
    "        chart1.category_axis.tick_labels.number_format = '0.0%'\n",
    " \n",
    "        xlsx_file = BytesIO()\n",
    "        # Ensure x is iterable\n",
    "        with chart_data1._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data1._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"End of Week\")\n",
    "            worksheet.write_column(1, 4, unique_in_df1['End of Week'], None)\n",
    "            worksheet.write(0, 7, \"Highest Value\")\n",
    "            worksheet.write_column(2, 7, [\"P3M Avg\"], None)\n",
    "            worksheet.write_column(3, 7, [\"P12M HighestQ\"], None)\n",
    "            worksheet.write_column(4, 7, [\"P3Y HighestQ\"], None)\n",
    "            # Write to worksheet\n",
    "            worksheet.write_column(2, 8, [f\"{avg_volume_share}\"], None)\n",
    "            worksheet.write_column(3, 8, [f\"{max_volume_share_row12m[\"Volume Share_client\"]}\"], None)\n",
    "            worksheet.write_column(4, 8,  [f\"{max_volume_share_row[\"Volume Share_client\"]}\"], None)\n",
    "            if key in modified_price_p12m:\n",
    "                modified_price_p12m[key]['End of Week'] = pd.to_datetime(modified_price_p12m[key]['End of Week'], errors='coerce').dt.strftime('%Y/%m/%d')\n",
    " \n",
    "                worksheet.write_column(len(unique_in_df1['End of Week'])+3, 4,modified_price_p12m[key]['End of Week'], None)\n",
    "        chart1._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "        legend = []\n",
    " \n",
    "        if x >= 0  :\n",
    "            legend.append((\"--- P3M Average\",RGBColor(87,85,85)))\n",
    "        if p12m >= 0 and p12m !=x:  # Separate `if` for this condition\n",
    "            legend.append((\"--- P12M Quarterly Highest\",RGBColor(0,160,151)))\n",
    "        if z >= 0 and z!=p12m:  # Separate `if` for this condition\n",
    "            legend.append((\"--- P3Y Quarterly Highest\",RGBColor(192, 0, 0)))\n",
    " \n",
    "\n",
    "#######################################Chart2#################################333\n",
    "        chart_data2 = XyChartData()\n",
    "        series_P3Y = chart_data2.add_series('P3Y_ Points')\n",
    "        series_P12M = chart_data2.add_series('P12M_Points')\n",
    "# Loop through data to determine matched/unmatched points\n",
    "        for i in range(len(category)):\n",
    "            point =(x_values_av[i], y_values[i])\n",
    "            is_matched = False\n",
    "            if key in modified_price_p12m:\n",
    "                if point in zip(\n",
    "                        modified_price_p12m[key]['Av Price/KG_client'],\n",
    "                        modified_price_p12m[key]['Volume Share_client']):\n",
    "                    is_matched = True\n",
    " \n",
    "            if is_matched:\n",
    "                series_P12M.add_data_point(x_values_av[i], y_values[i])\n",
    "            else:\n",
    "                series_P3Y.add_data_point(x_values_av[i], y_values[i])\n",
    "       \n",
    "        x_values_P12M = []\n",
    "        y_values_P12M= []\n",
    "        for point in series_P12M:\n",
    "            x_values_P12M.append(point.x)\n",
    "            y_values_P12M.append(point.y)\n",
    "        if len(x_values_P12M) > 1 and len(y_values_P12M) > 1 and len(set(x_values_P12M)) > 1:  # Ensure there are enough values to fit\n",
    "            slope, intercept = np.polyfit(x_values_P12M, y_values_P12M, 1)  # Linear fit (degree 1)\n",
    "            # print(intercept,slope)\n",
    "        category_axis = chart2.category_axis\n",
    "        min_xvalue2 =min(x_values_av)\n",
    "        max_xvalue2= max(x_values_av)  \n",
    " \n",
    "        ###############P3yQ Line#################\n",
    "        z=( max_volume_share_row['Volume Share_client']-intercept)/slope\n",
    "        line_series = chart_data2.add_series('Custom Linep3yQ')\n",
    "        line_series.add_data_point(0, max_volume_share_row['Volume Share_client'])\n",
    "        line_series.add_data_point(z,  max_volume_share_row['Volume Share_client'])  \n",
    "        line2_series = chart_data2.add_series(\"Custom Line2p3yQ\")\n",
    "        line2_series.add_data_point(z,  max_volume_share_row['Volume Share_client'])\n",
    "        line2_series.add_data_point(z, 0)\n",
    "        ###############P12MQ Line#################\n",
    "        if key in modified_price_p12m :\n",
    "            p12m=(max_volume_share_row12m['Volume Share_client']-intercept)/slope\n",
    "            line_series = chart_data2.add_series('Custom Linep12mQ')\n",
    "            line_series.add_data_point(0, max_volume_share_row12m['Volume Share_client'])\n",
    "            line_series.add_data_point(p12m,  max_volume_share_row12m['Volume Share_client'])\n",
    "            line2_series = chart_data2.add_series(\"Custom Line2p12mQ\")\n",
    "            line2_series.add_data_point(p12m,  max_volume_share_row12m['Volume Share_client'])\n",
    "            line2_series.add_data_point(p12m, 0)    \n",
    " \n",
    "        ##############P3M Line#################\n",
    "        if key in categories_dict_P3M and not categories_dict_P3M[key].empty:\n",
    "            # Calculate the average volume share\n",
    "            avg_volume_share = categories_dict_P3M[key][\"Volume Share_client\"].mean()\n",
    "            x=(avg_volume_share-intercept)/slope\n",
    "            line_series = chart_data2.add_series('Custom Linep3m')\n",
    "            line_series.add_data_point(0, avg_volume_share)\n",
    "            line_series.add_data_point(x, avg_volume_share)\n",
    "            line2_series = chart_data2.add_series('Custom Line2p3m')\n",
    "            line2_series.add_data_point(x, avg_volume_share)\n",
    "            line2_series.add_data_point(x, 0)\n",
    "           \n",
    "        x_values_P12M.append(p12m)\n",
    "        x_values_P12M.append(z)\n",
    "        x_values_P12M.append(x)    \n",
    "        ###############Regression line####################\n",
    "        series_Y_Hat = chart_data2.add_series(\"Y_Hat\")\n",
    "        # Compute y_hat for each x-value\n",
    "        for x in x_values_P12M:\n",
    "            y_hat = slope * x + intercept\n",
    "            # Add the computed y_hat to series_Y_Hat\n",
    "            series_Y_Hat.add_data_point(x, y_hat)\n",
    "   \n",
    "        chart2.replace_data(chart_data2)\n",
    "        value_axis = chart2.value_axis\n",
    "        value_axis.minimum_scale =min_yvalue * 0.8\n",
    "        value_axis.maximum_scale = max_yvalue * 1.2\n",
    "        # chart2.category_axis.tick_labels.number_format = '#,##0.00'+ currency\n",
    "        chart2.category_axis.tick_labels.number_format = '#,##0.00'  if decimals == 2 else '#,##0'\n",
    "        category_axis = chart2.category_axis\n",
    "        smallest = min(min_xvalue2, x, p12m, z)\n",
    "        largest = max(max_xvalue2, x, p12m, z)\n",
    "        if smallest <0:\n",
    "            smallest =0\n",
    "        category_axis.minimum_scale=round(smallest*0.8)\n",
    "        category_axis.maximum_scale=round(largest*1.2)\n",
    "       \n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "        category_axis.axis_title.text_frame.text = f\"Avg Price / Vol ({currencywithoutspace})\"  # Set the axis title text  \n",
    "        category_axis.axis_title.text_frame.paragraphs[0].font.size = Pt(8)\n",
    "        category_axis.axis_title.text_frame.paragraphs[0].font.bold = False\n",
    "        category_axis.axis_title.text_frame.paragraphs[0].font.name = 'Nexa Bold'        \n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data2._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data2._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"End of Week\")\n",
    "            worksheet.write_column(1, 4, unique_in_df1['End of Week'], None)\n",
    "            worksheet.write(0, 7, \"Highest Value\")\n",
    "            worksheet.write_column(2, 7, [\"P3M Avg\"], None)\n",
    "            worksheet.write_column(3, 7, [\"P12M HighestQ\"], None)\n",
    "            worksheet.write_column(4, 7, [\"P3Y HighestQ\"], None)\n",
    "            # Write to worksheet\n",
    "            worksheet.write_column(2, 8, [f\"{avg_volume_share}\"], None)\n",
    "            worksheet.write_column(3, 8, [f\"{max_volume_share_row12m[\"Volume Share_client\"]}\"], None)\n",
    "            worksheet.write_column(4, 8,  [f\"{max_volume_share_row[\"Volume Share_client\"]}\"], None)\n",
    "            if key in modified_price_p12m:\n",
    "                modified_price_p12m[key]['End of Week'] = pd.to_datetime(modified_price_p12m[key]['End of Week'], errors='coerce').dt.strftime('%Y/%m/%d')\n",
    "                worksheet.write_column(len(unique_in_df1['End of Week'])+3, 4,modified_price_p12m[key]['End of Week'], None)\n",
    "        chart2._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "     \n",
    "        if x >= 0 and (\"--- P3M Average\", RGBColor(87, 85, 85)) not in legend:\n",
    "            legend.insert(0,(\"--- P3M Average\",RGBColor(87,85,85)))\n",
    "        if p12m >= 0 and p12m != x and (\"--- P12M Quarterly Highest\",RGBColor(0,160,151)) not in legend:  # Separate `if` for this condition\n",
    "            legend.insert(1,(\"--- P12M Quarterly Highest\",RGBColor(0,160,151)))\n",
    "        if z >= 0 and z!=p12m and (\"--- P3Y Quarterly Highest\",RGBColor(192, 0, 0)) not in legend :  # Separate `if` for this condition\n",
    "            legend.insert(2,(\"--- P3Y Quarterly Highest\",RGBColor(192, 0, 0)))\n",
    "        # Access the text frame of the shape\n",
    "        text_frame = shapes[10].text_frame\n",
    "        text_frame.clear()  # Clear existing text\n",
    "        for idx, (text, color) in enumerate(legend):\n",
    "            # If not the first entry, add a newline\n",
    "            if idx > 0:\n",
    "                text_frame.add_paragraph()  # Add a new paragraph\n",
    "            # Create a new run for this text entry\n",
    "            p = text_frame.paragraphs[-1]  # Get the last paragraph (which is the current one)\n",
    "            run = p.add_run()  # Add a run to this paragraph\n",
    "            run.text = text  # Set the text\n",
    "            run.font.color.rgb = color  # Set the font color for this run\n",
    "            run.font.size = Pt(7)  # Set the font size (optional)\n",
    "            run.font.name = \"Nexa Book\"  #\n",
    "       \n",
    "        slide_num +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec32daa",
   "metadata": {},
   "source": [
    "# Price Point Distribution (Scraped Av Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricePointScraped(prs,sectorPD,numOfDuplicates,sec_seg='Sector',position=0):\n",
    "     \"\"\"\n",
    "        Generate slides displaying price point distribution.\n",
    " \n",
    "        Args:\n",
    "        - prs: PowerPoint presentation object.\n",
    "        - sectorPD (dict): Dictionary containing DataFrames with price point information for each sector.\n",
    "        - brandInScope (str): Name of the brand in focus.\n",
    "        - numOfDuplicates (int): Number of duplicate slides to generate.\n",
    "        - months (str): Time period for the data.\n",
    "        - sec_seg (str): The name of the column representing the sector or segment.\n",
    "        - position (int): Position of the slide in the presentation.\n",
    "        \"\"\"\n",
    "     for slidenum in range(numOfDuplicates):\n",
    "        dfName=list(sectorPD.keys())[slidenum]\n",
    "        shapes = prs.slides[slidenum+position].shapes\n",
    "        titleNumber = get_shape_number(shapes, \"Price Point Distribution | Brand | Category | National | P12M\")\n",
    "        headerNumber = get_shape_number(shapes, \"Price Point Distribution Analysis by product (Replace with SO WHAT)\")\n",
    "        axistitle=get_shape_number(shapes,\"Base Price/Unit ($)\")\n",
    "        currencywithoutspace =currency.strip()  # Remove the leading space\n",
    "        shapes[axistitle].text=f'Scraped Av. Price/Unit ({currencywithoutspace})'\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.size = Pt(8)\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "        shapes[axistitle].text_frame.paragraphs[0].font.color.rgb = RGBColor(87, 85, 85)  # Set color to black\n",
    " \n",
    "        shapes[titleNumber-1].text = data_source # Set data source information\n",
    "        # Set title for the slide\n",
    "        shapes[titleNumber].text = \"Price Point Distribution | \" + list(sectorPD.keys())[slidenum] \n",
    "        # shapes[titleNumber].text_frame.paragraphs[0].font.bold = True\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa (Headings)'    \n",
    "        tables,charts=createTableAndChart(shapes)\n",
    "        chart=charts[0].chart\n",
    "        chart_data = CategoryChartData()\n",
    "        chart_data.categories = sectorPD[dfName][prodORitem].unique()\n",
    "        # formatted_prices = sectorPD[dfName]['Base Price/Unit'].apply(lambda x: f\"{currency}{round(x, decimals):,.2f}\")\n",
    "        # chart_data.add_series('Base Price/Unit', formatted_prices)\n",
    "       \n",
    "        chart_data.add_series('Scraped Av. Price/Unit', round(sectorPD[dfName]['Scraped Av. Price/Unit'].astype(float),decimals))\n",
    "        chart.replace_data(chart_data)\n",
    "        chart.has_title = False\n",
    " \n",
    "        for i,series in enumerate(chart.series):\n",
    "                for j, point in enumerate(series.points):      \n",
    "                    data_label = point.data_label\n",
    "                    data_label.has_text_frame = True\n",
    "                    data_label.text_frame.text = str(round(series.values[j], decimals))\n",
    "                    data_label.position = XL_LABEL_POSITION.ABOVE  # Set the position above the point\n",
    " \n",
    "        value_axis = chart.value_axis\n",
    "        value_axis.auto_axis = True\n",
    "        value_axis.minimum_scale = None\n",
    "        value_axis.major_unit = None\n",
    "        value_axis.minor_unit = None\n",
    "        value_axis.axis_title.text_frame.text=''\n",
    "        value_axis.tick_labels.number_format = \"#,##0.00\" if decimals ==2 else \"#,##0\"\n",
    " \n",
    "        # Table #\n",
    "        table=tables[0].table\n",
    " \n",
    "        num_columns_to_remove = (len(table.columns) - sectorPD[dfName].shape[0]) - 1  # Specify the number of rows to remove from the end\n",
    "        table_width = Inches(8.89)  # Specify the desired table height\n",
    "        # table=col_cell_remove(table,num_columns_to_remove,table_width,sectorPD[dfName])\n",
    "        table=col_cell_remove(table,num_columns_to_remove)\n",
    "        # print(num_columns_to_remove)\n",
    "       \n",
    "       \n",
    "        total_col_width = table_width - table.columns[0].width\n",
    "        num_columns = len(table.columns) - 1  # Exclude the first row\n",
    " \n",
    "        if num_columns > 0:\n",
    "            cell_width = total_col_width / num_columns\n",
    "            for col in range(1, table.columns.__len__()):\n",
    "                table.columns[col].width = int(cell_width)\n",
    " \n",
    "        # mergedCellDf = sectorPD[dfName][sec_seg].value_counts().reset_index()\n",
    "        mergedCellDf = sectorPD[dfName].groupby(sec_seg).size().reset_index(name='count')\n",
    "        # print(dfName, mergedCellDf)\n",
    "\n",
    "        # print(dfName, sectorPD[dfName][sec_seg])\n",
    "        # mergedCellDf = mergedCellDf.rename(columns = {\"index\":f'{sec_seg}'})\n",
    "        # mergedCellDf=mergedCellDf.merge(sectorPD[dfName][[sec_seg,'Sort_Value']].drop_duplicates()).sort_values(['Sort_Value'])\n",
    " \n",
    "        mergedCellDf['mergedCell']=mergedCellDf['count'].cumsum()\n",
    "        count=1\n",
    "        # print(dfName,mergedCellDf['mergedCell'].unique())\n",
    "        for mergedCell in mergedCellDf['mergedCell'].unique():\n",
    "            table.cell(0,count).merge(table.cell(0,mergedCell))\n",
    "            count=mergedCell+1\n",
    " \n",
    "        table.height = Inches(1.54)\n",
    "       \n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if j == 0:\n",
    "                    if i == 3:\n",
    "                        cell.text=f\"Scraped Av. Price/Vol ({currencywithoutspace})\"\n",
    "                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                        cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                        cell.text_frame.paragraphs[0].font.name = 'Nexa (Headings)'\n",
    "                    continue\n",
    "               \n",
    "                if i==0:\n",
    "                    cell.text=sectorPD[dfName][sec_seg].iloc[j-1]\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(8)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                elif (i==1):\n",
    "                    cell.text=sectorPD[dfName][f\"{prodORitem}\"].iloc[j-1]\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(6)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = True\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Bold'\n",
    "                elif (i==2):\n",
    "                    cell.text=sectorPD[dfName]['Total Size'].iloc[j-1]\n",
    "                elif (i==3):\n",
    "                    cell.text=str(round(sectorPD[dfName]['Scraped Av. Price/KG'].astype(float).iloc[j-1],decimals))\n",
    "                       \n",
    "                if cell.text!='' and i!=0 and i!=1:\n",
    "                    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.size = Pt(7)\n",
    "                    cell.text_frame.paragraphs[0].runs[0].font.bold = False\n",
    "                    cell.text_frame.paragraphs[0].font.name = 'Nexa Book'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1179f",
   "metadata": {},
   "source": [
    "# Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropemptydf(dic):\n",
    "    keys_to_remove = [k for k, v in dic.items() if v.empty]\n",
    "    for k in keys_to_remove:\n",
    "        del dic[k]\n",
    "        \n",
    "def remove_others_from_dic(sorted_dic, col):\n",
    "    for k in sorted_dic.keys():\n",
    "        sorted_dic[k] = sorted_dic[k][~sorted_dic[k][col].str.contains(\"Others\", case=False, na=False)]\n",
    "#####PricepositionSlideClean      \n",
    "def PricePositioningClean(dic, col=\" \"):\n",
    "    modified_price_positioning = {}\n",
    "    for l in dic.keys():\n",
    "        df = dic[l].copy()  # Create a copy of the DataFrame\n",
    "        # df = DetectHeader(df)  # Detect and clean headers\n",
    "        df['Value Share'] = df['Value Share'].astype(float)\n",
    "        df = df[df[col] != \"Grand Total\"]\n",
    "        df=df[~df[col].str.contains(\"Others\")]\n",
    "        # if not df.empty:\n",
    "        modified_price_positioning[l] = df\n",
    "        \n",
    "    sorted_dic_position = dfSort(modified_price_positioning, client_brands, col, num=9, salesCol='Value Share')\n",
    "    sorted_dic_table = dfSort(modified_price_positioning, client_brands, col, num=6, salesCol='Value Share')\n",
    "    remove_others_from_dic(sorted_dic_position, col)\n",
    "    remove_others_from_dic(sorted_dic_table, col)\n",
    "    dropemptydf(sorted_dic_position)\n",
    "    dropemptydf(sorted_dic_table)\n",
    "\n",
    "    return sorted_dic_position ,sorted_dic_table # Return the sorted dictionary\n",
    "#####Sector/Segment Leadership TableClean\n",
    "def sharGrowthDfclean(dic, totdic, valid_list):\n",
    "    sharGrowthDf = {}\n",
    "    keys_to_check = (\n",
    "        [\"NATIONAL\"] + regions_RET + channels_RET + market_RET +\n",
    "        regions_CHAN + channels_CHAN + market_CHAN +\n",
    "        regions_CUST + channels_CUST + market_CUST\n",
    "    )\n",
    "    \n",
    "    for key in keys_to_check:\n",
    "        matched = [k.split(' | ')[0] for k in dic.keys() \n",
    "                   if k.split(' | ')[1] == key and k.split(' | ')[0] in valid_list]\n",
    "\n",
    "        if matched and key in totdic:\n",
    "            df = totdic[key].copy()\n",
    "            order = list(df[df.columns[0]].dropna().astype(str))  # Ensure all values are strings for matching\n",
    "            # Filter and sort matched by order\n",
    "            matched_sorted = [x for x in order if x in matched]\n",
    "            sharGrowthDf[key] = [matched_sorted[i:i+6] for i in range(0, len(matched_sorted), 6)]\n",
    "\n",
    "    return sharGrowthDf\n",
    "\n",
    "####Sector/Segment Leadership Analysis clean\n",
    "def leadershipanalysisclean(inputdic,outputdic,parent=\"sector\",total=False):\n",
    "    for key in inputdic.keys():\n",
    "        tot1 = inputdic[key].copy()\n",
    "        # tot1=DetectHeader(tot1)\n",
    "        tot1[parent] = tot1[parent].ffill()\n",
    "        tot1[\"Gross Margin %\"] = tot1[\"Gross Margin %\"].fillna(0)\n",
    "        tot1 =tot1[~tot1[parent].str.contains(\"Total\",na=False)]\n",
    "        if total==True:\n",
    "            tot1=tot1[tot1['Value Share']>=0.01]\n",
    "            tot1 = tot1.sort_values(by='Value Share', ascending=False)\n",
    "            top_sectors = tot1.head(10)\n",
    "            outputdic[key] = top_sectors\n",
    "        else:\n",
    "            outputdic[key] = tot1         \n",
    "            \n",
    "####Sector/Segment BrandLeadershipsclean      \n",
    "def totalleadership(indictionary, outdictionary, Inscope=\"\",total=False):\n",
    "    for k in indictionary.keys():\n",
    "        t = indictionary[k].copy()\n",
    "        # t=DetectHeader(t)\n",
    "        t[\"Gross Margin %\"] = t[\"Gross Margin %\"].fillna(0)\n",
    "        t =t[~t[Inscope].str.contains(\"Grand Total\",na=False)]\n",
    "        if total==True:\n",
    "            t=t[t['Value Share']>=0.01]\n",
    "            t = t.sort_values(by='Value Share', ascending=False)\n",
    "            top_sectors = t.head(5)\n",
    "            outdictionary[k] = top_sectors\n",
    "        else:\n",
    "            outdictionary[k] = t       \n",
    "            \n",
    "def wobcleaning(inputdic,slideby=\"\"):\n",
    "    outputdic={}\n",
    "    for k in inputdic.keys():\n",
    "        c=inputdic[k].copy()\n",
    "        # c=DetectHeader(c)\n",
    "        c=c[~c[slideby].str.contains(\"Grand Total\",na=False)]\n",
    "        c = c.sort_values(\"Value Share\", ascending=False)\n",
    "        outputdic[k]=c\n",
    "    return outputdic                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Shelf price /vol and Avg price /vol comparisonClean\n",
    "def shelfallbrandsclean (inputalldic,outputalldic,inputtopdic,outputtopdic,Inscope=\"Sector\",bymanuf=\"\"):\n",
    "    for k in inputalldic.keys():\n",
    "        t = inputalldic[k].copy()\n",
    "        # print(k,inputalldic)\n",
    "        # t=DetectHeader(t)\n",
    "        t[Inscope] = t[Inscope].ffill()\n",
    "        t = t[t[Inscope].str.contains('Total')]\n",
    "        t = t.sort_values('Value Share', ascending=False)\n",
    "        t[Inscope] = t[Inscope].str.replace(' Total', '')\n",
    "        t['Sort_Value'] = range(1,t.shape[0]+1)\n",
    "        t['Sort_Value'] = t['Sort_Value'] * -1\n",
    "        outputalldic[k] = t\n",
    "        \n",
    "    for k in inputtopdic.keys():\n",
    "        b = inputtopdic[k].copy()\n",
    "        # b = DetectHeader(b)\n",
    "        b[Inscope] = b[Inscope].ffill()\n",
    "        b=b.fillna(0)\n",
    "        if bymanuf==f'{ManufOrTopC}':\n",
    "            cop = b[~b[f'{ManufOrTopC}'].isin(client_manuf)]\n",
    "        \n",
    "            cop = cop[~cop[Inscope].str.contains('Total')]\n",
    "            cop_tot = cop[[f'{ManufOrTopC}', 'Value Share']].groupby(f'{ManufOrTopC}', group_keys=False).sum().reset_index()\n",
    "            cop_tot = cop_tot.sort_values('Value Share', ascending=False)\n",
    "            cop_tot = cop_tot[~cop_tot[f'{ManufOrTopC}'].str.contains('Other')]\n",
    "            top_manuf = cop_tot[f'{ManufOrTopC}'][:3].tolist()\n",
    "\n",
    "            for c in client_manuf:\n",
    "                if c not in b[f'{ManufOrTopC}'].values:\n",
    "                    continue\n",
    "\n",
    "                final = b[b[f'{ManufOrTopC}'].isin([c] + top_manuf)]\n",
    "            \n",
    "                final = final.merge(outputalldic[k][[Inscope, 'Sort_Value']]).sort_values(by=['Sort_Value', 'Value Share'], ascending=False)\n",
    "                outputtopdic[c + ' | ' + k] = final\n",
    "\n",
    "        else: \n",
    "            cop = b[~b[f\"{BrandOrTopB}\"].isin(client_brands)]\n",
    "            cop = cop[~cop[Inscope].str.contains('Total')]\n",
    "            cop_tot = cop[[f\"{BrandOrTopB}\", 'Value Share']].groupby(f\"{BrandOrTopB}\", group_keys=False).sum().reset_index()\n",
    "            cop_tot = cop_tot.sort_values('Value Share', ascending=False)\n",
    "            cop_tot = cop_tot[~cop_tot[f\"{BrandOrTopB}\"].str.contains('Other')]\n",
    "            top_brands = cop_tot[f\"{BrandOrTopB}\"][:3].tolist()\n",
    "\n",
    "            for c in client_brands:\n",
    "                if c not in b[f\"{BrandOrTopB}\"].values:\n",
    "                    continue\n",
    "\n",
    "                final = b[b[f\"{BrandOrTopB}\"].isin([c] + top_brands)]\n",
    "                # print(k)\n",
    "                final = final.merge(outputalldic[k][[Inscope, 'Sort_Value']]).sort_values(by=['Sort_Value', 'Value Share'], ascending=False)\n",
    "                outputtopdic[c + ' | ' + k] = final\n",
    "            \n",
    "        for key in outputtopdic.keys():\n",
    "            outputtopdic[key]['Av Price/KG'] = pd.to_numeric(outputtopdic[key]['Av Price/KG'], errors='coerce')\n",
    "            outputtopdic[key]['Top Comp Av Price/KG'] = (\n",
    "                outputtopdic[key]\n",
    "                .loc[outputtopdic[key]['Value Share'] == outputtopdic[key].groupby(Inscope)['Value Share'].transform('max'), 'Av Price/KG']\n",
    "                .groupby(outputtopdic[key][Inscope])\n",
    "                .transform('max')\n",
    "            )\n",
    "            outputtopdic[key]['Top Comp Av Price/KG']=outputtopdic[key]['Top Comp Av Price/KG'].ffill()\n",
    "            outputtopdic[key]['Ix_Av Price/KG'] = (\n",
    "                outputtopdic[key].groupby(Inscope)['Av Price/KG'].transform(\n",
    "                    lambda x: ((x / outputtopdic[key]['Top Comp Av Price/KG']) * 100)\n",
    "                    )\n",
    "            )\n",
    "            outputtopdic[key]['Ix_Av Price/KG'] = (\n",
    "                outputtopdic[key]['Ix_Av Price/KG']\n",
    "                .replace([np.inf, -np.inf], np.nan)  # handle inf\n",
    "                .fillna(0)                           # replace NaN\n",
    "                .round()\n",
    "                .astype(int)\n",
    "            )\n",
    "            outputtopdic[key]['Ix_Av Price/KG'] = \"IX \" + outputtopdic[key]['Ix_Av Price/KG'].astype(str)\n",
    "\n",
    "            outputtopdic[key][\"Base Price/KG\"] = pd.to_numeric(outputtopdic[key][\"Base Price/KG\"], errors='coerce')\n",
    "            # Calculate the Ix within each sector\n",
    "            outputtopdic[key]['Top Comp Base Price/KG'] = (\n",
    "            outputtopdic[key]\n",
    "            .loc[outputtopdic[key]['Value Share'] == outputtopdic[key].groupby(Inscope)['Value Share'].transform('max'), 'Base Price/KG']\n",
    "            .groupby(outputtopdic[key][Inscope])\n",
    "            .transform('max')\n",
    "            )\n",
    "            outputtopdic[key]['Top Comp Base Price/KG']=outputtopdic[key]['Top Comp Base Price/KG'].ffill()\n",
    "\n",
    "            outputtopdic[key]['Ix_Base Price/KG'] = (\n",
    "            outputtopdic[key].groupby(Inscope)['Base Price/KG'].transform(\n",
    "                lambda x: ((x / outputtopdic[key]['Top Comp Base Price/KG']) * 100)\n",
    "            )\n",
    "            )\n",
    "            outputtopdic[key]['Ix_Base Price/KG'] = (\n",
    "                outputtopdic[key]['Ix_Base Price/KG']\n",
    "                .replace([np.inf, -np.inf], np.nan)  # handle inf\n",
    "                .fillna(0)                           # replace NaN\n",
    "                .round()\n",
    "                .astype(int)\n",
    "            )\n",
    "            outputtopdic[key]['Ix_Base Price/KG'] = \"IX \" + outputtopdic[key]['Ix_Base Price/KG'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Shelf Price & AVG PRICE FUNCTION\n",
    "def shelfPriceCleaning(total_brands, top_brands, sec_seg='Sector',slide_by=[],brandORmanuf=''):\n",
    "    all_brands = {}\n",
    "\n",
    "    for top_key in top_brands.keys():\n",
    "        common_part = top_key.split(\" | \",1)[1]  # Extract the common part from the top_brands key\n",
    "        total_key = [key for key in total_brands.keys() if common_part in key][0]  # Find the corresponding total_brands key\n",
    "        \n",
    "        if 'Sort_Value' in total_brands[total_key].columns:\n",
    "            total_brands[total_key] = total_brands[total_key].drop(columns=['Sort_Value'])\n",
    "        total_brands[total_key] = total_brands[total_key].sort_values(['Value Share'], ascending=False)\n",
    "        total_brands[total_key]['Sort_Value'] = range(1, total_brands[total_key].shape[0] + 1)\n",
    "\n",
    "        total_brands[total_key][brandORmanuf] = 'Total'\n",
    "        total_brands[total_key][sec_seg] = total_brands[total_key][sec_seg].str.replace('Total', '').str.strip()\n",
    "        \n",
    "        all_brands[top_key] = pd.concat([total_brands[total_key], top_brands[top_key]])\n",
    "        unique_brands = all_brands[top_key][brandORmanuf].unique()\n",
    "        missing_brand_sector = {}\n",
    "        \n",
    "        for sector in all_brands[top_key][sec_seg].unique():\n",
    "            missingBrands = list(set(unique_brands) - set(all_brands[top_key][all_brands[top_key][sec_seg] == sector][brandORmanuf].unique()))\n",
    "            if missingBrands:\n",
    "                missing_brand_sector[sector] = missingBrands\n",
    "\n",
    "        missing_brand_sector = pd.DataFrame({sec_seg: missing_brand_sector.keys(), brandORmanuf: missing_brand_sector.values()}).explode(brandORmanuf)\n",
    "        all_brands[top_key] = pd.concat([all_brands[top_key], missing_brand_sector]).sort_values(by=[sec_seg]).replace(np.nan, None)\n",
    "        all_brands[top_key]['Value Share'] = all_brands[top_key]['Value Share'].astype(float)\n",
    "        total_brands[total_key]['Sort_Value'] = total_brands[total_key]['Sort_Value'].astype(int)\n",
    "        total_brands[total_key] = total_brands[total_key][total_brands[total_key][sec_seg].isin(slide_by)]\n",
    "        all_brands[top_key] = all_brands[top_key].drop(columns='Sort_Value').merge(total_brands[total_key][[sec_seg, 'Sort_Value']]).sort_values(['Sort_Value', 'Value Share'], ascending=[True, False])\n",
    "        all_brands[top_key] = all_brands[top_key][all_brands[top_key][sec_seg].isin(slide_by)]\n",
    "        \n",
    "    return all_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c28b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningPricePointScraped(dfs,Eandfs,Inscope):\n",
    "    output={}\n",
    "    for k in dfs.keys():\n",
    "        t = dfs[k].copy()\n",
    "        t=DetectHeader(t)\n",
    "        endf=Eandfs[k].copy()\n",
    "        endf=DetectHeader(endf)\n",
    "        \n",
    "        # t = t[(t['Total Size'].notna()) | (t[Inscope].str.contains(\"Total\"))]\n",
    "        t[\"End of Week\"]=t[\"End of Week\"].ffill()\n",
    "        t[Inscope] = t[Inscope].ffill()\n",
    "        t[\"Ean\"] = t[\"Ean\"].ffill()\n",
    "        t[\"SKU\"] = t[\"SKU\"].ffill()\n",
    "        \n",
    "        dfTotal = t[t[Inscope].str.contains('Total')]\n",
    "        # dfTotal['Sort_Value']=range(1,dfTotal.shape[0]+1)\n",
    "        # dfTotal[Inscope]=dfTotal[Inscope].str.replace(' Total','')\n",
    "        t = t[~t[Inscope].str.contains('Total')]\n",
    "        t=t[~t[\"End of Week\"].str.contains('Total')]  \n",
    "        t = t[~t[f'{prodORitem}'].fillna('').str.contains('Total')]\n",
    "        t=t[~t['Ean'].str.contains('Total')] \n",
    "        \n",
    "        # t=t.dropna(subset=['Scraped Av. Price/Unit', 'Scraped Av. Price/KG'])\n",
    "        \n",
    "        t['End of Week'] = pd.to_datetime(t['End of Week'], errors='coerce')\n",
    "        # t.drop(columns=['End of Week'], inplace=True)\n",
    "        # dfTotal['Sort_Value']=range(1,dfTotal.shape[0]+1)\n",
    "        # dfTotal[Inscope]=dfTotal[Inscope].str.replace(' Total','')\n",
    "        # t = t[~t[Inscope].str.contains('Total')].head(15)\n",
    "        # t=t.merge(dfTotal[[Inscope,'Sort_Value']]).sort_values(['Sort_Value','Scraped Av. Price/KG'],ascending=[True,False])\n",
    "        if not t.empty and k in Eandfs:\n",
    "            t = t.merge(endf, on='Ean', how='left')\n",
    "            t['End of Week'] = pd.to_datetime(t['End of Week'], errors='coerce')\n",
    "            latest_eow = t['End of Week'].max().date()\n",
    "            t = t[t['End of Week'].dt.date == latest_eow]\n",
    "            t = t.sort_values('Value Sales',ascending=False).head(15)\n",
    "\n",
    "            # print(latest_eow)\n",
    "\n",
    "            output[k] = t\n",
    "             # missing_values = sectorPD[key][['Base Price/Unit', 'Base Price/KG']].isna().any()\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Price Point Slides clean \n",
    "def cleaningPricePoint(dfs,Inscope):\n",
    "    output={}\n",
    "    for k in dfs.keys():\n",
    "        t = dfs[k].copy()\n",
    "        # t=DetectHeader(t)\n",
    "        t = t[(t['Total Size'].notna()) | (t[Inscope].str.contains(\"Total\"))]\n",
    "        t[Inscope] = t[Inscope].ffill()\n",
    "        t['Value Sales'] = t['Value Sales'].fillna(0)\n",
    "        t = t[t['Value Sales']>1000]\n",
    "        t = t.sort_values('Value Sales',ascending = False)\n",
    "        dfTotal = t[t[Inscope].str.contains('Total')]\n",
    "        dfTotal=dfTotal.sort_values(['Value Sales'],ascending=False)\n",
    "        dfTotal['Sort_Value']=range(1,dfTotal.shape[0]+1)\n",
    "        dfTotal[Inscope]=dfTotal[Inscope].str.replace(' Total','')\n",
    "        t = t[~t[Inscope].str.contains('Total')].head(15)\n",
    "        t=t.merge(dfTotal[[Inscope,'Sort_Value']]).sort_values(['Sort_Value','Value Sales'],ascending=[True,False])\n",
    "        t=t.dropna(subset=['Base Price/Unit', 'Base Price/KG'])\n",
    "        if not t.empty:\n",
    "            output[k] = t             # missing_values = sectorPD[key][['Base Price/Unit', 'Base Price/KG']].isna().any()\n",
    "    return output           \n",
    "def clean_P12M(data,slideby=\"\"):\n",
    "    modified_price_point_by_brands_items_P12M = {}\n",
    "    final ={}\n",
    "    for key in data.keys():\n",
    "        df = data[key]\n",
    "        # df=DetectHeader(df)\n",
    "        df[slideby] = df[slideby].ffill()\n",
    "        df = df[~df[slideby].str.contains('Total')]\n",
    "        df = df.reset_index(drop =True)\n",
    "        if df.shape[0] >0:\n",
    "            modified_price_point_by_brands_items_P12M[key] = df\n",
    "    for key, df in modified_price_point_by_brands_items_P12M.items():\n",
    "        for client in df[slideby].unique():\n",
    "            if client in df[slideby].unique():\n",
    "                new_key = key + ' | ' + client\n",
    "                if df.shape[0] > 0:\n",
    "                    final[new_key] = df\n",
    "                    \n",
    "    return final\n",
    "def clean_P3M(data,slideby=\"\"):\n",
    "    cleaned_data = {}\n",
    "    final ={}\n",
    "    for key in data.keys():\n",
    "        df = data[key]\n",
    "        # df=DetectHeader(df)\n",
    "        df[slideby] = df[slideby].ffill()\n",
    "        df=df[df[\"Value Sales\"]>1000]\n",
    "        if df.shape[0] >0:\n",
    "            cleaned_data[key] = df\n",
    "            \n",
    "    for key, df in cleaned_data.items():\n",
    "        total_entries = df[(df[slideby].str.contains(' Total')) & ~(df[slideby].isin(['Grand Total',\"All Others Total\"])) & ~(df[slideby].isin([i+' Total' for i in client_brands]))]\n",
    "        total_entries['Value Share'] = total_entries['Value Share'].astype(float)\n",
    "        total_entries = total_entries.nlargest(3,columns=\"Value Share\")    \n",
    "        comp_lis = list(total_entries[slideby].str.replace(\" Total\",''))\n",
    "        if slideby==f\"{BrandOrTopB}\":\n",
    "            for client in client_brands:\n",
    "                if client in df[f\"{BrandOrTopB}\"].unique():\n",
    "                    df = df[~df[f\"{BrandOrTopB}\"].isin(['Grand Total',\"All Others Total\"])]\n",
    "                    df = df[~df[f\"{BrandOrTopB}\"].str.contains('Total')]\n",
    "                    df[f'{prodORitem}'] = df[f'{prodORitem}'].astype(str)\n",
    "\n",
    "            \n",
    "                    df = df[~df[f'{prodORitem}'].str.contains('Total')]\n",
    "                    \n",
    "                    df['Base Price/Unit'] = df['Base Price/Unit'].fillna(0)\n",
    "                    df['Base Price/KG'] = df['Base Price/KG'].fillna(0)\n",
    "                    df = df.reset_index(drop =True)\n",
    "                    \n",
    "                    comp_sorted = df[\n",
    "                        (~df[f\"{BrandOrTopB}\"].isin(client_brands)) & \n",
    "                        (df[f\"{BrandOrTopB}\"].isin(comp_lis))\n",
    "                    ].sort_values(by=\"Value Share\", ascending=False)\n",
    "                    top_5_comp = comp_sorted.groupby(f\"{BrandOrTopB}\", group_keys=False).apply(lambda x: x.sort_values(by='Value Share', ascending=False).head(5)).reset_index(drop = True)\n",
    "                    \n",
    "                    client_sorted = df[df[f\"{BrandOrTopB}\"]==client].sort_values(by =\"Value Share\", ascending = False)\n",
    "                    top_5_client = client_sorted.reset_index(drop=True).head(5)\n",
    "                    merged = pd.concat([top_5_client, top_5_comp], ignore_index=True)\n",
    "                    new_key = key + ' | ' + client\n",
    "                    if merged.shape[0] > 0:\n",
    "                            final[new_key] = merged\n",
    "        else:\n",
    "            for manuf in client_manuf:\n",
    "                if manuf in df[slideby].unique():\n",
    "                    df = df[~df[slideby].isin(['Grand Total',\"All Others Total\"])]\n",
    "                    df = df[~df[slideby].str.contains('Total')]\n",
    "                    df[f'{prodORitem}'] = df[f'{prodORitem}'].astype(str)\n",
    "\n",
    "                    df = df[~df[f'{prodORitem}'].str.contains('Total')]\n",
    "                    \n",
    "                    df['Base Price/Unit'] = df['Base Price/Unit'].fillna(0)\n",
    "                    df['Base Price/KG'] = df['Base Price/KG'].fillna(0)\n",
    "                    df = df.reset_index(drop =True)\n",
    "                    \n",
    "                    comp_sorted = df[\n",
    "                        (~df[slideby].isin(client_brands)) & \n",
    "                        (df[slideby].isin(comp_lis))\n",
    "                    ].sort_values(by=\"Value Share\", ascending=False)\n",
    "                    top_5_comp = comp_sorted.groupby(slideby, group_keys=False).apply(lambda x: x.sort_values(by='Value Share', ascending=False).head(5)).reset_index(drop = True)\n",
    "                    \n",
    "                    client_sorted = df[df[slideby]==manuf].sort_values(by =\"Value Share\", ascending = False)\n",
    "                    top_5_client = client_sorted.reset_index(drop=True).head(5)\n",
    "                    merged = pd.concat([top_5_client, top_5_comp], ignore_index=True)\n",
    "                    new_key = key + ' | ' + manuf\n",
    "                    if merged.shape[0] > 0:\n",
    "                            final[new_key] = merged\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af26424",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cleaning Price Distribution By Brand\n",
    "def brandPriceDistributionCleaning(dfs,brandInScope=['Kerrygold']):\n",
    "    brandPriceDistribution={}\n",
    "    for key in dfs.keys():\n",
    "        brandPriceDistributionCopy = dfs[key].copy()\n",
    "        # brandPriceDistributionCopy=DetectHeader(brandPriceDistributionCopy)\n",
    "        brandPriceDistributionCopy[f\"{BrandOrTopB}\"]=brandPriceDistributionCopy[f\"{BrandOrTopB}\"].ffill()\n",
    "        brandPriceDistributionCopy['Value Share']=brandPriceDistributionCopy['Value Share'].astype(float)\n",
    "        clientDfTotal = brandPriceDistributionCopy[brandPriceDistributionCopy[f\"{BrandOrTopB}\"].isin(i + ' Total' for i in brandInScope)].sort_values(['Value Share'],ascending=False)\n",
    "        clientDfTotal[f\"{BrandOrTopB}\"] = clientDfTotal[f\"{BrandOrTopB}\"].str.replace(' Total','')\n",
    "        clientDf = brandPriceDistributionCopy[brandPriceDistributionCopy[f\"{BrandOrTopB}\"].isin(brandInScope)]\n",
    "        brandPriceDistributionCopy=brandPriceDistributionCopy[brandPriceDistributionCopy['Value Share']>=0.005]\n",
    "        if len(brandInScope)==0:\n",
    "           brandPriceDistributionCopy=brandPriceDistributionCopy[brandPriceDistributionCopy['Value Share']>=0.01]\n",
    "        brandPriceDistributionCopy= pd.concat([brandPriceDistributionCopy, clientDf]).drop_duplicates()        \n",
    "        # Sort the brands on the Total Value Share \n",
    "        dfTotal=brandPriceDistributionCopy[brandPriceDistributionCopy[f\"{BrandOrTopB}\"].str.contains('Total')].sort_values(['Value Share'],ascending=False)\n",
    "        dfTotal[f\"{BrandOrTopB}\"]=dfTotal[f\"{BrandOrTopB}\"].str.replace(' Total','')\n",
    "        dfTotal=dfTotal[~dfTotal[f\"{BrandOrTopB}\"].isin(['Other'] + brandInScope)] # Drop The brand named 'Other'\n",
    "        num_res = 10 - clientDfTotal[f\"{BrandOrTopB}\"].nunique()\n",
    "        dfTotal = pd.concat([dfTotal.iloc[:num_res],clientDfTotal]).sort_values(['Value Share'], ascending=False)\n",
    "        dfTotal['Sort_Value']=range(1,dfTotal.shape[0]+1)\n",
    "        brandPriceDistributionCopy=brandPriceDistributionCopy[~brandPriceDistributionCopy[f\"{BrandOrTopB}\"].str.contains(' Total')]#drop total after sort\n",
    "        brandPriceDistributionCopy=brandPriceDistributionCopy.merge(dfTotal[[f\"{BrandOrTopB}\",'Sort_Value']]).sort_values('Sort_Value')        \n",
    "        # filling the missing pack size for each brand for drawing the chart\n",
    "        unique_size=brandPriceDistributionCopy['Pack Size'].unique()\n",
    "        missing_brand_size={}\n",
    "        for brand in brandPriceDistributionCopy[f\"{BrandOrTopB}\"]:\n",
    "            missingSizes=list(set(unique_size)-set(brandPriceDistributionCopy[brandPriceDistributionCopy[f\"{BrandOrTopB}\"]==brand]['Pack Size'].unique()))\n",
    "            if missingSizes:\n",
    "                missing_brand_size[brand]=missingSizes\n",
    "        missing_brand_size=pd.DataFrame({f\"{BrandOrTopB}\":missing_brand_size.keys(),'Pack Size':missing_brand_size.values()}).explode('Pack Size')\n",
    "        brandPriceDistributionCopy=pd.concat([brandPriceDistributionCopy,missing_brand_size])\n",
    "        brandPriceDistributionCopy['Pack Size No']=brandPriceDistributionCopy['Pack Size'].str.replace('GR','').str.replace('OZ','')\n",
    "        brandPriceDistributionCopy['Is_Client'] = brandPriceDistributionCopy[f\"{BrandOrTopB}\"].isin(client_brands)\n",
    "        brandPriceDistributionCopy=brandPriceDistributionCopy.drop(columns='Sort_Value').merge(dfTotal[[f\"{BrandOrTopB}\",'Sort_Value']]).sort_values(['Is_Client','Sort_Value','Pack Size No'],ascending=[False,True,True])\n",
    "        brandPriceDistributionCopy=brandPriceDistributionCopy.fillna(0)\n",
    "        brandPriceDistributionCopy= brandPriceDistributionCopy.reset_index() \n",
    "        brandPriceDistribution[key]=brandPriceDistributionCopy\n",
    "    return brandPriceDistribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cleaning Price Distribution By Brand by Sec/Seg/SubSeg/SUbCat\n",
    "def segmentPriceDistributionCleaning(brandPriceDistributiontest,brandInScope=['Kerrygold'],sec_seg='Segment',sec_seg_InScope = []):\n",
    "    brandPriceDistributionfinal={}\n",
    "    for key in brandPriceDistributiontest.keys():\n",
    "        brandPriceDistribution=brandPriceDistributiontest[key].copy()\n",
    "        # brandPriceDistribution[key]=DetectHeader(brandPriceDistribution[key])\n",
    "        brandPriceDistribution[f\"{BrandOrTopB}\"] = brandPriceDistribution[f\"{BrandOrTopB}\"].ffill()\n",
    "        brandPriceDistribution[sec_seg] = np.where(brandPriceDistribution[f\"{BrandOrTopB}\"].str.contains(' Total'), brandPriceDistribution[f\"{BrandOrTopB}\"], brandPriceDistribution[sec_seg])\n",
    "        brandPriceDistribution[sec_seg] = brandPriceDistribution[sec_seg].ffill()\n",
    "        brandPriceDistribution[f\"{BrandOrTopB}\"]=brandPriceDistribution[f\"{BrandOrTopB}\"].ffill()\n",
    "        # brandPriceDistribution['Value Share']=brandPriceDistribution['Value Share'].astype(float)\n",
    "        clientDf = brandPriceDistribution[brandPriceDistribution[f\"{BrandOrTopB}\"].isin(i + ' Total' for i in brandInScope)]\n",
    "        clientDf = clientDf.sort_values(\"Value Share\", ascending=False)\n",
    "        clientDf[f\"{BrandOrTopB}\"] = clientDf[f\"{BrandOrTopB}\"].str.replace(\" Total\", \"\")\n",
    "        # Exclude Brands with < 0.5% Market Share\n",
    "        brandPriceDistribution=brandPriceDistribution[(brandPriceDistribution['Value Share']>=.005)]\n",
    "        # Sort the brands on the Total Value Share\n",
    "        dfTotal=brandPriceDistribution[brandPriceDistribution[f\"{BrandOrTopB}\"].str.contains('Total')].sort_values(['Value Share'],ascending=False)\n",
    "        dfTotal[f\"{BrandOrTopB}\"]=dfTotal[f\"{BrandOrTopB}\"].str.replace(' Total','')\n",
    "        dfTotal=dfTotal[dfTotal[f\"{BrandOrTopB}\"]!='Other'] # Drop The brand named 'Other'\n",
    "        dfTotal=dfTotal.iloc[:5,:]\n",
    "        missingBrand = list(set(clientDf[f\"{BrandOrTopB}\"].unique())-set(dfTotal[f\"{BrandOrTopB}\"].unique()))\n",
    "        if missingBrand:\n",
    "            existBrand = dfTotal[dfTotal[f\"{BrandOrTopB}\"].isin(brandInScope)]\n",
    "            topBrandsWithoutClient=dfTotal[~dfTotal[f\"{BrandOrTopB}\"].isin(brandInScope)]\n",
    "            dfTotal = pd.concat([topBrandsWithoutClient.iloc[:topBrandsWithoutClient.shape[0] - len(missingBrand)],clientDf[clientDf[f\"{BrandOrTopB}\"].isin(missingBrand)],existBrand]).sort_values(['Value Share'],ascending=False)\n",
    "        else:\n",
    "            pass\n",
    "        dfTotal['Sort_Value_brands'] = range(1,dfTotal.shape[0]+1)\n",
    "        brandPriceDistribution = brandPriceDistribution[~brandPriceDistribution[f\"{BrandOrTopB}\"].str.contains(' Total')]#drop total after sort\n",
    "        dfTotalSegment = brandPriceDistribution[brandPriceDistribution[sec_seg].str.contains('Total')]#.sort_values(['Value Share'],ascending=False)\n",
    "        dfTotalSegment = dfTotalSegment[dfTotalSegment[f\"{BrandOrTopB}\"].isin(dfTotal[f\"{BrandOrTopB}\"].unique())]\n",
    "        segmentDf=[]\n",
    "        for brand in dfTotalSegment[f\"{BrandOrTopB}\"].unique():\n",
    "            segmentDfPerBrand=dfTotalSegment[dfTotalSegment[f\"{BrandOrTopB}\"]==brand].sort_values(['Value Share'],ascending=False)\n",
    "            segmentDfPerBrand['Sort_Value_'+sec_seg]=range(1,segmentDfPerBrand.shape[0]+1)\n",
    "            segmentDfPerBrand[sec_seg]=segmentDfPerBrand[sec_seg].str.replace(' Total','')\n",
    "            unique_size=brandPriceDistribution['Pack Size'].unique()\n",
    "            eachBrandDf=brandPriceDistribution[brandPriceDistribution[f\"{BrandOrTopB}\"]==brand]\n",
    "            eachBrandDf=eachBrandDf[~eachBrandDf[sec_seg].str.contains('Total')]\n",
    "            missing_brand_size={}\n",
    "            for segment in eachBrandDf[sec_seg].unique():\n",
    "                missingSizes=list(set(unique_size)-set(eachBrandDf[eachBrandDf[sec_seg]==segment]['Pack Size'].unique()))\n",
    "                missing_brand_size[segment] = missingSizes\n",
    "            missing_brand_size=pd.DataFrame({f\"{BrandOrTopB}\":brand,sec_seg:missing_brand_size.keys(),'Pack Size':missing_brand_size.values()}).explode('Pack Size')\n",
    "            brandPriceDistribution=pd.concat([brandPriceDistribution,missing_brand_size])#.sort_values(by=[sec_seg]).replace(np.nan,'0')\n",
    "            brandPriceDistribution['Pack Size No']=brandPriceDistribution['Pack Size'].str.replace('GR','').str.replace('OZ','')\n",
    "            segmentDf.append(segmentDfPerBrand)\n",
    "        if segmentDf:    \n",
    "            segmentDf=pd.concat(segmentDf)\n",
    "            brandPriceDistribution=brandPriceDistribution.merge(dfTotal[[f\"{BrandOrTopB}\",'Sort_Value_brands']])#.sort_values(['Sort_Value_brands','Sort_Value_Segment','Pack Size No'])\n",
    "            brandPriceDistribution=brandPriceDistribution.merge(segmentDf[[f\"{BrandOrTopB}\",sec_seg,'Sort_Value_'+sec_seg]],on=[f\"{BrandOrTopB}\",sec_seg]).sort_values(['Sort_Value_brands','Sort_Value_'+sec_seg,'Pack Size No'])\n",
    "        brandPriceDistribution=brandPriceDistribution[brandPriceDistribution['Pack Size'].notna()]\n",
    "        brandPriceDistribution=brandPriceDistribution.fillna(0)\n",
    "        brandPriceDistributionfinal[key]=brandPriceDistribution[brandPriceDistribution[sec_seg].isin(sec_seg_InScope)]\n",
    "    return brandPriceDistributionfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fcadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Correlation slide clean\n",
    "def clean_data(price_correlation_data,p3y=False):\n",
    "    cleaned_data = {}\n",
    "    final ={}\n",
    "    for key in price_correlation_data:\n",
    "        df = price_correlation_data[key].copy()\n",
    "        # df=DetectHeader(df)\n",
    "        df[f\"{BrandOrTopB}\"] = df[f\"{BrandOrTopB}\"].fillna(method='ffill')\n",
    "        df = df[~df[f\"{BrandOrTopB}\"].str.contains(\"All Others\", na=False)]\n",
    "        df.fillna(0,inplace = True)\n",
    "        if p3y==True:\n",
    "            df['QuarterStart'] = df['QuarterStart'].astype(str)\n",
    "            # Apply the filter to exclude rows where 'QuarterStart' contains 'Total'\n",
    "            df = df[~df['QuarterStart'].str.contains('Total', case=False, na=False)]\n",
    "        if df.shape[0] > 0: \n",
    "            cleaned_data[key] = df\n",
    "    for key, df in cleaned_data.items():\n",
    "        for client in client_brands:\n",
    "            if client in df[f\"{BrandOrTopB}\"].unique():\n",
    "                total_sorted = df[df[f\"{BrandOrTopB}\"].str.contains('total', case=False)]\n",
    "                total_sorted[f\"{BrandOrTopB}\"] = total_sorted[f\"{BrandOrTopB}\"].str.replace(' Total', '', regex=False)\n",
    "                total_sorted = total_sorted[~total_sorted[f\"{BrandOrTopB}\"].isin(client_brands+['Grand'])].sort_values(by =\"Value Share\", ascending = False)\n",
    "                top_3 = total_sorted.reset_index(drop=True).head(3)\n",
    "                top_3[f\"{BrandOrTopB}\"] = top_3[f\"{BrandOrTopB}\"].str.replace(' Total', '', regex=False)\n",
    "                top_3_brands = top_3[f\"{BrandOrTopB}\"]\n",
    "                for i in top_3_brands:\n",
    "                    client_df = df[df[f\"{BrandOrTopB}\"]== client].reset_index(drop= True)\n",
    "                    comp_df = df[df[f\"{BrandOrTopB}\"]== i].reset_index(drop= True)\n",
    "                    merged_df = pd.merge(client_df, comp_df, on='End of Week', suffixes=('_client', '_comp'))\n",
    "                    merged_df['Av Price/KG_comp'] = merged_df['Av Price/KG_comp'].replace(0,np.nan)\n",
    "                    merged_df['Price lx vs PL'] = merged_df['Av Price/KG_client'] / merged_df['Av Price/KG_comp']\n",
    "                    new_key = key + ' | ' + client + ' | ' + i\n",
    "                    if merged_df.shape[0] > 0:\n",
    "                        final[new_key] = merged_df\n",
    "    \n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r_squared(modified_price, modified_price_p12m):\n",
    "    r_squared_dict = {}\n",
    "    filtered_modified_price = {}\n",
    " \n",
    "    for key, df in modified_price.items():\n",
    "        df.fillna(0, inplace=True)\n",
    "        r2chart1, r2chart2 = None, None\n",
    " \n",
    "        # --- Chart 1 ---\n",
    "        if 'Price lx vs PL' in df.columns and 'Volume Share_client' in df.columns:\n",
    "            df12m = modified_price_p12m.get(key)\n",
    "            if df12m is not None:\n",
    "                df12m.fillna(0, inplace=True)\n",
    "                x_vals1 = df12m['Price lx vs PL'].tolist()\n",
    "                y_vals1 = df12m['Volume Share_client'].tolist()\n",
    " \n",
    "                if len(x_vals1) > 1 and len(y_vals1) > 1:\n",
    "                    slope, intercept = np.polyfit(x_vals1, y_vals1, 1)\n",
    "                    y_hat = [slope * x + intercept for x in x_vals1]\n",
    "                    ss_res = sum((y - y_h) ** 2 for y, y_h in zip(y_vals1, y_hat))\n",
    "                    ss_tot = sum((y - np.mean(y_vals1)) ** 2 for y in y_vals1)\n",
    "                    r2chart1 = 1 - ss_res / ss_tot if ss_tot != 0 else 0\n",
    " \n",
    "        # --- Chart 2 ---\n",
    "        if key in modified_price_p12m:\n",
    "            df12m = modified_price_p12m[key]\n",
    "            df12m.fillna(0, inplace=True)\n",
    " \n",
    "            if 'Av Price/KG_client' in df12m.columns and 'Volume Share_client' in df12m.columns:\n",
    "                x_vals2 = df12m['Av Price/KG_client'].tolist()\n",
    "                y_vals2 = df12m['Volume Share_client'].tolist()\n",
    " \n",
    "                if len(x_vals2) > 1 and len(y_vals2) > 1:\n",
    "                    slope2, intercept2 = np.polyfit(x_vals2, y_vals2, 1)\n",
    "                    y_hat2 = [slope2 * x + intercept2 for x in x_vals2]\n",
    "                    ss_res2 = sum((y - y_h) ** 2 for y, y_h in zip(y_vals2, y_hat2))\n",
    "                    ss_tot2 = sum((y - np.mean(y_vals2)) ** 2 for y in y_vals2)\n",
    "                    r2chart2 = 1 - ss_res2 / ss_tot2 if ss_tot2 != 0 else 0\n",
    " \n",
    "        r_squared_dict[key] = {\"chart1\": r2chart1, \"chart2\": r2chart2}\n",
    " \n",
    "        if (r2chart1 is not None and r2chart1 >= 0.5) or (r2chart2 is not None and r2chart2 >= 0.5):\n",
    "            filtered_modified_price[key] = df\n",
    " \n",
    "    return filtered_modified_price, r_squared_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad85f2d",
   "metadata": {},
   "source": [
    "## Summary slide Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575de053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(dic, col=\" \"):\n",
    "    outputdic = {}\n",
    "\n",
    "    for k, df in dic.items():\n",
    "        df = dic[k].copy()\n",
    "        # df = DetectHeader(df)\n",
    "        df[df.columns[0]] = df[df.columns[0]].ffill()\n",
    "        if 'Value Share' not in df.columns or col not in df.columns:\n",
    "            continue  # Skip if required columns are missing\n",
    "        df['Value Share'] = pd.to_numeric(df['Value Share'], errors='coerce')\n",
    "        df = df[df[col] != \"Grand Total\"]\n",
    "        df = df[df[df.columns[0]] != \"Grand Total\"]\n",
    "        df = df[~df[df.columns[0]].str.contains(\"Total\", na=False)]\n",
    "        # df = df[df[df.columns[0]].isin(seclis)]\n",
    "        df[col] = df[col].astype(str)\n",
    "        df = df[~df[col].str.contains(\"Other|Others|Other Manufacturer|All Others\", na=False, case=False)]\n",
    "        # if seclis==sectors:\n",
    "        #      outputdic[f'{categories[0]} | '+k] = df\n",
    "        # else:\n",
    "        outputdic[k] = df\n",
    "    sorted_dic_position = dfSort(outputdic, client_brands, col, num=9, salesCol='Value Share')\n",
    "    remove_others_from_dic(sorted_dic_position, col)\n",
    "    dropemptydf(sorted_dic_position)\n",
    "\n",
    "    return sorted_dic_position\n",
    "def group_by_key(dic, lis):\n",
    "    grouped_data = {}\n",
    "    catdf={}\n",
    "    for k in dic:\n",
    "        df=dic[k].copy()\n",
    "        parts = k.split(\"|\")\n",
    "        if lis is categories:\n",
    "            key_part1, key_part2 = parts[1].strip(), parts[0].strip()\n",
    "        else:\n",
    "           key_part1, key_part2 = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "        if key_part2 in lis:\n",
    "            if key_part1 not in grouped_data:\n",
    "                grouped_data[key_part1] = []\n",
    "            grouped_data[key_part1].append(k)\n",
    "            if lis is categories:\n",
    "              catdf[key_part2+\" | \"+key_part1]=df\n",
    "            else:\n",
    "                catdf[key_part1+\" | \"+key_part2]=df\n",
    "    \n",
    "    return list(grouped_data.values()),catdf\n",
    "\n",
    "def indexlist(grouplis):\n",
    "    final_lis1 = []\n",
    "    cat_lis = []\n",
    "    for i in range(len(grouplis)):\n",
    "        cat_lis += genrateIndexList(grouplis[i], chartIndex=10, chartCount=4)[0]\n",
    "    final_lis1.append(cat_lis)\n",
    "    \n",
    "    return final_lis1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
