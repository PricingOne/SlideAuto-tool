{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f15def",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'C:\\\\Users\\\\Ali Salem\\\\Desktop\\\\App_Update\\\\static/files\\\\parameters.xlsx'\n",
    "slides_name = ['Top 20 promotions', 'Top 20 promotions CLIENT ONLY', 'Promo sales per retailer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a454f5-c4e1-460c-a27d-40aa00dfcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "%run \"{os.getcwd()}\\Promotion Replacement Function.ipynb\" #container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999d128",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f3a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali Salem\\Desktop\\App_Update\\parameters.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'parameters.xlsx'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the full path to the file\n",
    "f_path = os.path.join(current_dir, filename)\n",
    "print(f_path)\n",
    "#xls = pd.ExcelFile(f_path)\n",
    "parm = pd.read_excel(f_path, sheet_name='Promotion')\n",
    "fields = dict(zip(parm['Field'],parm['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa7607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "dataset_name = fields['f_name']\n",
    "f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "decimals = fields['decimals']\n",
    "sign = fields['sign']\n",
    "currency = fields['currency']\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "national=fields['national']\n",
    "customareas=fields['customareas']\n",
    "areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "\n",
    "regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "data_source=fields['data_source']\n",
    "years=list(set(fields['years'].split(','))-set(['']))\n",
    "start_date = fields['start_date']\n",
    "end_date=fields['end_date']\n",
    "\n",
    "ManufOrTopC = fields['ManufOrTopC']\n",
    "BrandOrTopB = fields['BrandOrTopB']\n",
    "prodORitem = fields['prodORitem']\n",
    "\n",
    "percent = fields['percent']\n",
    "percentstr=fields['percentstr']\n",
    "\n",
    "National=[\"NATIONAL\"]if national else []\n",
    "subcatg_parent = fields['subcatg_parent']\n",
    "subcatg_parent_list = segments\n",
    "promo_col = list(set(fields['promo_col'].split(','))-set(['']))\n",
    "selectedBrands = client_brands \n",
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN \n",
    "notInScope = []\n",
    "OpenEditData=fields['OpenEditData']\n",
    "normalized = fields['normalized']\n",
    "promo_type = fields['promo_type']\n",
    "display_share = fields['display_share']\n",
    "feature_share = fields['feature_share']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "defaults = ast.literal_eval(\"{\" + fields['defaults'] + \"}\")\n",
    "\n",
    "\n",
    "marketList = regions_RET + channels_RET + market_RET + regions_CHAN + channels_CHAN + market_CHAN + regions_CUST + channels_CUST + market_CUST\n",
    "categoryList=categories +sectors+segments+subsegments+subcategories\n",
    "# defaults = {\n",
    "#     'Manual Shave Men': 6.69,'Disposables': 7.98,\"System\" : 5.03,\"Razors\" : 2.80,\"Refills\" : 6.58\n",
    "# }\n",
    "diff_market_value = {\n",
    "}\n",
    "\n",
    "def totalsize (lis,defaultdic,diffmarketdic=[]):\n",
    "\n",
    "    max_total_size = {\n",
    "    f\"{category} | {market}\": diff_market_value.get(market.upper(), {}).get(category, defaults[category])\n",
    "    for market in lis\n",
    "    for category in defaults\n",
    "    }\n",
    "\n",
    "    return max_total_size  \n",
    "\n",
    "max_total_size=totalsize(marketList,defaults,diff_market_value)\n",
    "\n",
    "custom_colors = [\n",
    "    RGBColor(91, 159, 153),    # Darker teal\n",
    "    RGBColor(131, 199, 193),   # Brighter medium teal\n",
    "    RGBColor(168, 216, 212),   # Original light teal\n",
    "    RGBColor(198, 236, 232),   # Very light teal\n",
    "    RGBColor(111, 179, 173),\n",
    "    RGBColor(121, 189, 183)\n",
    "]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8ab5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_parent = {\"Sector\":\"Category\",\n",
    "                \"Segment\":\"Sector\",\n",
    "                \"SubSegment\":\"Segment\", \n",
    "                \"SubCategory\":\"Segment\"}\n",
    "Scope = {\n",
    "    \"Category\": categories,\n",
    "    \"Sector\": sectors,\n",
    "    \"Segment\": segments,\n",
    "    \"Subsegment\": subsegments,\n",
    "    \"Subcategory\": subcategories\n",
    "}\n",
    "suffixes = [\"Category\", \"Sector\", \"Segment\",'SubSegment', 'SubCategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd5a3",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461dc096-382d-4c3b-91c1-8610a7cd684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+\"/Promotion Datasets Test/\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e341f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c2b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionBrandsP12M = cleaningData(promotions_brands_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d32fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionBrandsP12M_total = cleaningdata_with_grand_total(promotions_brands_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad3da6e-fb47-4873-b875-bd146d89d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionProductsP12M = cleaningData(promotions_products_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5159e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionProductsP12M_updated = {}\n",
    "for key, df in modified_promotionProductsP12M.items():\n",
    "    df = df.copy()\n",
    "    df = df[df[f'{prodORitem}'] != '']\n",
    "    df = df[df['Promo Sales'] >= 10000]\n",
    "    df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "    if not df.empty:\n",
    "        modified_promotionProductsP12M_updated[key] = df\n",
    "modified_promotionProductsP12M_volumeuplift = modified_promotionProductsP12M_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40a1e66-80f4-4dd0-9af8-a1a4e1cdc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_promotionEndOfWeek = cleaningData(promotions_EndOfWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86f6a2a-90f7-40b1-8f9f-723f5578455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_valueUplift = cleaningData(value_uplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da7fc3d-461c-4a38-8ae2-8d19805e5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModifiedBrands = cleaning13New(promotions_brands_P12M,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ae1fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for each pivot call in a list of tuples:\n",
    "pivot_params = [\n",
    "    (Sector_client_VSOD, 'Top Brands', 'Sector_client_VSODNew'),\n",
    "    (Sector_manuf_VSOD, 'Top Companies', 'Sector_manuf_VSODNew'),\n",
    "    (Segment_client_VSOD, 'Top Brands', 'Segment_client_VSODNew'),\n",
    "    (Segment_manuf_VSOD, 'Top Companies', 'Segment_manuf_VSODNew'),\n",
    "    (SubSegment_client_VSOD, 'Top Brands', 'SubSegment_client_VSODNew'),\n",
    "    (SubSegment_manuf_VSOD, 'Top Companies', 'SubSegment_manuf_VSODNew'),\n",
    "    (SubCategory_client_VSOD, 'Top Brands', 'SubCategory_client_VSODNew'),\n",
    "    (SubCategory_manuf_VSOD, 'Top Companies', 'SubCategory_manuf_VSODNew')\n",
    "]\n",
    "\n",
    "# Prepare a dictionary to store results:\n",
    "pivot_results = {}\n",
    "\n",
    "for data_dict, pivot_col, result_name in pivot_params:\n",
    "    pivot_results[result_name] = dict_to_pivot_general(\n",
    "        data_dict=data_dict,\n",
    "        pivot_col=pivot_col,\n",
    "        value_col='VSOD',\n",
    "        aggfunc='sum',\n",
    "        fill_value=pd.NA\n",
    "    )\n",
    "\n",
    "# If you want to have these as separate variables in your workspace, you can unpack like:\n",
    "Sector_client_VSODNew = pivot_results['Sector_client_VSODNew']\n",
    "Sector_manuf_VSODNew = pivot_results['Sector_manuf_VSODNew']\n",
    "Segment_client_VSODNew = pivot_results['Segment_client_VSODNew']\n",
    "Segment_manuf_VSODNew = pivot_results['Segment_manuf_VSODNew']\n",
    "SubSegment_client_VSODNew = pivot_results['SubSegment_client_VSODNew']\n",
    "SubSegment_manuf_VSODNew = pivot_results['SubSegment_manuf_VSODNew']\n",
    "SubCategory_client_VSODNew = pivot_results['SubCategory_client_VSODNew']\n",
    "SubCategory_manuf_VSODNew = pivot_results['SubCategory_manuf_VSODNew']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d18ef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors) >0:\n",
    "    a = Sector_VSOD\n",
    "    if len(Sector_client_VSODNew) >0:\n",
    "        b = cleaningData(Sector_client_VSODNew)\n",
    "        sect_vsod_merged = merging(b,a, col=[direct_parent[\"Sector\"],'Sector'])\n",
    "    else:\n",
    "        sect_vsod_merged = a\n",
    "    c = cleaningData(Sector_manuf_VSODNew)  \n",
    "    for key in sect_vsod_merged:\n",
    "        merged_df = pd.merge(sect_vsod_merged[key], c[key], on=[direct_parent[\"Sector\"],'Sector'], how='left')\n",
    "        if merged_df.shape[0]>0:\n",
    "            sect_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(segments) >0:\n",
    "    a = Segment_VSOD\n",
    "    if len(Segment_client_VSODNew) > 0:\n",
    "        b = cleaningData(Segment_client_VSODNew)\n",
    "        seg_vsod_merged = merging(a,b, col=[direct_parent[\"Segment\"],'Segment'])\n",
    "    else:\n",
    "        seg_vsod_merged = a\n",
    "    \n",
    "    c = cleaningData(Segment_manuf_VSODNew)\n",
    "    for key in seg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(seg_vsod_merged[key], c[key], on=[direct_parent[\"Segment\"],'Segment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            seg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subsegments) >0:\n",
    "    a = SubSegment_VSOD\n",
    "    if len(SubSegment_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubSegment_client_VSODNew)\n",
    "        subseg_vsod_merged = merging(a,b, col=[direct_parent[\"SubSegment\"],'SubSegment'])\n",
    "    else:\n",
    "        subseg_vsod_merged = a\n",
    "    c = cleaningData(SubSegment_manuf_VSOD)\n",
    "    for key in subseg_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subseg_vsod_merged[key], c[key], on=[direct_parent[\"SubSegment\"],'SubSegment'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subseg_vsod_merged[key] = merged_df    \n",
    "\n",
    "if len(subcategories) >0:\n",
    "    a = SubCategory_VSOD\n",
    "    if len(SubCategory_client_VSODNew) > 0 :\n",
    "        b = cleaningData(SubCategory_client_VSODNew)\n",
    "        subcat_vsod_merged = merging(a,b, col=[direct_parent[\"SubCategory\"],'SubCategory'])\n",
    "    else:\n",
    "        subcat_vsod_merged = a\n",
    "    c = cleaningData(SubCategory_manuf_VSODNew)\n",
    "    for key in subcat_vsod_merged:\n",
    "        # Merge DataFrames based on 'Sector' column\n",
    "        merged_df = pd.merge(subcat_vsod_merged[key], c[key], on=[direct_parent[\"SubCategory\"],'SubCategory'], how='left')\n",
    "        merged_df = merged_df.fillna(0)\n",
    "        if merged_df.shape[0]>0:\n",
    "            subcat_vsod_merged[key] = merged_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e97a11db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n",
      "Skipping Equate: missing columns ['Equate']\n"
     ]
    }
   ],
   "source": [
    "client=client_brands+client_manuf\n",
    "if len(sectors)!=0:\n",
    "    sect_vsod_merged=splitkeys(sect_vsod_merged,categories,parent=direct_parent['Sector'],clientlist=client)\n",
    "if len(segments)!=0:\n",
    "    seg_vsod_merged=splitkeys(seg_vsod_merged,sectors,parent=direct_parent['Segment'],clientlist=client)\n",
    "if len(subsegments)!=0:\n",
    "    subseg_vsod_merged=splitkeys(subseg_vsod_merged,segments,parent=direct_parent['SubSegment'],clientlist=client)\n",
    "if len(subcategories)!=0:\n",
    "    subcat_vsod_merged=splitkeys(subcat_vsod_merged,segments,parent=direct_parent['SubCategory'],clientlist=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b271ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    #seg_vsod_count = seg_vsod_count * len(sectors) \n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    #subseg_vsod_count =subseg_vsod_count *len(segments)\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    #subcat_vsod_count = subcat_vsod_count * len(subsegments)\n",
    "    subcat_vsod_count = subcat_vsod_count\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd04ba3-5570-4ad4-8d61-252872480a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandSortedTotalFinal={}\n",
    "promotionsBrandSortedTotal=dfSort(modified_promotionBrandsP12M, client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in promotionsBrandSortedTotal.items():\n",
    "     df_client = selectClientBrands(promotionsBrandSortedTotal[key],'Top Brands', 'Promo Value')\n",
    "     number_of_brands_needed = max(6 - len(df_client),0)\n",
    "     df = df[~df['Top Brands'].isin(client_brands)]\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).head(number_of_brands_needed)\n",
    "     df = pd.concat([df, df_client], ignore_index=True)\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "        \n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     \n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66555e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandNOTSortedTotalFinal={}\n",
    "promotionsBrandNOTSortedTotalFinal=dfSort(modified_promotionBrandsP12M, client_brands, \"Top Brands\", num=8,salesCol='Promo Value')\n",
    "for key,df in modified_promotionBrandsP12M.items():\n",
    "     df = df.sort_values(by='Promo Value', ascending=False).reset_index(drop=True)\n",
    "     df = df[~df['Top Brands'].str.contains('Others', case=False)]\n",
    "     df = df[~df['Top Brands'].str.contains('Grand Total', case=False)]\n",
    "     df = df[df['Value Share'] > 0.01]\n",
    "     df['VSOD Evaluation vs YA'] = df['VSOD Evaluation vs YA'].astype(float)\n",
    "     df['Promo Value Uplift vs YA'] = df['Promo Value Uplift vs YA'].astype(float)\n",
    "     if df.shape[0] >0:\n",
    "          promotionsBrandNOTSortedTotalFinal[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75e0e42f-2500-4d43-9ed2-2b5ac567a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands_og = selectedBrands\n",
    "selectedBrands= selectedBrands + [\"Grand Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab470824-4116-42ea-b87c-150650a1d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsSelected={key:modified_promotionBrandsP12M_total[key][modified_promotionBrandsP12M_total[key]['Top Brands'].isin(selectedBrands)].sort_values(by='Promo Value',ascending=False) for key in modified_promotionBrandsP12M_total.keys()   if all(cat != key.split(' | ')[0] for cat in categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5deb8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in promotionsBrandsSelected:\n",
    "    grand_total_row = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] == 'Grand Total']\n",
    "    sorted_df = promotionsBrandsSelected[key].loc[promotionsBrandsSelected[key]['Top Brands'] != 'Grand Total']\n",
    "    promotionsBrandsSelected[key] = pd.concat([grand_total_row, sorted_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf5988c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBrands = selectedBrands_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d4a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including client brands\n",
    "promotionsNotBrandsSelected = {\n",
    "    key: modified_promotionBrandsP12M_total[key][\n",
    "        ~modified_promotionBrandsP12M_total[key]['Top Brands'].isin(selectedBrands)\n",
    "    ].sort_values(by='Value Share', ascending=False)\n",
    "    for key in modified_promotionBrandsP12M_total.keys()\n",
    "    if all(cat != key.split(' | ')[0] for cat in categories)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5825f852-d5a8-4717-863c-60bce7831474",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotionsBrandsWithMarket=concatAttribute(promotionsBrandsSelected,marketList)\n",
    "promotionsBrandsWithMarket = fillingMissingBrands(promotionsBrandsWithMarket)\n",
    "promotionsNotBrandsWithMarket=concatAttribute(promotionsNotBrandsSelected,marketList)\n",
    "promotionsNotBrandsWithMarket = fillingMissingBrands(promotionsNotBrandsWithMarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "762fb5e2-0b4d-442f-9531-040980af3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_market(data, Scope):\n",
    "    final = {}\n",
    "    for k,df in data.items():\n",
    "        for key, value in Scope.items():\n",
    "            df_market = df[df['SOURCE'].isin(value)]\n",
    "            df_market = df_market.reset_index(drop=True)\n",
    "            if df_market.shape[0] >0:\n",
    "                final[k + ' | ' + value[0]] = df_market\n",
    "    return final        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a003a6-6da6-495c-a2d9-a9b0af5a7a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newpromotionsBrandsWithMarket = split_market(promotionsBrandsWithMarket,Scope)\n",
    "newpromotionsNotBrandsWithMarket = split_market(promotionsNotBrandsWithMarket,Scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e045f79-110e-4cb8-b237-b514151b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatAttributeNew(sorted):\n",
    "    \"\"\"\n",
    "    Concatenate DataFrames from a sorted dictionary based on exact matches of categories, sectors, segments,\n",
    "    subsegments, and subcategories. Adds a 'SOURCE' column to each DataFrame indicating its market.\n",
    "\n",
    "    Parameters:\n",
    "    sorted (dict): Dictionary with keys like 'category | sector | segment | brand' and values as DataFrames.\n",
    "    categories, sectors, segments, subsegments, subcategories (list): Lists of strings to match exactly.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with matched group names as keys and concatenated DataFrames as values.\n",
    "    \"\"\"\n",
    "    # Combine all lists and preserve order without duplicates\n",
    "    lis = list(dict.fromkeys(categories + sectors + segments + subsegments + subcategories))\n",
    "\n",
    "    marketDic = defaultdict(list)\n",
    "    concatenatedDic = {}\n",
    "\n",
    "    for i in lis:\n",
    "        for key, df in sorted.items():\n",
    "            parts = key.split(' | ')\n",
    "            if i in parts:\n",
    "                # Determine market label\n",
    "        \n",
    "                market_label = parts[1]  # category\n",
    "\n",
    "                df = df.copy()  # Avoid modifying original\n",
    "                df['SOURCE'] = market_label\n",
    "                marketDic[i].append(df)\n",
    "\n",
    "        if marketDic[i]:\n",
    "            concatenatedDic[i] = pd.concat(marketDic[i], ignore_index=True)\n",
    "\n",
    "    return concatenatedDic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28e29be2-2f65-4603-8858-1087e008b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = concatAttributeNew(modified_promotionBrandsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b8c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_modified_promotionProductsP12M = filter_data(modified_promotionProductsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5316486-6b68-430c-963f-11df7ef98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20clientonly = filter_data_Top(modified_promotionProductsP12M)\n",
    "bottom20clientonly = filter_data_Bot(modified_promotionProductsP12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3e9198-c36a-4544-8a00-92a1e2ab89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotionsEndOfWeekCleaning(promotions_EndOfWeek, notInScope, col='Top Brands'):\n",
    "    promotionsEndOfWeek = {}\n",
    "    for key, value in promotions_EndOfWeek.items():\n",
    "        df = value.copy()\n",
    "        if df.shape[0] != 0:\n",
    "            modified_key = key\n",
    "            flag = False if any(element in modified_key for element in notInScope) else True\n",
    "            if flag:\n",
    "                promotionsEndOfWeek[modified_key] = df[df[col] != 'Grand Total'].reset_index(drop=True).replace(np.nan, 0)\n",
    "        else:\n",
    "            print(key, ' Is empty')\n",
    "    \n",
    "    return promotionsEndOfWeek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3bdd031-7086-48bc-b9b6-d9e09be82bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=cleaningData(promotions_EndOfWeek)\n",
    "promotionsEndOfWeekCleaned=promotionsEndOfWeekCleaning(mod,notInScope,col='End of Week')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e7408ac-109a-48e1-83ee-1f3acda454ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brandMarketCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in promotionsEndOfWeekCleaned.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33070cde-4b18-410c-bf87-00d132014a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates(dfList, promotionsEndOfWeekCleaned):\n",
    "    # Create a list of unique brand-category combinations\n",
    "    brandCatList = sorted(set(key.split(' | ')[0] + ' | ' + key.split(' | ')[1] for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]) and (key.split(' | ')[1] == name.split(' | ')[1]):\n",
    "                dic[key] += 1\n",
    "                \n",
    "    # Iterate over unique brand-category combinations\n",
    "    for name in dic.keys():\n",
    "        # Get dataframe keys associated with the current brand-category combination\n",
    "        dfName = [key for key in dfList if name == (key.split(' | ')[0] + ' | ' + key.split(' | ')[1])]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['End of Week']].drop_duplicates()\n",
    "        if uniqueDates.shape[0] > 0:\n",
    "            dfCompleteDates = {}\n",
    "            dfGroup.append(dfName)\n",
    "            for key in dfName:\n",
    "                EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left').replace(np.nan, 0).sort_values(by='End of Week').reset_index(drop = True)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26bde262-eab5-4afc-ab44-9c3658cb974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory,catGroup,catDuplication=completeDates(brandMarketCategory,promotionsEndOfWeekCleaned)\n",
    "if len(sectors) != 0:\n",
    "    dfSector,secGroup,secDuplication=completeDates(brandMarketSector,promotionsEndOfWeekCleaned)\n",
    "if len(segments) != 0:\n",
    "    dfSegment,segGroup,segDuplication=completeDates(brandMarketSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment,subsegGroup,subsegDuplication=completeDates(brandMarketSubSegment,promotionsEndOfWeekCleaned)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory,subcatGroup,subcatDuplication=completeDates(brandMarketSubCategory,promotionsEndOfWeekCleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4108f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors):\n",
    "    sect_vsod_count =0\n",
    "    for key,df in sect_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                sect_vsod_count +=1\n",
    "    sect_vsod_count = sect_vsod_count *len(categories)\n",
    " \n",
    "if len(segments):\n",
    "    seg_vsod_count =0\n",
    "    for key,df in seg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                seg_vsod_count +=1\n",
    "    seg_vsod_count = seg_vsod_count           \n",
    " \n",
    "if len(subsegments) >0:\n",
    "    subseg_vsod_count =0\n",
    "    for key,df in subseg_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subseg_vsod_count +=1\n",
    "    subseg_vsod_count = subseg_vsod_count\n",
    " \n",
    "if len(subcategories) >0:\n",
    "    subcat_vsod_count =0\n",
    "    for key,df in subcat_vsod_merged.items():\n",
    "        client_manuf_brands = client_brands + client_manuf\n",
    "        for client in client_manuf_brands:\n",
    "            if client in df.columns:\n",
    "                subcat_vsod_count +=1\n",
    "    subcat_vsod_count = subcat_vsod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43c6f94a-d00f-46ad-9011-678073e6bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoRet ={}\n",
    "if len(categories)!=0:\n",
    "    first_key, first_value = next(iter(catDuplication.items()))\n",
    "    PromoRet.update({first_key: first_value})\n",
    "if len(sectors)!=0:\n",
    "    sec_key, sec_value = next(iter(secDuplication.items()))\n",
    "    PromoRet.update({sec_key:sec_value})\n",
    "if len(segments)!=0:\n",
    "    third_key, third_value = next(iter(segDuplication.items()))\n",
    "    PromoRet.update({third_key: third_value})\n",
    "if len(subsegments)!=0:\n",
    "    fourth_key, fourth_value = next(iter(subsegDuplication.items()))\n",
    "    PromoRet.update({fourth_key:fourth_value})\n",
    "if len(subcategories)!=0:\n",
    "    fifth_key, fifth_value = next(iter(subcatDuplication.items()))\n",
    "    PromoRet.update({fifth_key:fifth_value })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a728a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromoSalesTypes_data = {}\n",
    "for key in brands_promo_type.keys():\n",
    "    df=brands_promo_type[key].copy()\n",
    "    df[\"Promo Sales\"] = pd.to_numeric(df[\"Promo Sales\"], errors=\"coerce\").fillna(0)\n",
    "    df[\"Value Share\"] = pd.to_numeric(df[\"Value Share\"], errors=\"coerce\").fillna(0)\n",
    "    df = df[df['Promo Type'].notna()]\n",
    "    brand_totals = df.groupby(\"Top Brands\")['Promo Sales'].sum()\n",
    "    df[\"Brand Total Sales\"] = df[\"Top Brands\"].map(brand_totals)\n",
    "    df[\"% Promo Sales\"] = df[\"Promo Sales\"] / df[\"Brand Total Sales\"]\n",
    "\n",
    "    df = df[~df['Top Brands'].str.contains('Others|Grand Total', case=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    df = df[df['Promo Sales'] > 0]\n",
    "    # Select client brands and additional brands needed to make 10 brands\n",
    "    df_client = selectClientBrands(brands_promo_type[key],'Top Brands', 'Value Share')\n",
    "    comp_brand = df[~df['Top Brands'].isin(cb for cb in client_brands)].drop_duplicates(\"Top Brands\")\n",
    "    if not df_client.empty:\n",
    "        comp_brand = comp_brand.nlargest(10-df_client[\"Top Brands\"].nunique(), \"Value Share\")[\"Top Brands\"].to_list()\n",
    "        # Concatenate client brands and additional brands\n",
    "        df = df[df[\"Top Brands\"].isin(comp_brand + client_brands)]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.sort_values(\"Value Share\", ascending=False).reset_index(drop=True)\n",
    "        df = df[~df['Promo Type'].fillna('').str.contains('NONE/PL|Undefined|Nan', na=False)]\n",
    "        # print(comp_brand)\n",
    "        if df.shape[0]:\n",
    "            PromoSalesTypes_data[key] =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88c1ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup)):\n",
    "        cat_lis += genrateIndexList(catGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(cat_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup)):\n",
    "        sec_lis += genrateIndexList(secGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(sec_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup)):\n",
    "        seg_lis += genrateIndexList(segGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subseg_lis)\n",
    "else:\n",
    "    final_lis.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup[i], chartIndex=14, chartCount=4)[0]\n",
    "    final_lis.append(subcat_lis)\n",
    "else:\n",
    "    final_lis.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4fa9",
   "metadata": {},
   "source": [
    "### New Slide 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db1737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year=MonthYear_clean(Category_MonthYear,column='Category')\n",
    "sector_month_year = MonthYear_clean(Sector_MonthYear,column='Sector')\n",
    "segment_month_year = MonthYear_clean(Segment_MonthYear,column='Segment')\n",
    "subcat_month_year = MonthYear_clean(SubCategory_MonthYear,column='SubCategory')\n",
    "subseg_month_year = MonthYear_clean(SubSegment_MonthYear,column='SubSegment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ac48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month_year(data, column):\n",
    "    final_month_year ={}\n",
    "    for key,df in data.items():\n",
    "        for sec in df[column].unique():\n",
    "            newkey = key + ' | ' + sec\n",
    "            new_df = df[df[column] == sec].reset_index(drop=True)\n",
    "            if new_df.shape[0] > 0:\n",
    "                final_month_year[newkey] = new_df\n",
    "    return final_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "265d60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_month_year1=split_month_year(category_month_year,'Category')\n",
    "sector_month_year1 = split_month_year(sector_month_year,'Sector')\n",
    "segment_month_year1 = split_month_year(segment_month_year,'Segment')\n",
    "subseg_month_year1 = split_month_year(subseg_month_year,'SubSegment')\n",
    "subcat_month_year1 = split_month_year(subcat_month_year,'SubCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b92a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year1 = {}\n",
    "month_year1.update(sector_month_year1)\n",
    "month_year1.update(segment_month_year1)\n",
    "month_year1.update(subcat_month_year1)\n",
    "month_year1.update(subseg_month_year1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a94833af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory = [key for key in category_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in sector_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in segment_month_year1.keys() if any(cat == key.split(' | ')[2]  for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in subseg_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in subcat_month_year1.keys() if any(cat == key.split(' | ')[2] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17cb72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeDates1(dfList, promotionsEndOfWeekCleaned,column=\"Sector\"):\n",
    "    brandCatList = sorted(set(key.split(' | ')[0]  for key in dfList))\n",
    "    EndOfWeekcompletDate = {}\n",
    "    dfGroup = []\n",
    "    dic = defaultdict(int)\n",
    "    for key in brandCatList:\n",
    "        for name in dfList:\n",
    "            if (key.split(' | ')[0] == name.split(' | ')[0]):\n",
    "                \n",
    "                dic[key] += 1\n",
    "    for name in dic.keys():\n",
    "\n",
    "        if column == \"Sector\" :\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0] and len(name.split(' | ')) == 1]\n",
    "        else:\n",
    "            dfName = [key for key in dfList if name == key.split(' | ')[0]  ]\n",
    "        uniqueDates = pd.concat([promotionsEndOfWeekCleaned[key] for key in dfName])[['MonthYear']].drop_duplicates()\n",
    "        dfCompleteDates = {}\n",
    "        dfGroup.append(dfName)\n",
    "        for key in dfName:\n",
    "            EndOfWeekcompletDate[key] = pd.merge(uniqueDates, promotionsEndOfWeekCleaned[key], how='left')#.replace(np.nan, 0)\n",
    "            column = EndOfWeekcompletDate[key].columns[1]\n",
    "            year = EndOfWeekcompletDate[key].columns[3]\n",
    "            monthyear = EndOfWeekcompletDate[key].columns[0]\n",
    "            EndOfWeekcompletDate[key][column] = EndOfWeekcompletDate[key][column].fillna(method='ffill')      \n",
    "            EndOfWeekcompletDate[key][year] = pd.to_datetime(EndOfWeekcompletDate[key][monthyear], format='%b-%y').dt.year\n",
    "            EndOfWeekcompletDate[key] = EndOfWeekcompletDate[key].fillna(0)\n",
    "    return EndOfWeekcompletDate, dfGroup, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b1814ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCategory0,categoryGroup0,categoryDuplication0=completeDates1(brandMarketCategory,category_month_year1,column=\"Category\")\n",
    "if len(sectors) != 0:\n",
    "    dfSector0,secGroup0,secDuplication0=completeDates1(brandMarketSector,sector_month_year1,column=\"Sector\")\n",
    "if len(segments) != 0:\n",
    "    dfSegment0,segGroup0,segDuplication0=completeDates1(brandMarketSegment,segment_month_year1,column=\"Segment\")\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment0,subsegGroup0,subsegDuplication0=completeDates1(brandMarketSubSegment,subseg_month_year1,column=\"Subsegment\")\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory0,subcatGroup0,subcatDuplication0=completeDates1(brandMarketSubCategory,subcat_month_year1,column=\"Subcategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55074d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryGroup0=groupingkeys(categoryGroup0)\n",
    "if len(sectors) != 0:\n",
    "    secGroup0=groupingkeys(secGroup0)\n",
    "if len(segments) != 0:\n",
    "    segGroup0=groupingkeys(segGroup0)\n",
    "if len(subsegments) != 0:\n",
    "    subsegGroup0=groupingkeys(subsegGroup0)\n",
    "if len(subcategories) != 0:\n",
    "    subcatGroup0=groupingkeys(subcatGroup0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94eb5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 20, 20], [21, 21, 21]]\n",
      "[[20, 20, 20], [21, 21, 21], [20, 20, 20, 21, 21, 21]]\n",
      "[[20, 20, 20], [21, 21, 21], [20, 20, 20, 21, 21, 21], []]\n"
     ]
    }
   ],
   "source": [
    "final_lis0 = []\n",
    "category_lis = []\n",
    "if categories:\n",
    "    for i in range(len(categoryGroup0)):\n",
    "        category_lis += genrateIndexList(categoryGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(category_lis)  # Append empty list if sectors is False\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup0)):\n",
    "        sec_lis += genrateIndexList(secGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(sec_lis)  # Append empty list if sectors is False\n",
    "print(final_lis0)\n",
    "\n",
    "seg_lis = []\n",
    "if segments:\n",
    "    for i in range(len(segGroup0)):\n",
    "        seg_lis += genrateIndexList(segGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(seg_lis)  # Append empty list if segments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subseg_lis = []\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup0)):\n",
    "        subseg_lis += genrateIndexList(subsegGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subseg_lis)  # Append empty list if subsegments is False\n",
    "print(final_lis0)\n",
    "\n",
    "subcat_lis = []\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup0)):\n",
    "        subcat_lis += genrateIndexList(subcatGroup0[i], chartIndex=19, chartCount=6)[0]\n",
    "final_lis0.append(subcat_lis)  # Append empty list if subcategories is False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc50143",
   "metadata": {},
   "source": [
    "### New slide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3653fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_endofweek_P12M = {}\n",
    "past_12_months = pd.date_range(end=end_date , periods=12, freq='M').strftime('%b-%y').tolist()\n",
    "for key in modified_promotionEndOfWeek.keys():\n",
    "    df=modified_promotionEndOfWeek[key].copy()\n",
    "    df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "    filtered_df = df[df['End of Week'].dt.strftime('%b-%y').isin(past_12_months)]\n",
    "    if filtered_df.shape[0] >0:\n",
    "        modified_endofweek_P12M[key] = filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06d18d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in modified_endofweek_P12M.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_endofweek_P12M.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ace0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,modified_endofweek_P12M)\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,modified_endofweek_P12M)\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,modified_endofweek_P12M)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,modified_endofweek_P12M)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,modified_endofweek_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8479ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promofrequencyclean(data):        \n",
    "        modified_dfCategory1 = {}\n",
    "        for k in data.keys():\n",
    "                chart_df=data[k].copy()\n",
    "                chart_df['Weekly VSOD'] = np.where((chart_df['VSOD']>.2)&(chart_df['Value Uplift (v. base) Normalized'] != ''),1,None)\n",
    "                chart_df['try'] = 0\n",
    "                chart_df['New Uplift'] = 0\n",
    "                chart_df['try'] = np.where((chart_df['Value Uplift (v. base) Normalized']>=2),1.8,chart_df['Value Uplift (v. base) Normalized'])\n",
    "                chart_df['New Uplift'] = np.where((chart_df['Weekly VSOD']==1)&(chart_df['Value Uplift (v. base) Normalized']>0.05),chart_df['try'],None)\n",
    "                if not chart_df['Weekly VSOD'].isnull().all():\n",
    "                        modified_dfCategory1[k]= chart_df \n",
    "        return modified_dfCategory1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ad97599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)!=0: \n",
    "    modified_dfCategory1=promofrequencyclean(dfCategory1)\n",
    "if len(sectors)!=0: \n",
    "    modified_dfSector1=promofrequencyclean(dfSector1)\n",
    "if len(segments)!=0: \n",
    "    modified_dfSegment1=promofrequencyclean(dfSegment1)\n",
    "if len(subsegments)!=0: \n",
    "    modified_dfSubSegment1=promofrequencyclean(dfSubSegment1)\n",
    "if len(subcategories)!=0: \n",
    "    modified_dfSubCategory1=promofrequencyclean(dfSubCategory1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f0aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandMarketCategory= [key for key in modified_dfCategory1.keys() if any(cat in key.split(' | ')[0] for cat in categories )]\n",
    "if len(sectors) != 0:\n",
    "    brandMarketSector = [key for key in modified_dfSector1.keys() if any(cat == key.split(' | ')[0] for cat in sectors )]\n",
    "if len(segments) != 0:\n",
    "    brandMarketSegment = [key for key in modified_dfSegment1.keys() if any(cat == key.split(' | ')[0] for cat in segments )]\n",
    "if len(subsegments) != 0:\n",
    "    brandMarketSubSegment = [key for key in modified_dfSubSegment1.keys() if any(cat == key.split(' | ')[0] for cat in subsegments )]\n",
    "if len(subcategories) != 0:\n",
    "    brandMarketSubCategory = [key for key in modified_dfSubCategory1.keys() if any(cat == key.split(' | ')[0] for cat in subcategories )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31f3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories) != 0:\n",
    "    dfCategory1,catGroup1,catDuplication1=completeDates(brandMarketCategory,modified_endofweek_P12M)\n",
    "if len(sectors) != 0:\n",
    "    dfSector1,secGroup1,secDuplication1=completeDates(brandMarketSector,modified_endofweek_P12M)\n",
    "if len(segments) != 0:\n",
    "    dfSegment1,segGroup1,segDuplication1=completeDates(brandMarketSegment,modified_endofweek_P12M)\n",
    "if len(subsegments) != 0:\n",
    "    dfSubSegment1,subsegGroup1,subsegDuplication1=completeDates(brandMarketSubSegment,modified_endofweek_P12M)\n",
    "if len(subcategories) != 0:\n",
    "    dfSubCategory1,subcatGroup1,subcatDuplication1=completeDates(brandMarketSubCategory,modified_endofweek_P12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2bbe9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_region(data):\n",
    "    # Define categories for grouping\n",
    "    market_groups = {\n",
    "        \"RETAILER_REGIONS\": regions_RET,\n",
    "        \"RETAILER_CHANNELS\": channels_RET,\n",
    "        \"RETAILER_MARKET\": market_RET,\n",
    "        \"CHANNEL_REGIONS\": regions_CHAN,\n",
    "        \"CHANNEL_CHANNELS\": channels_CHAN,\n",
    "        \"CHANNEL_MARKET\": market_CHAN,\n",
    "        f\"{customareas}_REGIONS\": regions_CUST,\n",
    "        f\"{customareas}_CHANNELS\": channels_CUST,\n",
    "        f\"{customareas}_MARKET\": market_CUST,\n",
    "    }\n",
    "    result = []\n",
    "    for sublist in data:\n",
    "        for category, keywords in market_groups.items():\n",
    "            # Filter items matching the current category\n",
    "            base_category = category.split(\"_\")[0]\n",
    "\n",
    "            group = [\n",
    "                f\"{item} | {base_category}\" for item in sublist if item.split(\" | \")[-1] in keywords\n",
    "            ]\n",
    "            if group:  # Append only non-empty groups\n",
    "                result.append(group)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "016f5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories)>0:\n",
    "    catGroup1 = group_by_region(catGroup1)\n",
    "if len(sectors)>0:\n",
    "    secGroup1 = group_by_region(secGroup1)\n",
    "if len(segments)>0:\n",
    "    segGroup1 = group_by_region(segGroup1)\n",
    "if len(subsegments)>0:\n",
    "    subsegGroup1 = group_by_region(subsegGroup1)\n",
    "if len(subcategories)>0:\n",
    "    subcatGroup1 = group_by_region(subcatGroup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95b943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lis1 = []\n",
    "cat_lis = []\n",
    "if categories:\n",
    "    for i in range(len(catGroup1)):\n",
    "        cat_lis += genrateIndexList(catGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(cat_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "sec_lis = []\n",
    "if sectors:\n",
    "    for i in range(len(secGroup1)):\n",
    "        sec_lis += genrateIndexList(secGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(sec_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "seg_lis=[]\n",
    "if segments:\n",
    "    for i in range(len(segGroup1)):\n",
    "        seg_lis += genrateIndexList(segGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(seg_lis)\n",
    "\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subseg_lis =[]\n",
    "if subsegments:\n",
    "    for i in range(len(subsegGroup1)):\n",
    "        subseg_lis +=  genrateIndexList(subsegGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subseg_lis)\n",
    "else:\n",
    "    final_lis1.append([])\n",
    "\n",
    "subcat_lis =[]\n",
    "if subcategories:\n",
    "    for i in range(len(subcatGroup1)):\n",
    "        subcat_lis +=  genrateIndexList(subcatGroup1[i], chartIndex=25, chartCount=4)[0]\n",
    "    final_lis1.append(subcat_lis)\n",
    "else:\n",
    "    final_lis1.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21faef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer=regions_RET+channels_RET+market_RET\n",
    "channels=regions_CHAN+channels_CHAN+channels_CHAN\n",
    "customarea=regions_CUST+channels_CUST+market_CUST\n",
    "def addarea(modified_dfCategory1,retailer,market=\"RETAILER\"):\n",
    "    keys_to_modify = [k for k in modified_dfCategory1.keys() if k.split(\" | \")[-1] in retailer]\n",
    "    for k in keys_to_modify:\n",
    "        new_key = k + \" | \"+ market\n",
    "        modified_dfCategory1[new_key] = modified_dfCategory1[k]  \n",
    "        del modified_dfCategory1[k]       \n",
    "    return modified_dfCategory1      \n",
    "if len(categories)>0:            \n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfCategory1=addarea(modified_dfCategory1,customarea,market=f\"{customareas}\")\n",
    "\n",
    "if len(sectors)>0:            \n",
    "    modified_dfSector1=addarea(modified_dfSector1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSector1=addarea(modified_dfSector1,customarea,market=f\"{customareas}\")\n",
    "if len(segments)>0:            \n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSegment1=addarea(modified_dfSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subsegments)>0:            \n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubSegment1=addarea(modified_dfSubSegment1,customarea,market=f\"{customareas}\")\n",
    "if len(subcategories)>0:            \n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,retailer,market=\"RETAILER\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,channels,market=\"CHANNELS\")\n",
    "    modified_dfSubCategory1=addarea(modified_dfSubCategory1,customarea,market=f\"{customareas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec5211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(modified_promotionBrandsP12M.keys()):  # Convert to list to avoid runtime errors\n",
    "    df = modified_promotionBrandsP12M[k].copy()\n",
    "    # Filter rows based on 'Top Brands'\n",
    "    df = df[~df['Top Brands'].str.contains('Others', case=False, na=False)]\n",
    "    df = df[~df['Top Brands'].str.contains('Grand Total', case=False, na=False)]\n",
    "    df = df[df['Value Share'] > 0.01]\n",
    "    if not df.empty:\n",
    "        modified_promotionBrandsP12M[k] = df\n",
    "    else:\n",
    "        del modified_promotionBrandsP12M[k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee2a74",
   "metadata": {},
   "source": [
    "\n",
    "## Slide duplication: index, duplication and section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ceca67f7-038d-44e1-98aa-cbc9a32d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [*[0]*5,\n",
    "         #*[1]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[3]*5,\n",
    "         *[4]*5,\n",
    "         *[5]*5,\n",
    "         *[6]*5,\n",
    "         *[7]*5,\n",
    "         *[8]*4,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "         *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5,\n",
    "         *[14]*5,\n",
    "         *final_lis,\n",
    "         *[19]*5,\n",
    "         *final_lis0,\n",
    "         *final_lis1,\n",
    "         *[0]*5,\n",
    "         *[1]*5,\n",
    "         *[2]*5,\n",
    "         *[9]*5,\n",
    "         *[10]*5,\n",
    "        #  *[11]*5,\n",
    "         *[12]*5,\n",
    "         *[13]*5\n",
    "         #*[14]*5\n",
    "        ]\n",
    "duplication = combine_duplications(Scope,count_df,[#modified_promotionBrandsP12M, #0\n",
    "                                                   promotionsBrandSortedTotalFinal, #1\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2\n",
    "                                                   concated, #3\n",
    "                                                   modified_promotionProductsP12M_volumeuplift, #4\n",
    "                                                   new_modified_promotionProductsP12M, #5\n",
    "                                                   new_modified_promotionProductsP12M, #6\n",
    "                                                   top20clientonly, #7\n",
    "                                                   bottom20clientonly,#8\n",
    "                                                   modified_promotionBrandsP12M, #10\n",
    "                                                   newModifiedBrands, #11\n",
    "                                                   PromoSalesTypes_data if promo_type else None,#12\n",
    "                                                   modified_promotionBrandsP12M if feature_share else None, #13\n",
    "                                                   modified_promotionBrandsP12M if display_share else None, #14\n",
    "                                                   modified_promotionEndOfWeek,#15\n",
    "                                                   PromoRet, #16-19\n",
    "                                                   modified_valueUplift, #20\n",
    "                                                   #month_year1,#21\n",
    "                                                   #modified_endofweek_P12M, #22\n",
    "                                                   #modified_promotionBrandsP12M, #0 with no client\n",
    "                                                   promotionsBrandNOTSortedTotalFinal, #1 with no client\n",
    "                                                   newpromotionsNotBrandsWithMarket, #2 with no client\n",
    "                                                   concated, #3 with no client\n",
    "                                                   modified_promotionBrandsP12M, # 10 with no client\n",
    "                                                   newModifiedBrands, #11 with no client\n",
    "                                                   #PromoSalesTypes_data if promo_type else None,#12  with no client\n",
    "                                                   modified_promotionBrandsP12M if feature_share else None, #13  with no client\n",
    "                                                   modified_promotionBrandsP12M if display_share else None #14 with no client\n",
    "                                                  ])\n",
    "section_names = [#\"Promo Value Sale\",#0\n",
    "                 \"Promo Evolution\", #1\n",
    "                 \"VSOD Summary by Sector\" , #2\n",
    "                 \"Value uplift by retailer by brand\", #3 \n",
    "                 \"Volume Uplift vs discount depth\",#4\n",
    "                 \"Value Uplift vs Promo Efficiency Quadrant\", #5\n",
    "                 \"Top 20 promotions\", #6\n",
    "                 \"Top 20 promotions CLIENT ONLY\", #7\n",
    "                 \"Bottom 20 promotions CLIENT ONLY\", #8\n",
    "                 \"Promo share vs Value Share\", #10\n",
    "                 \"Promo Sales by total size\",#11\n",
    "                 \"Promo Sales by promo type\", #12\n",
    "                 \"Feature Share vs Fair Share\", #13\n",
    "                 \"Display Share vs Fair Share\", #14\n",
    "                 \"Promo Frequency learnings\", #15\n",
    "                 \"Promo sales per retailer\", #16-19\n",
    "                 \"Value Uplift vs discount depth\" ,#20\n",
    "                 #\"Seasonality Index\",#21\n",
    "                 #\"Promotional Frequency Analysis\", #22\n",
    "                 #\"Promo Value Sale no client prio\",\n",
    "                 \"Promo Evolution no client prio\",\n",
    "                 \"VSOD Summary by Sector no client prio\",\n",
    "                 \"Value uplift by retailer by brand no client prio\",\n",
    "                \"Promo share vs Value Share no client prio\", #10\n",
    "                 \"Promo Sales by total size no client prio\",#11\n",
    "                 #\"Promo Sales by promo type no client prio\", #12\n",
    "                 \"Feature Share vs Fair Share no client prio\", #13\n",
    "                 \"Display Share vs Fair Share no client prio\" #14\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "#duplication.insert(89, 0)\n",
    "\n",
    "if len(sectors) > 0:\n",
    "       #duplication.insert(45,(len(client_manuf)+len(client_brands))*len(categories)* len(marketList))\n",
    "       duplication.insert(40, sect_vsod_count)\n",
    "if len(segments) > 0:\n",
    "        #duplication.insert(46,(len(client_manuf)+len(client_brands))*len(sectors)* len(marketList)) \n",
    "         duplication.insert(41, seg_vsod_count)\n",
    " \n",
    "else:\n",
    "    duplication.insert(41,0)  \n",
    "  \n",
    "if len(subsegments) > 0:\n",
    "        #duplication.insert(47,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(42, subseg_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(42,0)\n",
    "\n",
    "if len(subcategories) > 0:\n",
    "        #duplication.insert(48,(len(client_manuf)+len(client_brands))*len(segments)* len(marketList))\n",
    "        duplication.insert(43, subcat_vsod_count)\n",
    "\n",
    "else:\n",
    "    duplication.insert(43,0)\n",
    "\n",
    "\n",
    "duplication.insert(84,1)\n",
    "duplication.insert(85, 1)\n",
    "duplication.insert(86, 1)\n",
    "duplication.insert(87, 0)\n",
    "duplication.insert(88, 0)\n",
    "duplication.insert(89, 1)\n",
    "duplication.insert(90, 1)\n",
    "duplication.insert(91, 1)\n",
    "duplication.insert(92, 0)\n",
    "duplication.insert(93, 0)\n",
    "\n",
    "section_names = [f\"{name} {suffix}\" for name in section_names for suffix in suffixes]\n",
    "\n",
    "section_names.insert(40,'Volume Sold on Deal Sector')\n",
    "section_names.insert(41,'Volume Sold on Deal Segment')\n",
    "section_names.insert(42,'Volume Sold on Deal SubSegment')\n",
    "section_names.insert(43,'Volume Sold on Deal SubCategory')\n",
    "\n",
    "section_names.insert(84,'Seasonality Index Category')\n",
    "section_names.insert(85,'Seasonality Index Sector')\n",
    "section_names.insert(86,'Seasonality Index Segment')\n",
    "section_names.insert(87,'Seasonality Index Subsegment')\n",
    "section_names.insert(88,'Seasonality Index Subcategory')\n",
    "\n",
    "section_names.insert(89,'Promotional Frequency Analysis Category')\n",
    "section_names.insert(90,'Promotional Frequency Analysis Sector')\n",
    "section_names.insert(91,'Promotional Frequency Analysis Segment')\n",
    "section_names.insert(92,'Promotional Frequency Analysis Subsegment')\n",
    "section_names.insert(93,'Promotional Frequency Analysis Subcategory')\n",
    "#section_names.insert(94,'Promotional Frequency Analysis Subcategory')\n",
    "\n",
    "duplication[77]=0\n",
    "#index = [i for i in index if i != []]\n",
    "# duplication = [i for i in duplication if i != []]\n",
    "#\n",
    "\n",
    "path = os.getcwd() + '//Promotion base.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated.pptx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bbcf3",
   "metadata": {},
   "source": [
    "### Deck 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a93e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, [17, 17, 16, 17], [17, 16, 17, 17, 17, 16, 16], [17, 16, 17, 17, 17, 16, 16, 16, 16, 16, 16], [], [], 19, 19, 19, 19, 19, [20, 20, 20], [21, 21, 21], [20, 20, 20, 21, 21, 21], [], [], [27, 27, 27], [27, 26, 27, 27, 27, 26, 26], [27, 26, 27, 27, 27, 26, 26, 26, 26, 26], [], [], 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13]\n",
      "[3, 6, 9, 0, 0, 0, 2, 4, 0, 0, 1, 2, 3, 0, 0, 3, 6, 9, 0, 0, 3, 6, 9, 0, 0, 3, 6, 9, 0, 0, 3, 6, 8, 0, 0, 3, 6, 8, 0, 0, 11, 22, 0, 0, 3, 6, 9, 0, 0, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 18, 26, 0, 0, 1, 1, 1, 0, 0, 8, 12, 18, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 3, 6, 9, 0, 0, 0, 2, 4, 0, 0, 1, 2, 3, 0, 0, 3, 6, 9, 0, 0, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Promo Evolution Category', 'Promo Evolution Sector', 'Promo Evolution Segment', 'Promo Evolution SubSegment', 'Promo Evolution SubCategory', 'VSOD Summary by Sector Category', 'VSOD Summary by Sector Sector', 'VSOD Summary by Sector Segment', 'VSOD Summary by Sector SubSegment', 'VSOD Summary by Sector SubCategory', 'Value uplift by retailer by brand Category', 'Value uplift by retailer by brand Sector', 'Value uplift by retailer by brand Segment', 'Value uplift by retailer by brand SubSegment', 'Value uplift by retailer by brand SubCategory', 'Volume Uplift vs discount depth Category', 'Volume Uplift vs discount depth Sector', 'Volume Uplift vs discount depth Segment', 'Volume Uplift vs discount depth SubSegment', 'Volume Uplift vs discount depth SubCategory', 'Value Uplift vs Promo Efficiency Quadrant Category', 'Value Uplift vs Promo Efficiency Quadrant Sector', 'Value Uplift vs Promo Efficiency Quadrant Segment', 'Value Uplift vs Promo Efficiency Quadrant SubSegment', 'Value Uplift vs Promo Efficiency Quadrant SubCategory', 'Top 20 promotions Category', 'Top 20 promotions Sector', 'Top 20 promotions Segment', 'Top 20 promotions SubSegment', 'Top 20 promotions SubCategory', 'Top 20 promotions CLIENT ONLY Category', 'Top 20 promotions CLIENT ONLY Sector', 'Top 20 promotions CLIENT ONLY Segment', 'Top 20 promotions CLIENT ONLY SubSegment', 'Top 20 promotions CLIENT ONLY SubCategory', 'Bottom 20 promotions CLIENT ONLY Category', 'Bottom 20 promotions CLIENT ONLY Sector', 'Bottom 20 promotions CLIENT ONLY Segment', 'Bottom 20 promotions CLIENT ONLY SubSegment', 'Bottom 20 promotions CLIENT ONLY SubCategory', 'Volume Sold on Deal Sector', 'Volume Sold on Deal Segment', 'Volume Sold on Deal SubSegment', 'Volume Sold on Deal SubCategory', 'Promo share vs Value Share Category', 'Promo share vs Value Share Sector', 'Promo share vs Value Share Segment', 'Promo share vs Value Share SubSegment', 'Promo share vs Value Share SubCategory', 'Promo Sales by total size Category', 'Promo Sales by total size Sector', 'Promo Sales by total size Segment', 'Promo Sales by total size SubSegment', 'Promo Sales by total size SubCategory', 'Promo Sales by promo type Category', 'Promo Sales by promo type Sector', 'Promo Sales by promo type Segment', 'Promo Sales by promo type SubSegment', 'Promo Sales by promo type SubCategory', 'Feature Share vs Fair Share Category', 'Feature Share vs Fair Share Sector', 'Feature Share vs Fair Share Segment', 'Feature Share vs Fair Share SubSegment', 'Feature Share vs Fair Share SubCategory', 'Display Share vs Fair Share Category', 'Display Share vs Fair Share Sector', 'Display Share vs Fair Share Segment', 'Display Share vs Fair Share SubSegment', 'Display Share vs Fair Share SubCategory', 'Promo Frequency learnings Category', 'Promo Frequency learnings Sector', 'Promo Frequency learnings Segment', 'Promo Frequency learnings SubSegment', 'Promo Frequency learnings SubCategory', 'Promo sales per retailer Category', 'Promo sales per retailer Sector', 'Promo sales per retailer Segment', 'Promo sales per retailer SubSegment', 'Promo sales per retailer SubCategory', 'Value Uplift vs discount depth Category', 'Value Uplift vs discount depth Sector', 'Value Uplift vs discount depth Segment', 'Value Uplift vs discount depth SubSegment', 'Value Uplift vs discount depth SubCategory', 'Seasonality Index Category', 'Seasonality Index Sector', 'Seasonality Index Segment', 'Seasonality Index Subsegment', 'Seasonality Index Subcategory', 'Promotional Frequency Analysis Category', 'Promotional Frequency Analysis Sector', 'Promotional Frequency Analysis Segment', 'Promotional Frequency Analysis Subsegment', 'Promotional Frequency Analysis Subcategory', 'Promo Evolution no client prio Category', 'Promo Evolution no client prio Sector', 'Promo Evolution no client prio Segment', 'Promo Evolution no client prio SubSegment', 'Promo Evolution no client prio SubCategory', 'VSOD Summary by Sector no client prio Category', 'VSOD Summary by Sector no client prio Sector', 'VSOD Summary by Sector no client prio Segment', 'VSOD Summary by Sector no client prio SubSegment', 'VSOD Summary by Sector no client prio SubCategory', 'Value uplift by retailer by brand no client prio Category', 'Value uplift by retailer by brand no client prio Sector', 'Value uplift by retailer by brand no client prio Segment', 'Value uplift by retailer by brand no client prio SubSegment', 'Value uplift by retailer by brand no client prio SubCategory', 'Promo share vs Value Share no client prio Category', 'Promo share vs Value Share no client prio Sector', 'Promo share vs Value Share no client prio Segment', 'Promo share vs Value Share no client prio SubSegment', 'Promo share vs Value Share no client prio SubCategory', 'Promo Sales by total size no client prio Category', 'Promo Sales by total size no client prio Sector', 'Promo Sales by total size no client prio Segment', 'Promo Sales by total size no client prio SubSegment', 'Promo Sales by total size no client prio SubCategory', 'Feature Share vs Fair Share no client prio Category', 'Feature Share vs Fair Share no client prio Sector', 'Feature Share vs Fair Share no client prio Segment', 'Feature Share vs Fair Share no client prio SubSegment', 'Feature Share vs Fair Share no client prio SubCategory', 'Display Share vs Fair Share no client prio Category', 'Display Share vs Fair Share no client prio Sector', 'Display Share vs Fair Share no client prio Segment', 'Display Share vs Fair Share no client prio SubSegment', 'Display Share vs Fair Share no client prio SubCategory']\n",
      "129\n",
      "129\n",
      "129\n",
      "[[17, 17, 16, 17], [17, 16, 17, 17, 17, 16, 16], [17, 16, 17, 17, 17, 16, 16, 16, 16, 16, 16], [], []]\n",
      "[[27, 27, 27], [27, 26, 27, 27, 27, 26, 26], [27, 26, 27, 27, 27, 26, 26, 26, 26, 26], [], []]\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(final_lis)\n",
    "print(final_lis1)\n",
    "print(sum(duplication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "474f4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42d9d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(slides_name) >0:\n",
    "    indices = [i for i, s in enumerate(section_names) if any(sub.lower() in s.lower() for sub in slides_name)]\n",
    "    filtered_section_names = [section_names[i] for i in indices]\n",
    "    filtered_duplication = [duplication[i] for i in indices]\n",
    "    filtered_index = [index[i] for i in indices]\n",
    "    slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n",
    "else:\n",
    "    slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830c75f",
   "metadata": {},
   "source": [
    "## Replace duplicated slides with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78376167-8225-4f4f-af41-cd366f3e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)\n",
    "posItr = 0\n",
    "ind =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a49aea0-21ff-4bf4-9427-d2f7a6b8a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2\n",
    "try:\n",
    "    if 0 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                \n",
    "                promoEvolutionNew(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec6850ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cd4fcae-6d85-4244-82e5-9a19f05b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3\n",
    "try:\n",
    "    if 1 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92914c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b8dc777-7e02-4573-b8f9-000bb04fcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4\n",
    "try:\n",
    "    if 2 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                valueUpliftRetailer(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27312e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c8ee2a2-5cdf-41f3-ad8a-95fb9baacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 5\n",
    "try:\n",
    "    if 3 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionProductsP12M_volumeuplift,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionProductsP12M_volumeuplift.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VolumeUplift(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd0b667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30f24f2e-b093-4fe6-8605-1ef06f69e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 6\n",
    "try:\n",
    "    if 4 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(new_modified_promotionProductsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in new_modified_promotionProductsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                ValueUpliftvsPromoEfficiencyQuadrant(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "569c3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba714fd4-a9da-45d9-9eb0-1a1889324bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 7\n",
    "try:\n",
    "    if 5 in filtered_index:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(new_modified_promotionProductsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in new_modified_promotionProductsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "477805d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 18\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df90b497-4ca3-4467-9965-3eeba68fef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 8\n",
    "try:\n",
    "    if 6 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(top20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in top20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                top20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e578ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4108f604-685c-4fd8-aab4-5c66967a67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 9\n",
    "try:\n",
    "    if 7 in filtered_index:\n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(bottom20clientonly,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in bottom20clientonly.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                bot20Client(prs,filtered_dict,duplication[ind],position=sum(duplication[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16765a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "762a2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, sect_vsod_merged, position=posItr, parent=direct_parent['Sector'], child = 'Sector')\n",
    "        print(posItr)\n",
    "        posItr += sect_vsod_count\n",
    "        ind +=1\n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "244a0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d41024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, seg_vsod_merged, position=posItr, parent=direct_parent['Segment'], child = 'Segment')\n",
    "        posItr += seg_vsod_count\n",
    "        ind +=1\n",
    "    \n",
    "else:\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66bc536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "451cdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subseg_vsod_merged, position=posItr, parent=direct_parent['SubSegment'], child = 'SubSegment')\n",
    "        posItr += subseg_vsod_count\n",
    "        ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "780b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2298d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories)>0:\n",
    "    try:\n",
    "        if 8 in filtered_index:\n",
    "                dup_list = filtered_duplication\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        newVolumeSold(prs, subcat_vsod_merged, position=posItr, parent=direct_parent['SubCategory'], child = 'SubCategory')\n",
    "        posItr += subcat_vsod_count\n",
    "        ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5677352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ee42400-58ae-4311-8ac7-9914c0ae666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "                ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f7b6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "569341f7-9b94-4bf5-9114-fe10a6d0cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "                ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b4e2148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e6331b0-3674-471a-8da0-d10719174ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 13\n",
    "if promo_type:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(PromoSalesTypes_data,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in PromoSalesTypes_data.items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 11 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:\n",
    "                    PromoSalesTypes(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5192201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "555338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2ecb5b3-8308-43ec-b4aa-16c2e7b0797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f16eefd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5ffadfa-5f94-4967-84f6-54c1d2ab7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 16\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionEndOfWeek,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionEndOfWeek.items() if key in dict[key1]}\n",
    "        if filtered_dict:       \n",
    "            try:\n",
    "                if 14 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoFrequency(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "                ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b84ad318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "43caf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if categories:\n",
    "    catFinal = sorted(splitDfsPromo(dfCategory,(client_manuf) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal = catFinal+sorted(splitDfsPromo(dfCategory,(client_brands) ,genrateIndexList(catGroup[0])[0]))\n",
    "    catFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "56f6fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35 [['Manual Shave Men | Edgewell Personal Care | NATIONAL', \"Manual Shave Men | Edgewell Personal Care | Sam's Corp\", 'Manual Shave Men | Edgewell Personal Care | Walmart'], ['Manual Shave Men | Cremo | NATIONAL', \"Manual Shave Men | Cremo | Sam's Corp\", 'Manual Shave Men | Cremo | Walmart'], ['Manual Shave Men | Equate | NATIONAL', 'Manual Shave Men | Equate | Walmart'], ['Manual Shave Men | Schick | NATIONAL', \"Manual Shave Men | Schick | Sam's Corp\", 'Manual Shave Men | Schick | Walmart']]\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr, catFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05117abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sectors:\n",
    "    secFinal = sorted(splitDfsPromo(dfSector,(client_manuf)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal = secFinal + sorted(splitDfsPromo(dfSector,(client_brands)  ,genrateIndexList(secGroup[0])[0]))\n",
    "    secFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f5855f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 35\n"
     ]
    }
   ],
   "source": [
    "print(ind,posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c788ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if segments:\n",
    "    segFinal = sorted(splitDfsPromo(dfSegment,(client_manuf)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal = segFinal+sorted(splitDfsPromo(dfSegment,(client_brands)  ,genrateIndexList(segGroup[0])[0]))\n",
    "    segFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "889d3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subsegments:\n",
    "    subsegFinal = sorted(splitDfsPromo(dfSubSegment,(client_manuf)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal = subsegFinal + sorted(splitDfsPromo(dfSubSegment,(client_brands)  ,genrateIndexList(subsegGroup[0])[0]))\n",
    "    subsegFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3153b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if subcategories:\n",
    "    subcatFinal = sorted(splitDfsPromo(dfSubCategory,(client_manuf) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal = subcatFinal+sorted(splitDfsPromo(dfSubCategory,(client_brands) ,genrateIndexList(subcatGroup[0])[0]))\n",
    "    subcatFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5febe962-91f9-4b04-80a0-986f63399c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slide 17\n",
    "#split catGroup into Lists depends on num of charts \n",
    "# index1 = filtered_index\n",
    "# catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "values_to_check = {15, 16, 17,18}\n",
    "try:\n",
    "    index1 = filtered_index\n",
    "except NameError:\n",
    "    index1 = index\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1= filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    index1 = index\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    catGroupSplit = splitListpromo(dfCategory, catGroup, [i-14 for i in index1[ind]])\n",
    "    promoSalesPerRetailer(prs,dfCategory,len(index1[ind]),catGroupSplit,position=sum(dup_list[:ind]))\n",
    "    posItr = sum(dup_list[:ind]) + len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "\n",
    "#split secGroup into Lists depends on num of charts \n",
    "if len(sectors) != 0:   \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        secGroupSplit = splitListpromo(dfSector, secGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSector,len(index1[ind]),secGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split segGroup into Lists depends on num of charts \n",
    "if len(segments) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        segGroupSplit = splitListpromo(dfSegment, segGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSegment,len(index1[ind]),segGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subsegGroup into Lists depends on num of charts \n",
    "if len(subsegments) != 0:\n",
    "    subsegGroupSplit = splitListpromo(dfSubSegment, subsegGroup, [i-14 for i in index1[ind]])\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        promoSalesPerRetailer(prs,dfSubSegment,len(index1[ind]),subsegGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n",
    "#split subcatGroup into Lists depends on num of charts \n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1= filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        index1 = index\n",
    "        dup_list = duplication\n",
    "        run_slide = True\n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroupSplit = splitListpromo(dfSubCategory, subcatGroup, [i-14 for i in index1[ind]])\n",
    "        promoSalesPerRetailer(prs,dfSubCategory,len(index1[ind]),subcatGroupSplit,position=posItr)\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "840168bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4bdf01c1-6ec8-405c-bb46-928310996eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 57\n"
     ]
    }
   ],
   "source": [
    "# slide 21\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_valueUplift,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_valueUplift.items() if key in dict[key1]}\n",
    "        if filtered_dict:\n",
    "            try:\n",
    "                if 19 in filtered_index:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                        run_slide = False\n",
    "            except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True \n",
    "\n",
    "            if run_slide:\n",
    "                valueUplift(prs,filtered_dict,dup_list[ind],position=posItr)\n",
    "                posItr += len(filtered_dict)\n",
    "ind +=1\n",
    "print(ind,posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e02f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {20,21,22,23,24,25}\n",
    "if len(categories)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfCategory0, len(index1[ind]), categoryGroup0, position=posItr,slideby=\"Category\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fec4ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSector0, len(index1[ind]), secGroup0, position=posItr,slideby=\"Sector\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95c95329",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(segments)>0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs, dfSegment0, len(index1[ind]), segGroup0, position=posItr,slideby=\"Segment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cfffb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubSegment0,len(index1[ind]),subsegGroup0,position=posItr,slideby=\"SubSegment\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8d74d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        seasonality(prs,dfSubCategory0,len(index1[ind]),subcatGroup0,position=posItr,slideby=\"SubCategory\")\n",
    "        posItr += len(index1[ind])\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bdb5a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 21\n"
     ]
    }
   ],
   "source": [
    "print(posItr,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e773cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date1 = pd.to_datetime(end_date)\n",
    "start_date1 = end_date1 - pd.DateOffset(months=12)\n",
    " \n",
    "# Generate all weekly periods (weekly ends, e.g., Sundays) between start and end\n",
    "week_ends = pd.date_range(start=start_date1, end=end_date1, freq='W-SUN')\n",
    " \n",
    "# Convert to list of dates (if needed)\n",
    "week_ends_list = week_ends.to_list()\n",
    "all_weeks_df = pd.DataFrame({'End of Week': week_ends_list})\n",
    "\n",
    "def add_all_weeks(data):\n",
    "    final_data ={}\n",
    "    for key,df in data.items():\n",
    "        df_full = all_weeks_df.merge(df, on='End of Week', how='left')\n",
    "        df_full.fillna(0, inplace=True)\n",
    "        final_data[key] = df_full\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bab704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_dfCategory1 = add_all_weeks(modified_dfCategory1)\n",
    "modified_dfSector1 = add_all_weeks(modified_dfSector1)\n",
    "modified_dfSegment1 = add_all_weeks(modified_dfSegment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6b6cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = {26,27,28,29}\n",
    "try:\n",
    "    normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "    if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "            dup_list = filtered_duplication\n",
    "            index1 = filtered_index\n",
    "            run_slide = True\n",
    "    else:\n",
    "            run_slide = False\n",
    "except NameError:\n",
    "        dup_list = duplication\n",
    "        index1=index\n",
    "        run_slide = True \n",
    "\n",
    "if run_slide:\n",
    "        catGroup1Split = splitListpromo(modified_dfCategory1, catGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfCategory1,len(index1[ind]),catGroup1Split,position=posItr)\n",
    "        posItr +=len(catGroup1Split)\n",
    "ind+=1\n",
    "#Sector Replace\n",
    "if len(sectors) != 0: \n",
    "    \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        secGroup1Split = splitListpromo(modified_dfSector1, secGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSector1,len(index1[ind]),secGroup1Split,position=posItr)\n",
    "        posItr += len(secGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "\n",
    "if len(segments) != 0: \n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 =  filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        segGroup1Split = splitListpromo(modified_dfSegment1, segGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSegment1,len(index1[ind]),segGroup1Split,position=posItr)\n",
    "        posItr += len(segGroup1Split)\n",
    "ind+=1\n",
    "\n",
    "if len(subsegments) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subsegGroup1Split = splitListpromo(modified_dfSubSegment1, subsegGroup1, [i-25 for i in index1[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubSegment1,len(index1[ind]),subsegGroup1Split,position=posItr)\n",
    "        posItr += len(subsegGroup1Split)\n",
    "    ind+=1\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "    try:\n",
    "        normalized_index = [sub if isinstance(sub, list) else [sub] for sub in filtered_index]\n",
    "        if any(value in values_to_check for sublist in normalized_index for value in sublist):\n",
    "                dup_list = filtered_duplication\n",
    "                index1 = filtered_index\n",
    "                run_slide = True\n",
    "        else:\n",
    "                run_slide = False\n",
    "    except NameError:\n",
    "            dup_list = duplication\n",
    "            index1=index\n",
    "            run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        subcatGroup1Split = splitListpromo(modified_dfSubCategory1, subcatGroup1, [i-25 for i in index[ind]])\n",
    "        Promotional_Frequency(prs,modified_dfSubCategory1,len(index1[ind]),subcatGroup1Split,position=posItr)\n",
    "        posItr += len(subcatGroup1Split)\n",
    "        ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09d3bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72350edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 2 with no client brands\n",
    "try:\n",
    "    if 0 in filtered_index and 'Promo Evolution no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(promotionsBrandNOTSortedTotalFinal,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in promotionsBrandNOTSortedTotalFinal.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                promoEvolutionNew(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0fb051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 3 with no client brands\n",
    "try:\n",
    "    if 1 in filtered_index and 'VSOD Summary by Sector no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(newpromotionsNotBrandsWithMarket,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in newpromotionsNotBrandsWithMarket.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                VSOD1(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61072cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 4 with no client brands\n",
    "try:\n",
    "    if 2 in filtered_index and 'Value uplift by retailer by brand no client prio' in filtered_section_names:\n",
    "        dup_list = filtered_duplication\n",
    "        run_slide = True\n",
    "    else:\n",
    "        run_slide = False\n",
    "except NameError:\n",
    "    dup_list = duplication\n",
    "    run_slide = True\n",
    "\n",
    "if run_slide:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(concated,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in concated.items() if key in dict[key1]}\n",
    "            if filtered_dict:\n",
    "                valueUpliftRetailer_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "            posItr += len(filtered_dict)\n",
    "            ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead65353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a963d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 11 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 9 in filtered_index and 'Promo share vs Value Share no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoShare_vs_ValueShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "                ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "print(posItr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 269\n"
     ]
    }
   ],
   "source": [
    "print(ind, posItr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 12 with no client prio\n",
    "for key,value in Scope.items():\n",
    "    dict = {key: count_df(newModifiedBrands,value) }\n",
    "    for key1,value1 in dict.items():\n",
    "        filtered_dict = {key: value for key, value in newModifiedBrands.items() if key in dict[key1]}\n",
    "        if filtered_dict:        \n",
    "            try:\n",
    "                if 10 in filtered_index and 'Promo Sales by total size no client prio' in filtered_section_names:\n",
    "                        dup_list = filtered_duplication\n",
    "                        run_slide = True\n",
    "                else:\n",
    "                    run_slide = False\n",
    "            except NameError:\n",
    "                dup_list = duplication\n",
    "                run_slide = True\n",
    "\n",
    "            if run_slide:\n",
    "                PromoSalesTotalSize_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                posItr += len(filtered_dict)\n",
    "                ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80096263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide 14 with no client prio\n",
    "if feature_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:       \n",
    "                try:\n",
    "                    if 12 in filtered_index and 'Feature Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    featureShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slide 15 with no client prio\n",
    "if display_share:\n",
    "    for key,value in Scope.items():\n",
    "        dict = {key: count_df(modified_promotionBrandsP12M,value) }\n",
    "        for key1,value1 in dict.items():\n",
    "            filtered_dict = {key: value for key, value in modified_promotionBrandsP12M.items() if key in dict[key1]}\n",
    "            if filtered_dict:        \n",
    "                try:\n",
    "                    if 13 in filtered_index and 'Display Share vs Fair Share no client prio' in filtered_section_names:\n",
    "                            dup_list = filtered_duplication\n",
    "                            run_slide = True\n",
    "                    else:\n",
    "                        run_slide = False\n",
    "                except NameError:\n",
    "                    dup_list = duplication\n",
    "                    run_slide = True\n",
    "\n",
    "                if run_slide:   \n",
    "                    displayShare_no(prs,filtered_dict,dup_list[ind],position=sum(dup_list[:ind]))\n",
    "                    posItr += len(filtered_dict)\n",
    "                    ind +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217af932",
   "metadata": {},
   "source": [
    "## Output slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e0982-087b-439b-a549-736abdbb54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# # app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "final=os.getcwd() +f\"\\\\Promotion {client_manuf[0]}.pptx\"\n",
    "open_chart_data_in_excel(final,outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413d6eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\aleaa\\\\Documents\\\\Slide-Automate\\\\Promotion Slide Duplicate/ValueUpliftvsDepth/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m loaded_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m datasets_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39m path1\n\u001b[1;32m----> 7\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(datasets_path\u001b[38;5;241m+\u001b[39md, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\aleaa\\\\Documents\\\\Slide-Automate\\\\Promotion Slide Duplicate/ValueUpliftvsDepth/'"
     ]
    }
   ],
   "source": [
    "%run \"..\\general_functions\\generalFunctions.ipynb\"\n",
    "%run \"..\\Promotion Slide Duplicate\\Promotion Replacement Function.ipynb\"\n",
    "\n",
    "path1 = r\"/ValueUpliftvsDepth/\"\n",
    "loaded_data = {}\n",
    "datasets_path = os.getcwd()+ path1\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        loaded_data[d.split('.')[0]] = pd.read_csv(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueUplift_dict = {} # value\n",
    "i=0\n",
    "for key, df in loaded_data.items():\n",
    "    data = DetectHeader(df)\n",
    "    columns_to_ffill = [col for col in data.columns if 'item' in col.lower() or 'product' in col.lower()]\n",
    "    data[columns_to_ffill] = data[columns_to_ffill].fillna(method='ffill')\n",
    "    data = data[~data['Item'].str.contains('Total', case=False)].reset_index(drop=True)\n",
    "    for item in data['Item'].unique():\n",
    "        df = data[data['Item'] == item]\n",
    "        df['Discount Depth (%)'] = df['Discount Depth (%)'].str.replace('%','').astype(float) /100\n",
    "        df['Promo Price/Unit'] = df['Promo Price/Unit'].str.replace('£','').astype(float)\n",
    "        if normalized:\n",
    "            df['Value Uplift (v. base) Normalized'] = df['Value Uplift (v. base) Normalized'].str.replace('%','').astype(float) /100\n",
    "        else:\n",
    "            df['Value Uplift (v. base)'] = df['Value Uplift (v. base)'].str.replace().str.replace('%','').astype(float) /100\n",
    "        df = df[df['End of Week'] != '0']\n",
    "        df['End of Week'] = pd.to_datetime(df['End of Week'])\n",
    "        df = df[(df['End of Week'] >= start_date) & (df['End of Week'] <= end_date)].reset_index(drop=True)\n",
    "        if df.shape[0]>0 and not df['Discount Depth (%)'].isna().all():\n",
    "            df = df.fillna(0).reset_index(drop = True)\n",
    "            new_key = key+'_'+ item\n",
    "            valueUplift_dict[new_key] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = 'before'\n",
    "decimals = 2\n",
    "currency = '£'\n",
    "data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Ending July 2024\"\n",
    "\n",
    "\n",
    "index = [20]\n",
    "duplication = [len(valueUplift_dict.keys())]\n",
    "section_names = [\"Value Uplift by product\"]\n",
    "path = os.getcwd() + '//Promotion base Oct 2024.pptx'\n",
    "new_pre = os.getcwd() + '//slide duplicated value.pptx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bfe1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each key-slide_num pair in modified_valueUplift\n",
    "for key, slide_num in zip(valueUplift_dict, range(len(valueUplift_dict.keys()))):\n",
    "        # Access the slide to be modified\n",
    "        slide = prs.slides[slide_num]\n",
    "        \n",
    "        # Extract data for the current key\n",
    "        df = valueUplift_dict[key]\n",
    "        #df = df[df['Value Uplift (v. base) Normalized'] !=0 ]\n",
    "        # Get shapes in the slide\n",
    "        shapes = slide.shapes\n",
    "        \n",
    "        # Find and update title shape\n",
    "        titleNumber = get_shape_number(shapes, \"Value Uplift vs discount depth | By Event | Category/Sector | Brand | Coop Alleanza | P12M\")\n",
    "        datasourcenum = get_shape_number(shapes, \"Data Source | Trade Panel\")\n",
    "        headerNumber = get_shape_number(shapes, 'Value Uplift vs discount depth (Replace With SO WHAT)')\n",
    "        if titleNumber is not None:\n",
    "            shapes[datasourcenum].text = data_source\n",
    "            shapes[titleNumber].text = shapes[titleNumber].text.replace('Category/Sector', key.split('_')[2]) \\\n",
    "                .replace('Brand | Coop Alleanza ', df['Item'][0])\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.size = Pt(12)\n",
    "            shapes[titleNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.size = Pt(16)\n",
    "            shapes[headerNumber].text_frame.paragraphs[0].font.name = 'Nexa Bold (Headings)'\n",
    "\n",
    "        # Create table and chart objects\n",
    "        tables, charts = createTableAndChart(slide.shapes)\n",
    "        chart1 = charts[0].chart  # First chart\n",
    "        chart2 = charts[1].chart  # Second chart\n",
    "        \n",
    "        # Extract data for charts\n",
    "        category = df['Item'].tolist()\n",
    "        x_values_discount = df['Discount Depth (%)'].tolist()\n",
    "        x_values_price = df['Promo Price/Unit'].tolist()\n",
    "        if normalized:\n",
    "            y_values = df['Value Uplift (v. base) Normalized'].tolist()\n",
    "        else:\n",
    "            y_values = df['Value Uplift (v. base)'].tolist()\n",
    "\n",
    "        \n",
    "        x_values_discount = [mround_numpy(value, 0.05) for value in x_values_discount]\n",
    "        x_values_price = [mround_numpy(value, 0.5) for value in x_values_price]\n",
    "        #Update first chart with Discount Depth vs Value Uplift data\n",
    "        chart_data1 = XyChartData()\n",
    "        series1 = chart_data1.add_series('Scatter')\n",
    "        for i in range(len(category)):\n",
    "            series1.add_data_point(x_values_discount[i], y_values[i])\n",
    "        chart1.replace_data(chart_data1)\n",
    "        \n",
    "        # Access the X-axis\n",
    "        \n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data1._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data1._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"Item\")\n",
    "            worksheet.write_column(1, 4, df['Item'].to_list(), None)\n",
    "            worksheet.write(0, 5, \"End of Week\")\n",
    "            worksheet.write_column(1, 5, df['End of Week'].to_list(), None)\n",
    "\n",
    "        chart1._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n",
    "\n",
    "        # Update second chart with Promo Price/Unit vs Value Uplift data\n",
    "        chart_data2 = XyChartData()\n",
    "        series2 = chart_data2.add_series('Scatter')\n",
    "        for i in range(len(category)):\n",
    "            series2.add_data_point(x_values_price[i], y_values[i])\n",
    "        chart2.replace_data(chart_data2)\n",
    "        \n",
    "        x_axis = chart2.category_axis\n",
    "        \n",
    "        # Loop through each X-axis category label and format as currency\n",
    "        if sign.lower() == 'before':\n",
    "            x_axis.tick_labels.number_format = f'\"{currency}\"#,##0.00'  if decimals == 2 else f'\"{currency}\"#,##0'\n",
    "        else:\n",
    "            x_axis.tick_labels.number_format = f'#,##0.00\"{currency}\"'  if decimals == 2 else f'#,##0\"{currency}\"'\n",
    "       \n",
    "        #x_axis.has_major_gridlines = False  # Optional: remove gridlines\n",
    "\n",
    "        xlsx_file = BytesIO()\n",
    "        with chart_data2._workbook_writer._open_worksheet(xlsx_file) as (workbook, worksheet):\n",
    "            chart_data2._workbook_writer._populate_worksheet(workbook, worksheet)\n",
    "            worksheet.write(0, 4, \"Item\")\n",
    "            worksheet.write_column(1, 4, df['Item'].to_list(), None)\n",
    "            worksheet.write(0, 5, \"End of Week\")\n",
    "            worksheet.write_column(1, 5, df['End of Week'].to_list(), None)\n",
    "        chart2._workbook.update_from_xlsx_blob(xlsx_file.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() + \"\\\\Promotion EdgeWell ValueUplift.pptx\"\n",
    "prs.save(outputPath)\n",
    "app = win32.Dispatch(\"PowerPoint.Application\")\n",
    "presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623751f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
