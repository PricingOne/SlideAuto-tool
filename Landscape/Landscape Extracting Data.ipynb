{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\Extracting Data Functions.ipynb\" # container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import adodbapi\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali Salem\\Desktop\\App_Update\\parameters.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'parameters.xlsx'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the full path to the file\n",
    "f_path = os.path.join(current_dir, filename)\n",
    "print(f_path)\n",
    "#xls = pd.ExcelFile(f_path)\n",
    "parm = pd.read_excel(f_path, sheet_name='Landscape')\n",
    "fields = dict(zip(parm['Field'],parm['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "dataset_name = fields['f_name']\n",
    "f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "decimals = fields['decimals']\n",
    "sign = fields['sign']\n",
    "currency = fields['currency']\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "national=fields['national']\n",
    "customareas=fields['customareas']\n",
    "areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "\n",
    "regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "data_source=fields['data_source']\n",
    "years=list(set(fields['years'].split(','))-set(['']))\n",
    "years = {int(y) for y in fields['years'].split(',') if y}\n",
    "\n",
    "end_date=fields['end_date']\n",
    "\n",
    "ManufOrTopC = fields['ManufOrTopC']\n",
    "BrandOrTopB = fields['BrandOrTopB']\n",
    "\n",
    "National=[\"NATIONAL\"]if national else[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2023, 2024, 2025}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_RET + regions_CHAN + regions_CUST\n",
    "channels = channels_RET + channels_CHAN + channels_CUST\n",
    "markets = market_RET + market_CHAN + market_CUST\n",
    "\n",
    "\n",
    "entity_hierarchy = [\n",
    "    (\"Area\",National),\n",
    "    (\"Region\", regions),\n",
    "    (\"Channel\", channels),\n",
    "    (\"Market\", markets)\n",
    "]\n",
    "hierarchy_levels = [\n",
    "    (\"Category\", categories),\n",
    "    (\"Sector\", sectors),\n",
    "    (\"Segment\", segments),\n",
    "    (\"SubSegment\", subsegments),\n",
    "    (\"SubCategory\", subcategories)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sam's Corp\", 'Walmart', \"Bj's Corp\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};\"\n",
    "path=os.path.join(os.getcwd(),\"Landscape Datasets Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_manuf = [\"Pbg\"]\n",
    "# client_brands = [\"Schick\", \"Cremo\", \"Equate\"]\n",
    " \n",
    "# decimals = 2\n",
    "# sign = \"Before\"\n",
    "# currency = '$'\n",
    "# currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    " \n",
    "\n",
    "# categories = [\"Manual Shave Men\"]\n",
    "# sectors = [\"System\", \"Disposables\"]\n",
    "# segments = [\"Razors\", \"Refills\", \"Disposables\"]\n",
    "# subsegments= [\"2 Blade\", \"3 Blade\",\t\"4 Blade\", \"5 Blade\", \"6 Blade\", \"Rem Blades\"]\n",
    "# subcategories= [\"Dry Skin\",\t\"Normal Skin\", \"Sensitive Skin\", \"Rem Types\"]\n",
    "\n",
    "# national = True\n",
    "# customareas= \"\"\n",
    "# areas = [\"NATIONAL\", \"RETAILER\", \"CHANNEL\"]\n",
    "\n",
    "# regions_RET  = []\n",
    "# channels_RET = [\"Bj's Corp\", \"Sam's Corp\", \"Walmart\"]\n",
    "# market_RET = []\n",
    "\n",
    "# regions_CHAN = [\"Conv\",\t\"Drug\",\t\"Food\"]\n",
    "# channels_CHAN = []\n",
    "# market_CHAN = []\n",
    "\n",
    "# regions_CUST = []\n",
    "# channels_CUST = []\n",
    "# market_CUST = []\n",
    " \n",
    "\n",
    "# data_source = \"DATA SOURCE: Trade Panel/Retailer Data | Ending March  2025\" \n",
    "\n",
    "# ManufOrTopC =\"Top Companies\"\n",
    "# BrandOrTopB = \"SubBrand\"\n",
    "\n",
    "# years = {2023,2024,2025}\n",
    "\n",
    "# National=[\"NATIONAL\"]if national else[]\n",
    "# regions = regions_RET + regions_CHAN + regions_CUST\n",
    "# channels = channels_RET + channels_CHAN + channels_CUST\n",
    "# markets = market_RET + market_CHAN + market_CUST\n",
    "\n",
    "\n",
    "# entity_hierarchy = [\n",
    "#     (\"Area\",National),\n",
    "#     (\"Region\", regions),\n",
    "#     (\"Channel\", channels),\n",
    "#     (\"Market\", markets)\n",
    "# ]\n",
    "# hierarchy_levels = [\n",
    "#     (\"Category\", categories),\n",
    "#     (\"Sector\", sectors),\n",
    "#     (\"Segment\", segments),\n",
    "#     (\"SubSegment\", subsegments),\n",
    "#     (\"SubCategory\", subcategories)\n",
    "# ]\n",
    "# server = \"powerbi://api.powerbi.com/v1.0/myorg/Edgewell\"\n",
    "# dataset_name = \"Edgewell US Male Dataset\"\n",
    "# conn_str = f\"Provider=MSOLAP.8;Data Source={server};Initial Catalog={dataset_name};\"\n",
    "\n",
    "# print(conn_str)\n",
    "# path=os.path.join(os.getcwd(),\"Landscape Datasets NewEX\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Sector_P12M_dfs.pkl.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Segment_P12M_dfs.pkl.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubSegment_P12M_dfs.pkl.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubCategory_P12M_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, filter_p12m, include_year=False):\n",
    "    outputdic = {}\n",
    "    \n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "    key =  f\"{categories[0]} | {entity_name}\"\n",
    "    filters = \", \".join(filter(None, [f'Products[Category] = \"{categories[0]}\"', time_filter]))\n",
    "\n",
    "    columns = [\n",
    "        \"Volume Sales\", \"Value Sales\", \"Value Share\", \"Volume Share\", \"Value Sales IYA\",\n",
    "        \"Av Price/KG\", \"WoB %\", \"Relative Price\", \"Growth Contribution\",\n",
    "        \"Volume Sales IYA\", \"IYA Price/KG\"\n",
    "    ]\n",
    "    \n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "\n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                Values(Products[Category]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "            grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "\n",
    "            # Reorder columns if necessary\n",
    "            grand_tot = grand_tot[df.columns]\n",
    "\n",
    "            # Concatenate the two\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "            outputdic[key] = df  \n",
    "\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, time_filter):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {} \n",
    "        futures = {}\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "            for area, entity_list in entity_hierarchy:\n",
    "                for entity in entity_list:\n",
    "                    include_year = not time_filter \n",
    "                    key =  f\"{categories[0]} | {entity}\"\n",
    "                    ordered_keys.append(key)\n",
    "                    future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, include_year=include_year)\n",
    "                    futures[future] = key\n",
    "       \n",
    "            temp_results = {}\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "\n",
    "            # Insert results in original order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "          \n",
    "            filename =  f\"{hierby}_P12M_dfs.pkl\"\n",
    "            \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(entity_hierarchy,hierarchy_levels, time_filter=True)   # sectors_12_dfs.pkl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Sector_dfs.pkl.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Segment_dfs.pkl.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubSegment_dfs.pkl.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubCategory_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, filter_p12m, include_year=False):\n",
    "    outputdic = {}\n",
    "    outputtotal = {}\n",
    " \n",
    "    key = f\"{categories[0]} | {entity_name}\"\n",
    " \n",
    "    # Optional time filter\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]),\n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    " \n",
    "    # Combine filters\n",
    "    filters = \", \".join(filter(None, [\n",
    "        f'Products[Category] = \"{categories[0]}\"',\n",
    "        time_filter\n",
    "    ]))\n",
    " \n",
    "    # Define all required columns\n",
    "    columns = [\n",
    "        \"Volume Sales\", \"Value Sales\", \"Value Share\", \"Volume Share\", \"Value Sales IYA\",\n",
    "        \"Av Price/KG\", \"WoB %\", \"Relative Price\", \"Growth Contribution\",\n",
    "        \"Volume Sales IYA\", \"IYA Price/KG\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    " \n",
    "    # Main DAX query\n",
    "    summarize_expr = (\n",
    "        f\"CROSSJOIN(SUMMARIZE(Products, Products[{hierby}]), VALUES(Calendar[Year]))\"\n",
    "        if include_year else f\"SUMMARIZE(Products, Products[{hierby}])\"\n",
    "    )\n",
    "    summarizegrand_expr = (\n",
    "        f\"CROSSJOIN(SUMMARIZE(Products, Products[Category]), VALUES(Calendar[Year]))\"\n",
    "        if include_year else f\"SUMMARIZE(Products, Products[Category])\"\n",
    "    )\n",
    " \n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {summarize_expr},\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    totalcol_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    grandtotal_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {summarizegrand_expr},\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )\n",
    "    \"\"\"\n",
    " \n",
    "    try:\n",
    "        # Execute main query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    " \n",
    "        # Execute total column query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(totalcol_query)\n",
    "            total_columns = [desc[0] for desc in cursor.description]\n",
    "            total_data = cursor.fetchall()\n",
    " \n",
    "        # Execute grand total query\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grandtotal_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    " \n",
    "        # Main dataframe\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]\n",
    " \n",
    "        # Total column dataframe\n",
    "        dt = pd.DataFrame(total_data, columns=total_columns)\n",
    "        dt.columns = dt.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        dt = dt.loc[~(dt.select_dtypes(include='number') == 0).all(axis=1)]\n",
    " \n",
    "        # Grand total dataframe\n",
    "        grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "        grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "        grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]\n",
    "       \n",
    "        grand_tot[df.columns.difference([\"Year\", df.columns[0]])] = grand_tot[\n",
    "            df.columns.difference([\"Year\", df.columns[0]])\n",
    "        ].astype(float)\n",
    "        grand_tot[df.columns[0]] = 'Grand Total'\n",
    " \n",
    "        if 'Year' in df.columns and 'Year' not in grand_tot.columns:\n",
    "            grand_tot['Year'] = df['Year'].max()\n",
    " \n",
    "        grand_tot = grand_tot[df.columns]\n",
    "        df = pd.concat([df, grand_tot], ignore_index=True)\n",
    " \n",
    "        if dt.shape[1] > 0:\n",
    "            dt.rename(columns=lambda col: f\"Total {col}\" if col != dt.columns[0] else col, inplace=True)\n",
    " \n",
    "        if \"Year\" in df.columns:\n",
    "            df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    " \n",
    " \n",
    "        outputdic[key] = df\n",
    "        outputtotal[key] = dt\n",
    " \n",
    "        print(f\"Query executed successfully for {entity_name}.\")\n",
    " \n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    " \n",
    "    return outputdic, outputtotal\n",
    " \n",
    " \n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, time_filter):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        dfs_results = {}\n",
    "        dfs_totals = {}\n",
    "        futures = []\n",
    "        ordered_keys = []\n",
    "        future_to_key = {}\n",
    "        dfs_results = {}\n",
    "        # futures = []\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "            for area, entity_list in entity_hierarchy:\n",
    "                for entity in entity_list:\n",
    "                    include_year = not time_filter\n",
    "                    future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, include_year=include_year)\n",
    "                    key=f\"{categories[0]} | {entity}\"\n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key    \n",
    " \n",
    "       \n",
    "       \n",
    "            temp_results = {}\n",
    "            temp_totals={}\n",
    "            for future in as_completed(futures):\n",
    "                result, total = future.result()\n",
    "                temp_results.update(result)\n",
    "                temp_totals.update(total)\n",
    "               \n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "                    dfs_totals[key] = temp_totals[key]\n",
    " \n",
    " \n",
    " \n",
    "            # Construct the output file name correctly\n",
    "            filename = f\"{hierby}_dfs.pkl\"\n",
    "            filenametotal =  f\"{hierby}_total_dfs.pkl\"\n",
    "           \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "               \n",
    "            output_filetotal = f\"{path}\\\\{filenametotal}\"\n",
    "            with open(output_filetotal, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_totals, f)\n",
    " \n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    " \n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels,time_filter=False)  # sectors_dfs.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client SCOPE = hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Manual Shave Men | Cremo | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Schick | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Conv.\n",
      "Query executed successfully for Manual Shave Men | Pbg | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Equate | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Equate | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Conv.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Conv.\n",
      "Query executed successfully for Manual Shave Men | Equate | Food.\n",
      "Query executed successfully for Manual Shave Men | Schick | Food.\n",
      "Query executed successfully for Manual Shave Men | Schick | Drug.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Food.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Food.\n",
      "Query executed successfully for Manual Shave Men | Equate | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Drug.\n",
      "Query executed successfully for Manual Shave Men | Equate | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Schick | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Sector_client_dfs.pkl.\n",
      "Query executed successfully for Manual Shave Men | Pbg | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Cremo | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Equate | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Equate | Conv.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Food.\n",
      "Query executed successfully for Manual Shave Men | Equate | Food.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Food.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Food.\n",
      "Query executed successfully for Manual Shave Men | Schick | Drug.\n",
      "Query executed successfully for Manual Shave Men | Equate | Drug.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Drug.\n",
      "Query executed successfully for Manual Shave Men | Schick | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Schick | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Segment_client_dfs.pkl.\n",
      "Query executed successfully for Manual Shave Men | Equate | Conv.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Conv.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Conv.\n",
      "Query executed successfully for Manual Shave Men | Equate | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Schick | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Cremo | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Pbg | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Schick | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Food.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Food.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Food.\n",
      "Query executed successfully for Manual Shave Men | Schick | Drug.\n",
      "Query executed successfully for Manual Shave Men | Equate | Drug.\n",
      "Query executed successfully for Manual Shave Men | Equate | Food.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Drug.\n",
      "Query executed successfully for Manual Shave Men | Equate | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Equate | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Schick | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubSegment_client_dfs.pkl.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Conv.\n",
      "Query executed successfully for Manual Shave Men | Equate | Conv.\n",
      "Query executed successfully for Manual Shave Men | Equate | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Pbg | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Schick | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Cremo | NATIONAL.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Conv.\n",
      "Query executed successfully for Manual Shave Men | Schick | Food.\n",
      "Query executed successfully for Manual Shave Men | Equate | Food.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Food.\n",
      "Query executed successfully for Manual Shave Men | Schick | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Food.\n",
      "Query executed successfully for Manual Shave Men | Equate | Drug.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Drug.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Drug.\n",
      "Query executed successfully for Manual Shave Men | Schick | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Schick | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Equate | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Sam's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Walmart.\n",
      "Query executed successfully for Manual Shave Men | Schick | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Equate | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Cremo | Bj's Corp.\n",
      "Query executed successfully for Manual Shave Men | Pbg | Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubCategory_client_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, filter_p12m, brand=None, manuf=None):\n",
    "    outputdic = {}\n",
    "    \n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "\n",
    "    manuf_filter = f'Products[{ManufOrTopC}]=\"{manuf}\"' if manuf else \"\"\n",
    "    brand_filter = f'Products[{BrandOrTopB}]=\"{brand}\", Products[{ManufOrTopC}]=\"{client_manuf[0]}\"' if brand else \"\"\n",
    "    key = f\"{categories[0]} | {brand} | {entity_name}\" if brand else f\"{categories[0]} | {manuf} | {entity_name}\" if manuf else \"\"\n",
    "    filters = \", \".join(filter(None, [manuf_filter, brand_filter, time_filter]))\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "         \"Value Share\",\"Av Price/KG\",\"Value Share DYA\"\n",
    "    ]\n",
    "    \n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "\n",
    "# Construct the DAX query dynamically\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {key}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, time_filter, client_brands=None, client_manuf=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys = []\n",
    "        future_to_key = {}\n",
    "        dfs_results = {}\n",
    "        \n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "            for area, entity_list in entity_hierarchy:\n",
    "                for entity in entity_list:                    \n",
    "                    for brand in client_brands:\n",
    "                        future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, brand=brand)\n",
    "                        key = f\"{categories[0]} | {brand} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key  # ✅ add this line\n",
    "                    for manuf in client_manuf:\n",
    "                        future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, manuf=manuf)\n",
    "                        key=f\"{categories[0]} | {manuf} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key    \n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(future_to_key):\n",
    "                key = future_to_key[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "            # Preserve original key order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "\n",
    "            # Construct the output file name correctly\n",
    "            if client_manuf:\n",
    "                filename = f\"{hierby}_client_dfs.pkl\" if time_filter else f\"{hierby}_dfs.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(entity_hierarchy,hierarchy_levels, time_filter=True,client_brands=client_brands,client_manuf=client_manuf)  # Brand-level\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUFACTURER Dataframes& BRANDS Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\manuf_dfs.pkl.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\brand_dfs.pkl.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\brand_12_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandorManuf,entity_name, area, hierby, filter_p12m, entity_type,include_year=False):\n",
    "    outputdic = {}\n",
    "    outputtotal={}\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "    filters = \", \".join(filter(None, [f'Products[Category] = \"{categories[0]}\"', time_filter]))\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "        \"Volume Sales\", \"Value Sales\", \"Value Share\", \"Volume Share\", \"Share DYA\",\"Av Price/KG\",\"IYA Price/KG\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {f\"CROSSJOIN(SUMMARIZE(Products, Products[{BrandorManuf}]), VALUES(Calendar[Year]))\" if include_year else f\"SUMMARIZE(Products, Products[{BrandorManuf}])\"},\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    totalcol_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {f\"Values(Products[{BrandorManuf}])\"},\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    grand_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {f\"CROSSJOIN(SUMMARIZE(Products, Products[Category]), VALUES(Calendar[Year]))\" },\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(totalcol_query)\n",
    "            totalcol_columns = [desc[0] for desc in cursor.description]\n",
    "            totalcol_data = cursor.fetchall()\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grand_query)\n",
    "            grandtotal_columns = [desc[0] for desc in cursor.description]\n",
    "            grandtotal_data = cursor.fetchall()\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            \n",
    "               \n",
    "            dt = pd.DataFrame(totalcol_data, columns=totalcol_columns)\n",
    "            dt.columns = dt.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            dt = dt.loc[~(dt.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            \n",
    "            grand_tot = pd.DataFrame(grandtotal_data, columns=grandtotal_columns)\n",
    "            grand_tot.columns = grand_tot.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            grand_tot = grand_tot.loc[~(grand_tot.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "        \n",
    "\n",
    "            grand_tot[df.columns.difference([\"Year\", df.columns[0]])] = grand_tot[df.columns.difference([\"Year\", df.columns[0]])].astype(float)\n",
    "\n",
    "            # Optionally add a label for clarity\n",
    "            grand_tot[df.columns[0]] = 'Grand Total'\n",
    "            if 'Year' in df.columns and 'Year' not in grand_tot.columns:\n",
    "                grand_tot['Year'] = df['Year'].max()  # or some other default like np.nan or a fixed value\n",
    "\n",
    "            # Reorder columns if necessary\n",
    "            grand_tot = grand_tot[df.columns]\n",
    "\n",
    "            # Concatenate the two\n",
    "            df = pd.concat([df, grand_tot], ignore_index=True)\n",
    "\n",
    "            if dt.shape[1] > 0:\n",
    "                dt.rename(columns=lambda col: f\"Total {col}\" if col != dt.columns[0] else col, inplace=True)\n",
    "\n",
    "            if \"Year\" in df.columns:\n",
    "                df[\"Year\"] = df[\"Year\"].astype(int)  # Ensure Year is integer\n",
    "\n",
    "            outputdic[key] = df # Always store result\n",
    "            outputtotal[key]=dt\n",
    "\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic,outputtotal\n",
    "\n",
    "def process_dax_queries(BrandorManuf,entity_hierarchy, hierarchy_levels, time_filter):\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        dfs_results = {}\n",
    "        dfs_totals={}\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        include_year = not time_filter \n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        future = executor.submit(execute_dax_query,BrandorManuf,entity, area, hierby, time_filter,value, include_year=include_year)\n",
    "                        futures.append(future)\n",
    "\n",
    "            temp_results = {}\n",
    "            temp_totals={}\n",
    "            for future in as_completed(futures):\n",
    "                result, total = future.result()\n",
    "                temp_results.update(result)\n",
    "                temp_totals.update(total)\n",
    "                \n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "                    dfs_totals[key] = temp_totals[key]\n",
    "                \n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        if BrandorManuf==f'{ManufOrTopC}':\n",
    "            filename = \"manuf_dfs.pkl\"\n",
    "            filenametotal = \"manuf_total_dfs.pkl\"\n",
    "            \n",
    "        else:\n",
    "            filename = \"brand_12_dfs.pkl\" if time_filter else \"brand_dfs.pkl\"\n",
    "            filenametotal = \"brand_12_total_dfs.pkl\" if time_filter else \"brand_total_dfs.pkl\"\n",
    "\n",
    "               \n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "        output_filetotal = f\"{path}\\\\{filenametotal}\"\n",
    "        with open(output_filetotal, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_totals, f)    \n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels,time_filter=False)  \n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy,hierarchy_levels, time_filter=False)   # sectors_12_dfs.pkl\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy,hierarchy_levels, time_filter=True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANUFACTURER Dataframes\"P12M\", \"LY\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\manuf_12_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandorManuf, entity_name, area, hierby, entity_type=None):\n",
    "    outputdic = {}\n",
    "    outputtotal={}\n",
    "    time_periods = '{\"P12M\", \"LY\"}'  # Correct format for DAX\n",
    "\n",
    "    key = f\"{entity_type} | {entity_name}\"\n",
    "    columns = [\"Volume Sales\", \"Value Sales\", \"Value Share\", \"Volume Share\", \"Share DYA\", \"Av Price/KG\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                    SUMMARIZE(Products, Products[{BrandorManuf}]), \n",
    "                    VALUES('Time Logic'[Time Period])\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({time_periods}, 'Time Logic'[Time Period]),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    grand_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                {f\"Values(Products[{BrandorManuf}])\"},\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            TREATAS({time_periods}, 'Time Logic'[Time Period]),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "            \n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(grand_query)\n",
    "            grand_columns = [desc[0] for desc in cursor.description]\n",
    "            grand_data = cursor.fetchall()   \n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            \n",
    "            dt = pd.DataFrame(grand_data, columns=grand_columns)\n",
    "            dt.columns = dt.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            dt = pd.DataFrame(grand_data, columns=grand_columns)\n",
    "            dt.columns = dt.columns.str.replace(r'.*\\[|\\]', '', regex=True)\n",
    "            dt = dt.loc[~(dt.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "\n",
    "            if dt.shape[1] > 0:\n",
    "                dt.rename(columns=lambda col: f\"Total {col}\" if col != dt.columns[0] else col, inplace=True)\n",
    "\n",
    "            if \"Year\" in df.columns:\n",
    "                df[\"Year\"] = df[\"Year\"].astype(int)  # Ensure Year is integer\n",
    "\n",
    "            outputdic[key] = df  # Always store result\n",
    "            outputtotal[key]=dt\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic,outputtotal\n",
    "\n",
    "\n",
    "def process_dax_queries(BrandorManuf, entity_hierarchy, hierarchy_levels):\n",
    "    dfs_results = {}\n",
    "    dfs_totals={}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:   \n",
    "                for area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        future = executor.submit(execute_dax_query, BrandorManuf, entity, area, hierby, value)\n",
    "                        futures.append(future)\n",
    "            temp_results = {}\n",
    "            temp_totals={}\n",
    "            for future in as_completed(futures):\n",
    "                result, total = future.result()\n",
    "                temp_results.update(result)\n",
    "                temp_totals.update(total)\n",
    "                \n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "                    dfs_totals[key] = temp_totals[key] \n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        filename = \"manuf_12_dfs.pkl\"\n",
    "        filenametotal=\"manuf_12_total_dfs.pkl\"\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "            \n",
    "        output_filetotal = f\"{path}\\\\{filenametotal}\"\n",
    "        with open(output_filetotal, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_totals, f) \n",
    "\n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(ManufOrTopC, entity_hierarchy, hierarchy_levels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manuf&Brands Evolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\manuf_evolution.pkl.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\brands_evolution.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandorManuf,entity_name, area, hierby, entity_type):\n",
    "    outputdic = {}\n",
    "\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "        \"Value Sales\", \"Price Evolution\", \"Share Evolution\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                    VALUES(Calendar[Year]),\n",
    "                    SUMMARIZE(Products, Products[{BrandorManuf}])\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\"),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            FILTER(Products, Products[Category] = \"{categories[0]}\"),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}])\n",
    "        )\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)      \n",
    "               \n",
    "            df = df.loc[~(df.iloc[:, 1:].select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            \n",
    "            if \"Year\" in df.columns:\n",
    "                df = df[df[\"Year\"].notna()]\n",
    "                df[\"Year\"] = df[\"Year\"].astype(int)  # Ensure Year is integer\n",
    "            \n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "    return outputdic\n",
    "\n",
    "def process_dax_queries(BrandorManuf,entity_hierarchy, hierarchy_levels):\n",
    "    dfs_results = {}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        future = executor.submit(execute_dax_query,BrandorManuf,entity, area, hierby,value)\n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key    \n",
    "\n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "                \n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        if BrandorManuf==f'{ManufOrTopC}':\n",
    "            filename = \"manuf_evolution.pkl\"\n",
    "        else:\n",
    "            filename = \"brands_evolution.pkl\"\n",
    "               \n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels)\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\manuf_evolution_total.pkl.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\brands_evolution_total.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandorManuf,entity_name, area, hierby, entity_type):\n",
    "    outputdic = {}\n",
    "\n",
    "    key =  f\"{entity_type} | {entity_name}\"\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "        \"Value Sales\", \"Price Evolution\", \"Share Evolution\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                VALUES(Calendar[Year]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\"),\n",
    "            Products[{hierby}] = \"{entity_type}\",\n",
    "            FILTER(Products, Products[Category] = \"{categories[0]}\"),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}])\n",
    "        )\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)      \n",
    "               \n",
    "            df = df.loc[~(df.iloc[:, 1:].select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            \n",
    "            if \"Year\" in df.columns:\n",
    "                df = df[df[\"Year\"].notna()]\n",
    "                df[\"Year\"] = df[\"Year\"].astype(int)  # Ensure Year is integer\n",
    "            \n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "    return outputdic\n",
    "\n",
    "def process_dax_queries(BrandorManuf,entity_hierarchy, hierarchy_levels):\n",
    "    dfs_results = {}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:\n",
    "                        future = executor.submit(execute_dax_query,BrandorManuf,entity, area, hierby,value)\n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key  \n",
    "                        \n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "                \n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        if BrandorManuf==f'{ManufOrTopC}':\n",
    "            filename = \"manuf_evolution_total.pkl\"\n",
    "        else:\n",
    "            filename = \"brands_evolution_total.pkl\"\n",
    "               \n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "process_dax_queries(f'{ManufOrTopC}',entity_hierarchy, hierarchy_levels)\n",
    "process_dax_queries(f'{BrandOrTopB}',entity_hierarchy, hierarchy_levels)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\calendar_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, entity_type=None, brand=None):\n",
    "    outputdic = {}\n",
    "    key = f\"{brand} | {entity_name}\" if brand else f\"{entity_type} | {entity_name}\"\n",
    "    columns = [\"Value Sales\", \"Av Price/KG\"]\n",
    "\n",
    "    # Handle brand filter correctly\n",
    "    brand_filter = f'Products[{BrandOrTopB}]=\"{brand}\"' if brand else None\n",
    "\n",
    "    if hierby==\"Category\":\n",
    "        filters = [\n",
    "            f'TREATAS({{\"{entity_name}\"}}, Market[{area}])',\n",
    "            \"FILTER('Scope', 'Scope'[Scope] = \\\"{hierby}\\\")\"\n",
    "        ]\n",
    "    else:    \n",
    "        filters = [\n",
    "        f'Products[{hierby}] = \"{entity_type}\"',\n",
    "        f'TREATAS({{\"{entity_name}\"}}, Market[{area}])',\n",
    "        \"FILTER('Scope', 'Scope'[Scope] = \\\"{hierby}\\\")\"\n",
    "    ]\n",
    "    if brand_filter:\n",
    "        filters.append(brand_filter)\n",
    "\n",
    "    # Ensure filters are correctly joined\n",
    "    filter_clause = \",\\n            \".join(filters)\n",
    "\n",
    "    # Construct column expressions\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                    Calendar, \n",
    "                    Calendar[MonthYear]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filter_clause}\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)  # Clean column names\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                    numeric_cols = df.select_dtypes(include='number').columns\n",
    "                    total_values = {}\n",
    "\n",
    "                    for col in numeric_cols:\n",
    "                        if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                            total_values[col] = df[col].mean()  # Take the average\n",
    "                        else:\n",
    "                            total_values[col] = df[col].sum()  # Take the sum\n",
    "                    grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                    df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    \n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands, path):\n",
    "    dfs_results = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:  # Ensure hierarchy_levels is a dict\n",
    "            for value in hier_values:\n",
    "                for area, entity_list in entity_hierarchy:  # Ensure it's dict.items()\n",
    "                    for entity in entity_list:\n",
    "                        future = executor.submit(execute_dax_query, entity, area, hierby, value)\n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key  \n",
    "                        for brand in client_brands:\n",
    "                            if hierby ==\"Category\":\n",
    "                                future = executor.submit(execute_dax_query, entity, area, hierby, value, brand=brand)\n",
    "                                key = f\"{brand} | {entity}\" \n",
    "                                ordered_keys.append(key)\n",
    "                                futures.append(future)\n",
    "                                future_to_key[future] = key  \n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "    # Save results to a pickle file\n",
    "    output_file = f\"{path}\\\\calendar_dfs.pkl\"\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pd.to_pickle(dfs_results, f)\n",
    "\n",
    "    print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "# Run function (ensure variables are defined before calling)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, client_brands, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Overview Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\categories_overview_dfs.pkl.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\categories_overview_manuf_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, entity_type=None, manuf=None):\n",
    "    outputdic = {}\n",
    "    key = f\"{entity_type} | {entity_name}\"\n",
    "    columns = [\"Volume Sales\",\"Value Sales\",\"Volume Sales IYA\",\"Value Sales IYA\",\"IYA Price/KG\"]\n",
    "\n",
    "    # Handle brand filter correctly\n",
    "    manuf_filter = f'FILTER(Products,Products[{ManufOrTopC}]=\"{manuf}\"),' if manuf else \"\"\n",
    "    filters = \", \".join(filter(None, [manuf_filter]))\n",
    "\n",
    "\n",
    "    # Construct DAX query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        SUMMARIZECOLUMNS(\n",
    "            FILTER(Products,Products[{hierby}] = \"{entity_type}\"),\n",
    "            FILTER(Products, Products[Category] = \"{categories[0]}\"),\n",
    "            {manuf_filter}\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Time Logic', 'Time Logic'[Time Period] = \"P12M\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\"),\n",
    "            \"Volume Sales\", COALESCE([Volume Sales], 0),\n",
    "            \"Value Sales\", COALESCE([Value Sales], 0),\n",
    "            \"Volume Sales IYA\", COALESCE([Volume Sales IYA], 0),\n",
    "            \"Value Sales IYA\", COALESCE([Value Sales IYA], 0),\n",
    "            \"IYA Price/KG\", COALESCE([IYA Price/KG], 0)\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)  # Clean column names\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "        \n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    \n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, path,client_manuf=None):\n",
    "    dfs_results = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:  # Ensure hierarchy_levels is a dict\n",
    "            if hierby==\"Category\":\n",
    "                for value in hier_values:\n",
    "                    for area, entity_list in entity_hierarchy:  # Ensure it's dict.items()\n",
    "                        for entity in entity_list:\n",
    "                            if client_manuf:\n",
    "                                for manuf in client_manuf:\n",
    "                                    future = executor.submit(execute_dax_query, entity, area, hierby, value, manuf=manuf)\n",
    "                                    key = f\"{value} | {entity}\" \n",
    "                                    ordered_keys.append(key)\n",
    "                                    futures.append(future)\n",
    "                                    future_to_key[future] = key  \n",
    "                            else:\n",
    "                                future = executor.submit(execute_dax_query, entity, area, hierby, value)\n",
    "                                key = f\"{value} | {entity}\" \n",
    "                                ordered_keys.append(key)\n",
    "                                futures.append(future)\n",
    "                                future_to_key[future] = key  \n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "    # Save results to a pickle file\n",
    "    output_file =f\"{path}\\\\categories_overview_manuf_dfs.pkl\" if client_manuf else f\"{path}\\\\categories_overview_dfs.pkl\"\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pd.to_pickle(dfs_results, f)\n",
    "\n",
    "    print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, path)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, path,client_manuf=client_manuf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Values Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\categories_values_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, entity_type=None):\n",
    "    outputdic = {}\n",
    "    key = f\"{entity_type} | {entity_name}\"\n",
    "    columns = [\"Value Sales\"]\n",
    "\n",
    "    # Collect filters\n",
    "    filters = [\n",
    "        f'Products[Category] = \"{categories[0]}\"',\n",
    "        f'TREATAS({{\"{entity_name}\"}}, Market[{area}])'\n",
    "    ]\n",
    "    # Ensure filters are correctly joined\n",
    "    filter_clause = \",\\n            \".join(filters)\n",
    "\n",
    "    # Construct column expressions\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(\n",
    "                CROSSJOIN(Products, Calendar),\n",
    "                            Calendar[MonthYear],                \n",
    "                            Products[Sector]\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filter_clause}\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)  # Clean column names\n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                    numeric_cols = df.select_dtypes(include='number').columns\n",
    "                    total_values = {}\n",
    "\n",
    "                    for col in numeric_cols:\n",
    "                        if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                            total_values[col] = df[col].mean()  # Take the average\n",
    "                        else:\n",
    "                            total_values[col] = df[col].sum()  # Take the sum\n",
    "                    grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                    df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    \n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, path):\n",
    "    dfs_results = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:  # Ensure hierarchy_levels is a dict\n",
    "            for value in hier_values:\n",
    "                if hierby == \"Category\":\n",
    "                    for area, entity_list in entity_hierarchy:  # Ensure it's dict.items()\n",
    "                        for entity in entity_list:\n",
    "                        # Submit task for each hierarchy level\n",
    "                            future = executor.submit(execute_dax_query, entity, area, hierby, value)\n",
    "                            key = f\"{value} | {entity}\" \n",
    "                            ordered_keys.append(key)\n",
    "                            futures.append(future)\n",
    "                            future_to_key[future] = key  \n",
    "\n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "    # Save results to a pickle file\n",
    "    output_file = f\"{path}\\\\categories_values_dfs.pkl\"\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pd.to_pickle(dfs_results, f)\n",
    "\n",
    "    print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "# Run function (ensure variables are defined before calling)\n",
    "process_dax_queries(entity_hierarchy, hierarchy_levels, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Sec,Seg,.. SCOPE = CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Sector_client_dfs_category.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\Segment_client_dfs_category.pkl.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubSegment_client_dfs_category.pkl.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\SubCategory_client_dfs_category.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area, hierby, filter_p12m, brand=None, manuf=None):\n",
    "    outputdic = {}\n",
    "    \n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "\n",
    "    manuf_filter = f'Products[{ManufOrTopC}]=\"{manuf}\"' if manuf else \"\"\n",
    "    brand_filter = f'Products[{BrandOrTopB}]=\"{brand}\", Products[{ManufOrTopC}]=\"{client_manuf[0]}\"' if brand else \"\"\n",
    "    key = f\"{categories[0]} | {brand} | {entity_name}\" if brand else f\"{categories[0]} | {manuf} | {entity_name}\" if manuf else \"\"\n",
    "    filters = \", \".join(filter(None, [manuf_filter, brand_filter, time_filter]))\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "        \"Value Sales\", \"Value Share\",\"Value Sales IYA\",\"Av Price/KG\",\"WoB %\",\"Volume Sales IYA\",\"IYA Price/KG\"\n",
    "    ]\n",
    "\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "\n",
    "# Construct the DAX query dynamically\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Products, Products[{hierby}]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(entity_hierarchy, hierarchy_levels, time_filter, client_brands=None, client_manuf=None):\n",
    "    dfs_results = {}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            if hierby == \"Category\":\n",
    "                continue\n",
    "            for area, entity_list in entity_hierarchy:\n",
    "                for entity in entity_list:                    \n",
    "                    if client_brands:\n",
    "                        for brand in client_brands:\n",
    "                            future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, brand=brand)\n",
    "                            key = f\"{categories[0]} | {brand} | {entity}\" \n",
    "                            ordered_keys.append(key)\n",
    "                            futures.append(future)\n",
    "                            future_to_key[future] = key  \n",
    "                        for manuf in client_manuf:\n",
    "                            future = executor.submit(execute_dax_query, entity, area, hierby, time_filter, manuf=manuf)\n",
    "                            key = f\"{categories[0]} | {manuf} | {entity}\" \n",
    "                            ordered_keys.append(key)\n",
    "                            futures.append(future)\n",
    "                            future_to_key[future] = key  \n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(future_to_key):\n",
    "                key = future_to_key[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "            # Preserve original key order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "            # Construct the output file name correctly\n",
    "            if client_manuf:\n",
    "                filename = f\"{hierby}_client_dfs_category.pkl\" if time_filter else f\"{hierby}_dfs.pkl\"\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(entity_hierarchy,hierarchy_levels, time_filter=True,client_brands=client_brands,client_manuf=client_manuf)  # Brand-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retailers, Channels, Custom Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Saved DataFrames for Market[Channel] to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_retailer_Channel.pkl.\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Saved DataFrames for Market[Region] to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_channels_Region.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(hierby, filter_p12m, area ,entity_type=None, row_field=None):\n",
    "    outputdic = {}\n",
    "\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "\n",
    "    key = f\"{entity_type}\"\n",
    "    filters = \", \".join(filter(None, [time_filter]))\n",
    "\n",
    "    columns = [\n",
    "        \"Trade WoB %\", \"Trade WoB % DYA\", \"Channel Growth Contribution\",\n",
    "        \"Value Sales\", \"Value Sales IYA\", \"Av Price/KG\", \"Channel Relative Price\",\n",
    "        \"Value Share\", \"IYA Price/KG\", \"Value Share DYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query dynamically with a single row_field\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, {row_field}),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            FILTER(Market, Market[Area] = \"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            df.columns = df.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "            df = df.sort_values('WoB %', ascending=False)              \n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                # Ensure Grand Total is added only once\n",
    "                if \"Grand Total\" not in df.iloc[:, 0].values:\n",
    "                    grand_total_row = pd.DataFrame([[ \"Grand Total\" ] + [total_values.get(col, 0) for col in df.columns[1:]]], columns=df.columns)\n",
    "                    df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "            # Drop duplicate \"Grand Total\" rows, if they still exist\n",
    "            df = df.drop_duplicates(subset=df.columns.tolist())\n",
    "\n",
    "\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels, time_filter,area,row_list):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for row_field in row_list:  # Process each row field separately\n",
    "            dfs_results = {}  # Store results per row field\n",
    "            futures = []\n",
    "            ordered_keys=[]\n",
    "            future_to_key={}\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    future = executor.submit(execute_dax_query, hierby, time_filter, area , value, row_field=row_field)\n",
    "                    key = f\"{value}\" \n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key  \n",
    "\n",
    "            temp_results = {}\n",
    "            for future in as_completed(future_to_key):\n",
    "                key = future_to_key[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "            # Preserve original key order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "            # Save results separately for each row field\n",
    "            if area == \"RETAILER\":\n",
    "                filename = f\"modified_retailer_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == \"CHANNEL\":\n",
    "                filename = f\"modified_channels_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == customareas:\n",
    "                filename = f\"modified_cust_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"Saved DataFrames for {row_field} to {output_file}.\")\n",
    "\n",
    "\n",
    "if \"RETAILER\" in areas:\n",
    "    RET_list = []\n",
    "    if len(regions_RET) != 0:\n",
    "        RET_list.append('Market[Region]')\n",
    "    if len(channels_RET) != 0:\n",
    "        RET_list.append('Market[Channel]')\n",
    "    if len(market_RET) != 0:\n",
    "        RET_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=\"RETAILER\",row_list=RET_list)\n",
    "    \n",
    "if \"CHANNEL\" in areas:\n",
    "    CHA_list = []\n",
    "    if len(regions_CHAN) != 0:\n",
    "       CHA_list.append('Market[Region]')\n",
    "    if len(channels_CHAN) != 0:\n",
    "      CHA_list.append('Market[Channel]')\n",
    "    if len(market_CHAN) != 0:\n",
    "      CHA_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=\"CHANNEL\",row_list=CHA_list)\n",
    "\n",
    "if customareas in areas:\n",
    "    CUST_list=[]\n",
    "    if len(regions_CUST)!=0:\n",
    "        CUST_list.append('Market[Region]')\n",
    "    if len(channels_CUST)!=0:\n",
    "        CUST_list.append('Market[Channel]')\n",
    "    if len(market_CUST)!=0:\n",
    "        CUST_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=f\"{customareas}\",row_list=CUST_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_dax_query(hierby, filter_p12m ,entity_type=None):\n",
    "    outputdic = {}\n",
    "\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "\n",
    "    key = f\"{entity_type}\"\n",
    "    filters = \", \".join(filter(None, [time_filter]))\n",
    "\n",
    "    columns = [\n",
    "        \"Trade WoB %\", \"Trade WoB % DYA\", \"Channel Growth Contribution\",\n",
    "        \"Value Sales\", \"Value Sales IYA\", \"Av Price/KG\", \"Channel Relative Price\",\n",
    "        \"Value Share\", \"IYA Price/KG\", \"Value Share DYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query dynamically with a single row_field\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, Market[Area]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filters},\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "        cursor.execute(dax_query)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        data = cursor.fetchall()\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "        df.columns = df.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "        df = df.sort_values('WoB %', ascending=False)              \n",
    "        if not df.empty:\n",
    "            numeric_cols = df.select_dtypes(include='number').columns\n",
    "            total_values = {}\n",
    "\n",
    "            for col in numeric_cols:\n",
    "                if \"price\" in col.lower():\n",
    "                    total_values[col] = df[col].mean()  # Take the average\n",
    "                else:\n",
    "                    total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "            # Ensure Grand Total is added only once\n",
    "            if \"Grand Total\" not in df.iloc[:, 0].values:\n",
    "                grand_total_row = pd.DataFrame([[ \"Grand Total\" ] + [total_values.get(col, 0) for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "        # Drop duplicate \"Grand Total\" rows, if they still exist\n",
    "        df = df.drop_duplicates(subset=df.columns.tolist())\n",
    "\n",
    "\n",
    "        outputdic[key] = df\n",
    "        # print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "    # print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels, time_filter):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Process each row field separately\n",
    "        dfs_results = {}\n",
    "        futures = []\n",
    "        ordered_keys = []\n",
    "        future_to_key = {}\n",
    "\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    future = executor.submit(execute_dax_query, hierby, time_filter, value)\n",
    "                    key = f\"{value}\" \n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key  \n",
    "\n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "        for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]       \n",
    "        \n",
    "        filename = \"modified_national.pkl\"\n",
    "\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "process_dax_queries(hierarchy_levels, time_filter=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_dax_query(hierby, filter_p12m ,entity_type=None, manuf=None, brand=None):\n",
    "    outputdic = {}\n",
    "\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "    manuf_filter = f'Products[{ManufOrTopC}]=\"{manuf}\"' if manuf else \"\"\n",
    "    brand_filter = f'Products[{BrandOrTopB}]=\"{brand}\", Products[{ManufOrTopC}]=\"{client_manuf[0]}\"' if brand else \"\"\n",
    "\n",
    "    key = f\"{entity_type} | {brand}\" if brand else f\"{entity_type} | {manuf}\" if manuf else \"\"\n",
    "    filters = \", \".join(filter(None, [manuf_filter, brand_filter, time_filter]))\n",
    "\n",
    "    columns = [\n",
    "        \"Trade WoB %\", \"Trade WoB % DYA\", \"Channel Growth Contribution\",\n",
    "        \"Value Sales\", \"Value Sales IYA\", \"Av Price/KG\", \"Channel Relative Price\",\n",
    "        \"Value Share\", \"IYA Price/KG\", \"Value Share DYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query dynamically with a single row_field\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, Market[Area]),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {filters},\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "        cursor.execute(dax_query)\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        data = cursor.fetchall()\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "        df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "        df.columns = df.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "        df = df.sort_values('WoB %', ascending=False)              \n",
    "        if not df.empty:\n",
    "            numeric_cols = df.select_dtypes(include='number').columns\n",
    "            total_values = {}\n",
    "\n",
    "            for col in numeric_cols:\n",
    "                if \"price\" in col.lower():\n",
    "                    total_values[col] = df[col].mean()  # Take the average\n",
    "                else:\n",
    "                    total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "            # Ensure Grand Total is added only once\n",
    "            if \"Grand Total\" not in df.iloc[:, 0].values:\n",
    "                grand_total_row = pd.DataFrame([[ \"Grand Total\" ] + [total_values.get(col, 0) for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "        # Drop duplicate \"Grand Total\" rows, if they still exist\n",
    "        df = df.drop_duplicates(subset=df.columns.tolist())\n",
    "\n",
    "\n",
    "        outputdic[key] = df\n",
    "        # print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "    # print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels, time_filter, client_manuf=None, client_brands=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Process each row field separately\n",
    "        dfs_results = {}\n",
    "        futures = []\n",
    "        ordered_keys = []\n",
    "        future_to_key = {}\n",
    "\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for manuf in client_manuf:\n",
    "                    future = executor.submit(execute_dax_query, hierby, time_filter, value, manuf=manuf)\n",
    "                    key = f\"{hierby}:{value} | {manuf}\" \n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key  \n",
    "                for brand in client_brands:\n",
    "                    future = executor.submit(execute_dax_query, hierby, time_filter, value, brand=brand)\n",
    "                    key = f\"{hierby}:{value} | {brand}\" \n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key  \n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                dfs_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "        if client_brands:\n",
    "            filename= \"modified_national_client.pkl\" \n",
    "\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "process_dax_queries(hierarchy_levels, time_filter=True, client_manuf=client_manuf, client_brands=client_brands)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retailers, Channels, Custom For CLIENTS Dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_retailer_Channel_client.pkl.\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_channels_Region_client.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(hierby, filter_p12m,area,entity_type=None,row_field=None, brand=None, manuf=None):\n",
    "    outputdic = {}\n",
    "\n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "\n",
    "    manuf_filter = f'Products[{ManufOrTopC}]=\"{manuf}\"' if manuf else \"\"\n",
    "    brand_filter = f'Products[{BrandOrTopB}]=\"{brand}\", Products[{ManufOrTopC}]=\"{client_manuf[0]}\"' if brand else \"\"\n",
    "\n",
    "    key = f\"{entity_type} | {brand}\" if brand else f\"{entity_type} | {manuf}\" if manuf else \"\"\n",
    "    filters = \", \".join(filter(None, [manuf_filter, brand_filter, time_filter]))\n",
    "\n",
    "    columns = [\n",
    "        \"Trade WoB %\", \"Trade WoB % DYA\", \"Channel Growth Contribution\",\n",
    "        \"Value Sales\", \"Value Sales IYA\", \"Av Price/KG\", \"Channel Relative Price\",\n",
    "        \"Value Share\", \"IYA Price/KG\", \"Value Share DYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct the DAX query dynamically\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                SUMMARIZE(Market, {row_field}),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({years}, Calendar[Year]),\n",
    "            {filters},\n",
    "            FILTER(Products,Products[{hierby}] = \"{entity_type}\"),\n",
    "            Filter(Market,Market[Area]=\"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "            \n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            df.columns = df.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "            df = df.sort_values('Value Share', ascending=False)  \n",
    "            df = df.sort_values('WoB %', ascending=False)  \n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                # Ensure Grand Total is added only once\n",
    "                if \"Grand Total\" not in df.iloc[:, 0].values:\n",
    "                    grand_total_row = pd.DataFrame([[ \"Grand Total\" ] + [total_values.get(col, 0) for col in df.columns[1:]]], columns=df.columns)\n",
    "                    df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "            # Drop duplicate \"Grand Total\" rows, if they still exist\n",
    "            df = df.drop_duplicates(subset=df.columns.tolist())\n",
    "\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels, time_filter,area,row_list, client_brands=None, client_manuf=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for row_field in row_list:  # Process each row field separately\n",
    "            dfs_results = {}\n",
    "            futures = []\n",
    "            ordered_keys=[]\n",
    "            future_to_key={}\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    if client_brands:\n",
    "                        for brand in client_brands:\n",
    "                            future = executor.submit(execute_dax_query, hierby, time_filter,area,value,row_field=row_field,brand=brand)\n",
    "                            key = f\"{value } | {brand}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            futures.append(future)\n",
    "                            future_to_key[future] = key  \n",
    "                        for manuf in client_manuf:\n",
    "                            future = executor.submit(execute_dax_query, hierby, time_filter,area,value,row_field=row_field,manuf=manuf)\n",
    "                            key = f\"{value } | {manuf}\"\n",
    "                            ordered_keys.append(key)\n",
    "                            futures.append(future)\n",
    "                            future_to_key[future] = key \n",
    "                            \n",
    "                temp_results = {}\n",
    "                for future in as_completed(future_to_key):\n",
    "                    key = future_to_key[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        temp_results.update(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "                # Preserve original key order\n",
    "                for key in ordered_keys:\n",
    "                    if key in temp_results:\n",
    "                        dfs_results[key] = temp_results[key]\n",
    "\n",
    "            # Construct the output file name correctly\n",
    "            if client_manuf:\n",
    "                if area == \"RETAILER\":\n",
    "                    filename = f\"modified_retailer_{row_field.split('[')[-1][:-1]}_client.pkl\"\n",
    "                elif area == \"CHANNEL\":\n",
    "                    filename = f\"modified_channels_{row_field.split('[')[-1][:-1]}_client.pkl\"\n",
    "                elif area == customareas:\n",
    "                    filename = f\"modified_cust_{row_field.split('[')[-1][:-1]}_client.pkl\"\n",
    "            \n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "            \n",
    "if \"RETAILER\" in areas:\n",
    "    RET_list = []\n",
    "    if len(regions_RET) != 0:\n",
    "        RET_list.append('Market[Region]')\n",
    "    if len(channels_RET) != 0:\n",
    "        RET_list.append('Market[Channel]')\n",
    "    if len(market_RET) != 0:\n",
    "        RET_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=\"RETAILER\",row_list=RET_list,client_brands=client_brands,client_manuf=client_manuf)\n",
    "if \"CHANNEL\" in areas:\n",
    "    CHA_list = []\n",
    "    if len(regions_CHAN) != 0:\n",
    "       CHA_list.append('Market[Region]')\n",
    "    if len(channels_CHAN) != 0:\n",
    "      CHA_list.append('Market[Channel]')\n",
    "    if len(market_CHAN) != 0:\n",
    "      CHA_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=\"CHANNEL\",row_list=CHA_list,client_brands=client_brands,client_manuf=client_manuf)\n",
    "\n",
    "if customareas in areas:\n",
    "    CUST_list=[]\n",
    "    if len(regions_CUST)!=0:\n",
    "        CUST_list.append('Market[Region]')\n",
    "    if len(channels_CUST)!=0:\n",
    "        CUST_list.append('Market[Channel]')\n",
    "    if len(market_CUST)!=0:\n",
    "        CUST_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, time_filter=True,area=f\"{customareas}\",row_list=CUST_list,client_brands=client_brands,client_manuf=client_manuf)\n",
    "\n",
    "# process_dax_queries(hierarchy_levels, time_filter=True,client_brands=client_brands,client_manuf=client_manuf)  # Brand-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Analysis Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Category | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for Segment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for Sector | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubSegment | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Query executed successfully for SubCategory | Market[Channel].\n",
      "Saved DataFrames for Market[Channel] to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_retailer_Channel.pkl.\n",
      "Query executed successfully for Category | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for Sector | Market[Region].\n",
      "Query executed successfully for Segment | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubSegment | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Query executed successfully for SubCategory | Market[Region].Query executed successfully for SubSegment | Market[Region].\n",
      "\n",
      "Query executed successfully for SubCategory | Market[Region].\n",
      "Saved DataFrames for Market[Region] to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_channels_Region.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(hierby, area ,entity_type=None, row_field=None):\n",
    "    outputdic = {}\n",
    "    time_periods = '{\"P3M\", \"P12M\"}'  # Correct format for DAX\n",
    "\n",
    "\n",
    "    key = f\"{entity_type} | {area} | {row_field.split('[')[-1][:-1]}\"\n",
    "\n",
    "    columns = [\n",
    "        \"Value Sales\",\"Value Share\", \"Value Share DYA\"\n",
    "    ]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    # Construct DAX query dynamically with a single row_field\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                \n",
    "                SUMMARIZE(Products, Products[{BrandOrTopB}]),  \n",
    "                SUMMARIZE(Market, {row_field}),\n",
    "                VALUES('Time Logic'[Time Period])\n",
    "                ),\n",
    "\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({{\"P3M\", \"P12M\"}}, 'Time Logic'[Time Period]),\n",
    "            FILTER(Products, Products[{hierby}] = \"{entity_type}\"),\n",
    "            FILTER(Market, Market[Area] = \"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            df.columns = df.columns.str.replace('Trade ', '').str.replace('Channel ','').str.strip()\n",
    "            df = df.drop_duplicates()\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {hierby} | {row_field}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {hierby} {entity_type} | {row_field}: {db_error}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(hierarchy_levels,area,row_list):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for row_field in row_list:  # Process each row field separately\n",
    "            dfs_results = {}  # Store results per row field\n",
    "            futures = []\n",
    "            ordered_keys=[]\n",
    "            future_to_key={}\n",
    "            for hierby, hier_values in hierarchy_levels:\n",
    "                for value in hier_values:\n",
    "                    future = executor.submit(execute_dax_query, hierby, area , value, row_field=row_field)\n",
    "                    key = f\"{value} | {area} | {row_field.split('[')[-1][:-1]}\"\n",
    "                    ordered_keys.append(key)\n",
    "                    futures.append(future)\n",
    "                    future_to_key[future] = key \n",
    "            temp_results = {}\n",
    "            for future in as_completed(future_to_key):\n",
    "                key = future_to_key[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "            # Preserve original key order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "            # Save results separately for each row field\n",
    "            if area == \"RETAILER\":\n",
    "                filename = f\"modified_momentum_retailer_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == \"CHANNEL\":\n",
    "                filename = f\"modified_momentum_channels_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == customareas:\n",
    "                filename = f\"modified_momentum_cust_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"Saved DataFrames for {row_field} to {output_file}.\")\n",
    "\n",
    "\n",
    "if \"RETAILER\" in areas:\n",
    "    RET_list = []\n",
    "    if len(regions_RET) != 0:\n",
    "        RET_list.append('Market[Region]')\n",
    "    if len(channels_RET) != 0:\n",
    "        RET_list.append('Market[Channel]')\n",
    "    if len(market_RET) != 0:\n",
    "        RET_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, area=\"RETAILER\",row_list=RET_list)\n",
    "    \n",
    "if \"CHANNEL\" in areas:\n",
    "    CHA_list = []\n",
    "    if len(regions_CHAN) != 0:\n",
    "       CHA_list.append('Market[Region]')\n",
    "    if len(channels_CHAN) != 0:\n",
    "      CHA_list.append('Market[Channel]')\n",
    "    if len(market_CHAN) != 0:\n",
    "      CHA_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, area=\"CHANNEL\",row_list=CHA_list)\n",
    "\n",
    "if customareas in areas:\n",
    "    CUST_list=[]\n",
    "    if len(regions_CUST)!=0:\n",
    "        CUST_list.append('Market[Region]')\n",
    "    if len(channels_CUST)!=0:\n",
    "        CUST_list.append('Market[Channel]')\n",
    "    if len(market_CUST)!=0:\n",
    "        CUST_list.append('Market[Market]')\n",
    "    process_dax_queries(hierarchy_levels, area=f\"{customareas}\",row_list=CUST_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum{\"P3M\", \"P12M\"} Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\momentum_dfs.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(entity_name, area):\n",
    "    outputdic = {}\n",
    "    time_periods = '{\"P3M\", \"P12M\"}'  # Correct format for DAX\n",
    "\n",
    "    key = f\"{categories[0]} | {entity_name}\"\n",
    "    columns = [\"Value Sales\", \"Value Share\",\"Value Share DYA\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                    SUMMARIZE(Products, Products[{BrandOrTopB}]), \n",
    "                    SUMMARIZE(Products, Products[Sector]), \n",
    "                    VALUES('Time Logic'[Time Period])\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({time_periods}, 'Time Logic'[Time Period]),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "def process_dax_queries(entity_hierarchy):\n",
    "    dfs_results = {}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for area, entity_list in entity_hierarchy:\n",
    "            for entity in entity_list:\n",
    "                future = executor.submit(execute_dax_query, entity, area)\n",
    "                key = f\"{categories[0]} | {entity}\"\n",
    "                ordered_keys.append(key)\n",
    "                futures.append(future)\n",
    "                future_to_key[future] = key     \n",
    "                \n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        filename = \"momentum_dfs.pkl\"\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(entity_hierarchy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum hierarchy Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for RETAILER.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_seg_retailer_Channel.pkl.\n",
      "Query executed successfully for RETAILER.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_subseg_retailer_Channel.pkl.\n",
      "Query executed successfully for RETAILER.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_subcat_retailer_Channel.pkl.\n",
      "Query executed successfully for CHANNEL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_seg_channels_Region.pkl.\n",
      "Query executed successfully for CHANNEL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_subseg_channels_Region.pkl.\n",
      "Query executed successfully for CHANNEL.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\modified_momentum_subcat_channels_Region.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(area,row_field=None):\n",
    "    outputdic = {}\n",
    "    time_periods = '{\"P3M\", \"P12M\"}'  # Correct format for DAX\n",
    "\n",
    "    key = f\"{categories[0]} | {area} | {row_field.split('[')[-1][:-1]}\"\n",
    "    \n",
    "    columns = [\"Value Sales\", \"Value Share\",\"Value Share DYA\"]\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "    row_list = [\n",
    "        f\"SUMMARIZE(Products, Products[{BrandOrTopB}])\"\n",
    "    ]\n",
    "    row_list.extend([\n",
    "    f\"SUMMARIZE(Market, {row_field})\"\n",
    "    ])\n",
    "    if her_list:\n",
    "        row_list.append(f\"SUMMARIZE(Products, {', '.join(her_list)})\")\n",
    "    row_list.extend([\"VALUES('Time Logic'[Time Period])\"])\n",
    "\n",
    " \n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "                    {\", \".join(row_list)}\n",
    "\n",
    "                ),\n",
    "                {column_exprs}\n",
    "            ),\n",
    "            TREATAS({time_periods}, 'Time Logic'[Time Period]),\n",
    "            Products[Category] = \"{categories[0]}\",\n",
    "            FILTER(Market, Market[Area] = \"{area}\"),\n",
    "            FILTER('Scope', 'Scope'[Scope] = \"Category\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "            outputdic[key] = df\n",
    "            print(f\"Query executed successfully for {area}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {row_field} in {area}: {db_error}\")\n",
    "    \n",
    "    return outputdic\n",
    "\n",
    "\n",
    "def process_dax_queries(area, row_list,her=None):\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for row_field in row_list:  # Process each row field separately\n",
    "            dfs_results = {}\n",
    "            futures = []        \n",
    "            ordered_keys=[]\n",
    "            future_to_key={}\n",
    "            future = executor.submit(execute_dax_query, area, row_field=row_field)\n",
    "            key = f\"{categories[0]} | {area} | {row_field.split('[')[-1][:-1]}\"\n",
    "            ordered_keys.append(key)\n",
    "            futures.append(future)\n",
    "            future_to_key[future] = key       \n",
    "            temp_results = {}\n",
    "            for future in as_completed(future_to_key):\n",
    "                key = future_to_key[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    temp_results.update(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "            # Preserve original key order\n",
    "            for key in ordered_keys:\n",
    "                if key in temp_results:\n",
    "                    dfs_results[key] = temp_results[key]\n",
    "\n",
    "            if area == \"RETAILER\":\n",
    "                filename = f\"modified_momentum_{her}_retailer_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == \"CHANNEL\":\n",
    "                filename = f\"modified_momentum_{her}_channels_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            elif area == customareas:\n",
    "                filename = f\"modified_momentum_{her}_cust_{row_field.split('[')[-1][:-1]}.pkl\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected area: {area}. Cannot determine filename.\")\n",
    "\n",
    "            output_file = f\"{path}\\\\{filename}\"\n",
    "            \n",
    "            with open(output_file, \"wb\") as f:\n",
    "                pd.to_pickle(dfs_results, f)\n",
    "\n",
    "            print(f\"All DataFrames saved to {output_file}.\")\n",
    "if any([segments, subsegments, subcategories]):\n",
    "    if \"RETAILER\" in areas:\n",
    "        RET_list=[]\n",
    "        if regions_RET:\n",
    "            RET_list.append('Market[Region]')\n",
    "        if channels_RET:\n",
    "            RET_list.append('Market[Channel]')\n",
    "        if market_RET:\n",
    "            RET_list.append('Market[Market]')\n",
    "        if segments:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[Segment]\")\n",
    "            process_dax_queries(area=\"RETAILER\", row_list=RET_list,her=\"seg\")\n",
    "        if subsegments:\n",
    "            her_list = []         \n",
    "            her_list.append('Products[Sector]')    \n",
    "            her_list.append('Products[SubSegment]')  \n",
    "            process_dax_queries(area=\"RETAILER\", row_list=RET_list,her=\"subseg\")\n",
    "        if subcategories:   \n",
    "            her_list = []      \n",
    "            her_list.append('Products[Sector]')    \n",
    "            her_list.append('Products[SubCategory]')     \n",
    "            process_dax_queries(area=\"RETAILER\", row_list=RET_list,her=\"subcat\")\n",
    "\n",
    "    if \"CHANNEL\" in areas:\n",
    "        CHA_list=[]\n",
    "        if len(regions_CHAN) != 0:\n",
    "            CHA_list.append('Market[Region]')\n",
    "        if len(channels_CHAN) != 0:\n",
    "            CHA_list.append('Market[Channel]')\n",
    "        if len(market_CHAN) != 0:\n",
    "            CHA_list.append('Market[Market]')\n",
    "        if segments:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[Segment]\")\n",
    "            process_dax_queries(area=\"CHANNEL\",row_list=CHA_list,her=\"seg\")\n",
    "        if subsegments:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[SubSegment]\")\n",
    "            process_dax_queries(area=\"CHANNEL\",row_list=CHA_list,her=\"subseg\")\n",
    "        if subcategories:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[SubCategory]\")\n",
    "            process_dax_queries(area=\"CHANNEL\",row_list=CHA_list,her=\"subcat\")        \n",
    "\n",
    "    if customareas in areas:\n",
    "        CUST_list=[]\n",
    "        if len(regions_CUST)!=0:\n",
    "            CUST_list.append('[Market].[Region]')\n",
    "        if len(channels_CUST)!=0:\n",
    "            CUST_list.append('[Market].[Channel]')\n",
    "        if len(market_CUST)!=0:\n",
    "            CUST_list.append('[Market].[Market]')\n",
    "        if segments:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[Segment]\")    \n",
    "            process_dax_queries(area=f\"{customareas}\",row_list=CUST_list,her=\"seg\")\n",
    "        if subsegments:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[SubSegment]\")    \n",
    "            process_dax_queries(area=f\"{customareas}\",row_list=CUST_list,her=\"subseg\")\n",
    "        if subcategories:\n",
    "            her_list = []\n",
    "            her_list.append(\"Products[Sector]\")\n",
    "            her_list.append(\"Products[SubCategory]\")    \n",
    "            process_dax_queries(area=f\"{customareas}\",row_list=CUST_list,her=\"subcat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue PVM Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\revenue_PVM_brand.pkl.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Bj's Corp.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for NATIONAL.\n",
      "Query executed successfully for Conv.\n",
      "Query executed successfully for Food.\n",
      "Query executed successfully for Drug.\n",
      "Query executed successfully for Sam's Corp.\n",
      "Query executed successfully for Walmart.\n",
      "Query executed successfully for Bj's Corp.\n",
      "All DataFrames saved to c:\\Users\\Ali Salem\\Desktop\\App_Update\\Landscape\\Landscape Datasets Test\\revenue_PVM_manuf.pkl.\n"
     ]
    }
   ],
   "source": [
    "def execute_dax_query(BrandOrManuf,entity_name, area, hierby, filter_p12m,entity_type=None):\n",
    "    outputdic = {}\n",
    "    \n",
    "    time_filter = \"\"\"\n",
    "        FILTER(\n",
    "            VALUES('Time Logic'[Time Period]), \n",
    "            'Time Logic'[Time Period] = \"P12M\"\n",
    "        )\n",
    "    \"\"\" if filter_p12m else \"\"\n",
    "    key = f\"{entity_type} | {entity_name}\" \n",
    "    filters = \", \".join(filter(None, [time_filter]))\n",
    "\n",
    "    # Define columns dynamically\n",
    "    columns = [\n",
    "         \"Revenue By PVM\",\"Value Share\"]\n",
    "    \n",
    "\n",
    "    column_exprs = \", \".join(f'\"{col}\", COALESCE([{col}], 0)' for col in columns)\n",
    "\n",
    "\n",
    "    dax_query = f\"\"\"\n",
    "        EVALUATE\n",
    "        CALCULATETABLE(\n",
    "            ADDCOLUMNS(\n",
    "                CROSSJOIN(\n",
    "   \n",
    "                SUMMARIZE(Products, Products[{BrandOrManuf}]), \n",
    "                SUMMARIZE(PVM, PVM[Revenue Group]) \n",
    "              ),  \n",
    "                {column_exprs}\n",
    "            ),\n",
    "            {time_filter},\n",
    "            FILTER(Products,Products[{hierby}] = \"{entity_type}\"),\n",
    "            TREATAS({{\"{entity_name}\"}}, Market[{area}]),   \n",
    "            FILTER('Scope', 'Scope'[Scope] = \"{hierby}\")\n",
    "        )   \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with adodbapi.connect(conn_str) as conn, conn.cursor() as cursor:\n",
    "            cursor.execute(dax_query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df.columns = df.columns.str.replace(r'.*\\[|\\]', '', regex=True)         \n",
    "            df = df.loc[~(df.select_dtypes(include='number') == 0).all(axis=1)]  # Remove zero rows\n",
    "            if not df.empty:\n",
    "                numeric_cols = df.select_dtypes(include='number').columns\n",
    "                total_values = {}\n",
    "\n",
    "                for col in numeric_cols:\n",
    "                    if \"price\" in col.lower():  # Check if the column name contains \"price\" (case insensitive)\n",
    "                        total_values[col] = df[col].mean()  # Take the average\n",
    "                    else:\n",
    "                        total_values[col] = df[col].sum()  # Take the sum\n",
    "\n",
    "                grand_total_row = pd.DataFrame([[\"Grand Total\"] + [total_values.get(col, \" \") for col in df.columns[1:]]], columns=df.columns)\n",
    "                df = pd.concat([df, grand_total_row], ignore_index=True)\n",
    "\n",
    "            outputdic[key] = df\n",
    "            \n",
    "            print(f\"Query executed successfully for {entity_name}.\")\n",
    "    except adodbapi.DatabaseError as db_error:\n",
    "        print(f\"Database error for {entity_name} in {area}: {db_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {entity_name} in {area}: {e}\")\n",
    "\n",
    "    return outputdic\n",
    "\n",
    "\n",
    "\n",
    "def process_dax_queries(BrandOrManuf,entity_hierarchy, hierarchy_levels, time_filter):\n",
    "    dfs_results = {}\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = []\n",
    "        ordered_keys=[]\n",
    "        future_to_key={}\n",
    "        for hierby, hier_values in hierarchy_levels:\n",
    "            for value in hier_values:\n",
    "                for area, entity_list in entity_hierarchy:\n",
    "                    for entity in entity_list:                    \n",
    "                        future = executor.submit(execute_dax_query,BrandOrManuf, entity, area, hierby, time_filter,value)\n",
    "                        key = f\"{value} | {entity}\"\n",
    "                        ordered_keys.append(key)\n",
    "                        futures.append(future)\n",
    "                        future_to_key[future] = key     \n",
    "        temp_results = {}\n",
    "        for future in as_completed(future_to_key):\n",
    "            key = future_to_key[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                temp_results.update(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve result for {key}: {e}\")\n",
    "\n",
    "        # Preserve original key order\n",
    "        for key in ordered_keys:\n",
    "            if key in temp_results:\n",
    "                dfs_results[key] = temp_results[key]\n",
    "\n",
    "        # Construct the output file name correctly\n",
    "        if BrandOrManuf==f'{BrandOrTopB}':\n",
    "            filename = f\"revenue_PVM_brand.pkl\"\n",
    "        else:\n",
    "            filename = f\"revenue_PVM_manuf.pkl\"\n",
    "\n",
    "        output_file = f\"{path}\\\\{filename}\"\n",
    "\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pd.to_pickle(dfs_results, f)\n",
    "\n",
    "        print(f\"All DataFrames saved to {output_file}.\")\n",
    "\n",
    "\n",
    "process_dax_queries(f\"{BrandOrTopB}\",entity_hierarchy,hierarchy_levels, time_filter=True)  # Brand-level\n",
    "process_dax_queries(f\"{ManufOrTopC}\",entity_hierarchy,hierarchy_levels, time_filter=True)  # Brand-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started at: Wed Sep  3 14:58:34 2025\n",
      "Script ended at: Wed Sep  3 15:17:42 2025\n",
      "Elapsed time: 1147.99 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Script started at: {time.ctime(start_time)}\")\n",
    "print(f\"Script ended at: {time.ctime(end_time)}\")\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0835"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1265.01 /60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = {}\n",
    "datasets_path =os.getcwd()+\"\\\\Landscape Datasets Test\\\\\"\n",
    "datasets = os.listdir(datasets_path)\n",
    "for d in datasets:\n",
    "    with open(datasets_path+d, 'rb') as handle:\n",
    "        globals()[d.split('.')[0]] = pd.read_pickle(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
