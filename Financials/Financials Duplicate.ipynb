{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'C:\\\\Users\\\\Ali Salem\\\\Desktop\\\\App_Update\\\\static/files\\\\parameters.xlsx'\n",
    "slides_name = ['Trade Margin Table By Sector', 'Trade Margin Table By Segment', 'Trade Margin Table By Subsegment', 'Trade Margin Table By Subcategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & reading pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%run \"{os.path.dirname(os.getcwd())}\\general_functions\\generalFunctions.ipynb\" #container\n",
    "\n",
    "%run \"{os.getcwd()}\\Financials Replacement Function.ipynb\" #container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali Salem\\Desktop\\App_Update\\parameters.xlsx\n"
     ]
    }
   ],
   "source": [
    "filename = 'parameters.xlsx'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the full path to the file\n",
    "f_path = os.path.join(current_dir, filename)\n",
    "print(f_path)\n",
    "#xls = pd.ExcelFile(f_path)\n",
    "parm = pd.read_excel(f_path, sheet_name='Financials')\n",
    "fields = dict(zip(parm['Field'],parm['Value']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "themePath = os.getcwd()+\"\\Theme1.thmx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Schick', 'Equate', 'Cremo'],\n",
       " 'Top Companies',\n",
       " 2,\n",
       " 'Before',\n",
       " '$ ',\n",
       " 'SKU',\n",
       " ['Manual Shave Men'])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server = \"powerbi://api.powerbi.com/v1.0/myorg/\"+ fields['server']\n",
    "dataset_name = fields['f_name']\n",
    "f_name = os.getcwd()+\"/\"+fields['f_name']+\".xlsx\"\n",
    "\n",
    "client_manuf = list(set(fields['client_manuf'].split(','))-set(['']))\n",
    "client_brands = list(set(fields['client_brands'].split(','))-set(['']))\n",
    "\n",
    "ManufOrTopC = fields['ManufOrTopC']\n",
    "BrandOrTopB = fields['BrandOrTopB']\n",
    "\n",
    "decimals = fields['decimals']\n",
    "sign = fields['sign']\n",
    "currency = fields['currency']\n",
    "currency = ' '+ currency if sign.lower() == 'after' else  currency + ' ' \n",
    "\n",
    "prodORitem=fields[\"prodORitem\"]\n",
    "categories = list(set(fields['categories'].split(','))-set(['']))\n",
    "sectors=list(set(fields['sectors'].split(','))-set(['']))\n",
    "segments=list(set(fields['segments'].split(','))-set(['']))\n",
    "subsegments=list(set(fields['subsegments'].split(','))-set(['']))\n",
    "subcategories=list(set(fields['subcategories'].split(','))-set(['']))\n",
    "\n",
    "national=fields['national']\n",
    "customareas=fields['customareas']\n",
    "print(fields['customareas'])\n",
    "if pd.isna(customareas):\n",
    "    customareas = ''\n",
    "areas = list(set(fields['areas'].split(','))-set(['']))+[customareas]\n",
    "areas = [a for a in areas if a != '']\n",
    "\n",
    "regions_RET = list(set(fields['regions_RET'].split(','))-set(['']))\n",
    "channels_RET = list(set(fields['channels_RET'].split(','))-set(['']))\n",
    "market_RET=list(set(fields['market_RET'].split(','))-set(['']))\n",
    "\n",
    "regions_CHAN=list(set(fields['regions_CHAN'].split(','))-set(['']))\n",
    "channels_CHAN=list(set(fields['channels_CHAN'].split(','))-set(['']))\n",
    "market_CHAN=list(set(fields['market_CHAN'].split(','))-set(['']))\n",
    "\n",
    "regions_CUST=list(set(fields['regions_CUST'].split(','))-set(['']))\n",
    "channels_CUST=list(set(fields['channels_CUST'].split(','))-set(['']))\n",
    "market_CUST=list(set(fields['market_CUST'].split(','))-set(['']))\n",
    "\n",
    "data_source=fields['data_source']\n",
    "\n",
    "years=list(set(fields['years'].split(','))-set(['']))\n",
    "end_date=fields['end_date']\n",
    "\n",
    "brands_only=fields['brands_only']\n",
    "National=[\"NATIONAL\"]if national else []\n",
    "percent = fields['percent']\n",
    "percentstr= fields['percentstr']\n",
    "\n",
    "\n",
    "client_brands,ManufOrTopC,decimals,sign,currency,prodORitem,categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_RET + regions_CHAN + regions_CUST\n",
    "channels = channels_RET + channels_CHAN + channels_CUST\n",
    "markets = market_RET + market_CHAN + market_CUST\n",
    "\n",
    "entity_hierarchy = [\n",
    "    (\"Area\",National),\n",
    "    (\"Region\", regions),\n",
    "    (\"Channel\", channels),\n",
    "    (\"Market\", markets)\n",
    "]\n",
    "hierarchy_levels = [\n",
    "    (\"Category\", categories),\n",
    "    (\"Sector\", sectors),\n",
    "    (\"Segment\", segments),\n",
    "    (\"SubSegment\", subsegments),\n",
    "    (\"SubCategory\", subcategories)\n",
    "]\n",
    "\n",
    "direct_parent = {\"Sector\":list(zip([\"Category\"]*len(categories),categories))\n",
    "                ,\"Segment\":list(zip([\"Sector\"]*len(sectors),sectors))\n",
    "                #,\"SubSegment\":list(zip([\"Segment\"]*len(sectors),sectors))\n",
    "                #,\"SubCategory\":list(zip([\"Segment\"]*len(segments),segments))\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_manuf = [\"Pbg\"]\n",
    "# client_brands = [\"Schick\",\"Equate\",\"Cremo\"]\n",
    " \n",
    "# decimals = 2\n",
    "# sign = \"Before\"\n",
    "# currency = '$'\n",
    "# currency = ' '+ currency if sign.lower() == 'after' else  currency + ' '\n",
    " \n",
    "# prodORitem = \"SKU\"\n",
    "# categories = [\"Manual Shave Men\"]\n",
    "# sectors = [\"System\",\"Disposables\"]\n",
    "# segments = [\"Razors\",\"Refills\",\"Disposables\"]\n",
    "# subsegments= []\n",
    "# subcategories= []\n",
    "\n",
    "# national = False\n",
    "# customareas= \"REGIONS\"\n",
    "# areas = [\"RETAILER\", f\"{customareas}\"]\n",
    "\n",
    "# regions_RET  = [\"Walmart\"]\n",
    "# channels_RET = []\n",
    "# market_RET = [\"Walmart Div1 Corp\", \"Walmart Nm Corp\",\"Walmart Sc Corp\"]\n",
    "\n",
    "# regions_CHAN = []\n",
    "# channels_CHAN = []\n",
    "# market_CHAN = []\n",
    " \n",
    "# regions_CUST = []\n",
    "# channels_CUST = []\n",
    "# market_CUST = [\"Walmart East\", \"Walmart North\",\"Walmart Southeast\",\"Walmart Southwest\",\"Walmart West\"]\n",
    "\n",
    "\n",
    "# data_source = \"DATA SOURCE: Client P&L\"\n",
    "\n",
    "# end_date = \"2025-04-01\"\n",
    "\n",
    "# OpenEditData=True\n",
    "# ManufOrTopC =\"Top Companies\"\n",
    "# BrandOrTopB=\"Top Brands\"\n",
    "\n",
    "# percent = 1000000\n",
    "# percentstr=\"'000 000\"\n",
    "# ### OpenEditData is a parameter (run open excel cell or not )\n",
    "# OpenEditData=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "national = ['National'] if \"NATIONAL\" in areas else []\n",
    "retailers = regions_RET + channels_RET + market_RET\n",
    "channels = regions_CHAN + channels_CHAN + market_CHAN\n",
    "cust = regions_CUST + channels_CUST + market_CUST\n",
    "area=national+retailers+channels+cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali Salem\\Desktop\\App_Update\\Financials\\Financials Datasets Test\\\n"
     ]
    }
   ],
   "source": [
    "loaded_data = {}\n",
    "\n",
    "datasets_path = os.getcwd()+\"\\\\\"\"Financials Datasets Test\"\"\\\\\"\n",
    "print(datasets_path)\n",
    "\n",
    "datasets = os.listdir(datasets_path)\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(datasets_path, dataset)\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        globals()[dataset.split('.')[0]] = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacement functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide1: Mix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_P12M_dfs={}\n",
    "for k in brands_client_dfs.keys():\n",
    "    t=brands_client_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] = t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t=t.fillna(0)\n",
    "    t = t[t['Net Sales'].astype(float) >= 1000]\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    if not t.empty and len(t['Top Brands']) != 1:\n",
    "        modified_brand_P12M_dfs[k]=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RET_CHAN_POS(dataframes,regions, channels, markets):\n",
    "    modified_regions = {}\n",
    "    modified_channels = {}\n",
    "    modified_markets = {}\n",
    "    dya = {}\n",
    "\n",
    "    for k in dataframes.keys():\n",
    "        t = dataframes[k].copy()\n",
    "        t = t[t[\"Net Sales\"].astype(float)>=1000]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199) \n",
    "\n",
    "        level_check = set([\"Region\", \"Channel\", \"Market\"])\n",
    "        existant_cols = list(set(t.columns)&level_check)\n",
    "\n",
    "        decider_dic = {\"Region\": regions, \"Channel\":channels, \"Market\":markets}\n",
    "        grand_tot = t[t[t.columns[0]] == 'Grand Total'] \n",
    "        dya[k] = grand_tot\n",
    "\n",
    "        if len(existant_cols) == 1:\n",
    "            df = t[t[t.columns[0]].isin(decider_dic[existant_cols[0]])]\n",
    "            if not df.empty:\n",
    "                if df.columns[0] == \"Region\":\n",
    "                    modified_regions[k] = df\n",
    "                if df.columns[0] == \"Channel\":\n",
    "                    modified_channels[k] = df\n",
    "                if df.columns[0] == \"Market\":\n",
    "                    modified_markets[k] = df\n",
    "\n",
    "        elif len(existant_cols) == 2:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_child = t[t[existant_cols[1]].isin(decider_dic[existant_cols[1]])].drop(columns = [existant_cols[0]])\n",
    "            t_parent = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1]])\n",
    "            t_parent[existant_cols[0]] = t_parent[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            for df in [t_child, t_parent]:\n",
    "                if not df.empty:\n",
    "                    if df.columns[0] == \"Region\":\n",
    "                        modified_regions[k] = df\n",
    "                    if df.columns[0] == \"Channel\":\n",
    "                        modified_channels[k] = df\n",
    "                    if df.columns[0] == \"Market\":\n",
    "                        modified_markets[k] = df\n",
    "                        \n",
    "            print(k,df)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            levels_rank = {\"Region\":1, \"Channel\":2, \"Market\":3}\n",
    "            existant_cols = sorted(existant_cols, key=lambda x: levels_rank[x])\n",
    "            t_market = t[t[existant_cols[2]].isin(decider_dic[existant_cols[2]])].drop(columns = [existant_cols[0],existant_cols[1]])\n",
    "            t_channel = t[t[existant_cols[1]].isin([i + \" Total\" for i in decider_dic[existant_cols[1]]])].drop(columns = [existant_cols[0],existant_cols[2]])\n",
    "            t_channel[existant_cols[1]] = t_channel[existant_cols[1]].str.replace(\" Total\", \"\").str.strip()\n",
    "            t_region = t[t[existant_cols[0]].isin([i + \" Total\" for i in decider_dic[existant_cols[0]]])].drop(columns = [existant_cols[1],existant_cols[2]])\n",
    "            t_region[existant_cols[0]] = t_region[existant_cols[0]].str.replace(\" Total\", \"\").str.strip()\n",
    "            if not t_region.empty:\n",
    "                modified_regions[k] = t_region\n",
    "            if not t_channel.empty:\n",
    "                modified_channels[k] = t_channel\n",
    "            if not t_market.empty:\n",
    "                modified_markets[k] = t_market\n",
    "            \n",
    "    return modified_regions, modified_channels, modified_markets, dya\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pbg | Razors Empty DataFrame\n",
      "Columns: [Channel, Gross Margin %, Gross Margin % IYA, Net Sales, Net Sales/Kg, Net Sales/Kg IYA, Value Sales IYA]\n",
      "Index: []\n",
      "Pbg | System Empty DataFrame\n",
      "Columns: [Channel, Gross Margin %, Gross Margin % IYA, Net Sales, Net Sales/Kg, Net Sales/Kg IYA, Value Sales IYA]\n",
      "Index: []\n",
      "Pbg | Refills Empty DataFrame\n",
      "Columns: [Channel, Gross Margin %, Gross Margin % IYA, Net Sales, Net Sales/Kg, Net Sales/Kg IYA, Value Sales IYA]\n",
      "Index: []\n",
      "Pbg | Disposables Empty DataFrame\n",
      "Columns: [Channel, Gross Margin %, Gross Margin % IYA, Net Sales, Net Sales/Kg, Net Sales/Kg IYA, Value Sales IYA]\n",
      "Index: []\n",
      "Pbg | Manual Shave Men Empty DataFrame\n",
      "Columns: [Channel, Gross Margin %, Gross Margin % IYA, Net Sales, Net Sales/Kg, Net Sales/Kg IYA, Value Sales IYA]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "modified_retailer_regions = {}\n",
    "modified_retailer_channels = {}\n",
    "modified_retailer_markets = {}\n",
    "\n",
    "modified_channels_regions = {}\n",
    "modified_channels_channels = {}\n",
    "modified_channels_markets = {}\n",
    "\n",
    "modified_cust_regions = {}\n",
    "modified_cust_channels = {}\n",
    "modified_cust_markets = {}\n",
    "\n",
    "dya_retailer={}\n",
    "dya_channel={}\n",
    "dya_cust = {}\n",
    "\n",
    "#**********Retailer*********\n",
    "if len(retailers)!=0:\n",
    "    modified_retailer_regions, modified_retailer_channels, modified_retailer_markets, dya_retailer = process_RET_CHAN_POS(retailers_P12M_dfs, regions_RET, channels_RET, market_RET)\n",
    "# *********Channels**********\n",
    "if len(channels)!=0:\n",
    "    modified_channels_regions, modified_channels_channels, modified_channels_markets, dya_channel = process_RET_CHAN_POS(channel_P12M_dfs, regions_CHAN, channels_CHAN, market_CHAN)\n",
    "#********POS****************\n",
    "if len(cust)!=0: \n",
    "    modified_cust_regions, modified_cust_channels, modified_cust_markets, dya_cust = process_RET_CHAN_POS(cust_P12M_dfs, regions_CUST, channels_CUST, market_CUST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Sector/Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixAnalysisCleaning(inputdic):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t=inputdic[k].copy()\n",
    "        t=t[:-1]\n",
    "        t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "        t=t.fillna(0)\n",
    "        t=t[t[\"Net Sales\"]>=1000]\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sectors_P12M_mix_analysis_dfs=MixAnalysisCleaning(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M_mix_analysis_dfs=MixAnalysisCleaning(Segment_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubSegment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M_mix_analysis_dfs=MixAnalysisCleaning(SubCategory_P12M_client_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide2: Trade Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TradeMarginCleaning(inputdic,scope=\"\"):\n",
    "    modifieddic={}\n",
    "    for k in inputdic.keys():\n",
    "        t = inputdic[k].copy()\n",
    "        t[scope] = t[scope].replace('Grand Total', 'Total')\n",
    "        t=t.replace(np.nan,0)\n",
    "        if not t.empty:\n",
    "            modifieddic[k]=t\n",
    "    return modifieddic   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    modified_sector_Trade_Margin_dfs=TradeMarginCleaning(Sector_P12M_client_dfs,scope=\"Sector\")\n",
    "if len(segments)!=0:\n",
    "    modified_segment_Trade_Margin_dfs=TradeMarginCleaning(Segment_P12M_client_dfs,scope=\"Segment\")\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_Trade_Margin_dfs=TradeMarginCleaning(SubSegment_P12M_client_dfs,scope=\"SubSegment\")\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_Trade_Margin_dfs=TradeMarginCleaning(SubCategory_P12M_client_dfs,scope=\"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector KPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data, Scope =\"Sector\"):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df =df[df['Net Sales'] > 1000]\n",
    "\n",
    "        df = df[~df[Scope].str.contains('Grand Total', case=False)]\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data1,data2, Scope = \"Sector\"):\n",
    "    final = {}\n",
    "    for key in modified_sector_P12M.keys():\n",
    "        if key in modified_sector_P3M.keys():\n",
    "            final[key] = pd.merge(data1[key], data2[key], on = Scope, suffixes= (\"_P12M\", \"_P3M\"))\n",
    "            df = final[key]\n",
    "            df = df[~df[Scope].str.contains('Total', case=False)]\n",
    "            df =df[df['Net Sales_P3M'] > 1000]\n",
    "            \n",
    "            df = df.sort_values('Rate of Sales_P3M', ascending=False).reset_index(drop =True)\n",
    "            \n",
    "            \n",
    "            if df.shape[0]>0:\n",
    "                final[key] = df\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sector_P12M = {}\n",
    "modified_sector_P3M ={}\n",
    "merged_data_sector ={}\n",
    "if len(sectors)!=0:\n",
    "    modified_sector_P12M  = clean(Sector_P12M_client_dfs, \"Sector\")\n",
    "    modified_sector_P3M  = clean(Sector_P3M_client_dfs, \"Sector\")\n",
    "    merged_data_sector = merge_data(modified_sector_P12M,modified_sector_P3M, \"Sector\")\n",
    "\n",
    "\n",
    "modified_segment_P12M ={}\n",
    "modified_segment_P3M ={}\n",
    "merged_data_segment ={}\n",
    "if len(segments)!=0:\n",
    "    modified_segment_P12M  = clean(Segment_P12M_client_dfs, \"Segment\")\n",
    "    modified_segment_P3M  = clean(Segment_P3M_client_dfs, \"Segment\")\n",
    "    merged_data_segment = merge_data(modified_segment_P12M,modified_segment_P3M, \"Segment\")\n",
    "\n",
    "modified_subsegment_P12M ={}\n",
    "modified_subsegment_P3M ={}\n",
    "merged_data_subsegment ={}\n",
    "if len(subsegments)!=0:\n",
    "    modified_subsegment_P12M  = clean(SubSegment_P12M_client_dfs, \"SubSegment\")\n",
    "    modified_subsegment_P3M  = clean(SubSegment_P3M_client_dfs, \"SubSegment\")\n",
    "    merged_data_subsegment = merge_data(modified_subsegment_P12M,modified_subsegment_P3M, \"SubSegment\")\n",
    "\n",
    "modified_subcategory_P12M = {}\n",
    "modified_subcategory_P3M ={}\n",
    "merged_data_subcategory ={}\n",
    "if len(subcategories)!=0:\n",
    "    modified_subcategory_P12M  = clean(SubCategory_P12M_client_dfs, \"SubCategory\")\n",
    "    modified_subcategory_P3M  = clean(SubCategory_P3M_client_dfs, \"SubCategory\")\n",
    "    merged_data_subcategory = merge_data(modified_subcategory_P12M,modified_subcategory_P3M, \"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 4: SKU KPIs Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_product_P12M_dfs={}\n",
    "modified_product_P3M_dfs={}\n",
    "modified_product_dfs = {}\n",
    "\n",
    "#P3M\n",
    "for k in product_P3M_dfs.keys():\n",
    "    t=product_P3M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    if not df.empty:\n",
    "        modified_product_P3M_dfs[k] = df\n",
    "\n",
    "#P12M\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    t = t[~t[\"Top Brands\"].str.contains(' Total')]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df = df.fillna(0)\n",
    "    df['Net Sales'] = df['Net Sales'].astype(float)\n",
    "    df = df[df['Net Sales'] > 1000]\n",
    "    if not df.empty:\n",
    "        modified_product_P12M_dfs[k] = df\n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_product_P12M_dfs.keys() if k not in modified_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_product_P3M_dfs[k] = pd.DataFrame(columns=modified_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_product_dfs[k] = comb.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By_Brand \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_brand_product_P3M_dfs={}\n",
    "modified_brand_product_P12M_dfs={}\n",
    "modified_brand_product_dfs={}\n",
    "\n",
    "###P3M\n",
    "for k in modified_product_P3M_dfs.keys():\n",
    "        t = modified_product_P3M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            parts = [part.strip() for part in new_key.split('|') if f'{client_manuf[0]}' not in part]\n",
    "            new_key = ' | '.join(parts)\n",
    "            if not df.empty :\n",
    "                modified_brand_product_P3M_dfs[new_key] = df  \n",
    "\n",
    "\n",
    "###P12M    \n",
    "for k in modified_product_P12M_dfs.keys():\n",
    "        t = modified_product_P12M_dfs[k].copy()\n",
    "        for brand in client_brands:\n",
    "            df = t[t['Top Brands'] == brand]\n",
    "            new_key = f\"{brand} | {k}\"\n",
    "            parts = [part.strip() for part in new_key.split('|') if f'{client_manuf[0]}' not in part]\n",
    "            new_key = ' | '.join(parts)\n",
    "            if not df.empty :\n",
    "                modified_brand_product_P12M_dfs[new_key] = df    \n",
    "\n",
    "\n",
    "missing_keys = [k for k in modified_brand_product_P12M_dfs.keys() if k not in modified_brand_product_P3M_dfs]\n",
    "for k in missing_keys:\n",
    "    modified_brand_product_P3M_dfs[k] = pd.DataFrame(columns=modified_brand_product_P12M_dfs[k].columns)\n",
    "\n",
    "for k in modified_brand_product_P12M_dfs.keys():\n",
    "    p12m_df = modified_brand_product_P12M_dfs[k].copy()\n",
    "    p12m_df = p12m_df.nlargest(15, 'Net Sales')\n",
    "    p3m_df = modified_brand_product_P3M_dfs[k].copy()\n",
    "    comb = pd.merge(p12m_df,p3m_df, how = 'left',on = [\"Top Brands\",f'{prodORitem}'], suffixes = (\"_P12M\", \"_P3M\"))\n",
    "    \n",
    "    comb = comb.sort_values(by=f'{prodORitem} Sales Rate_P3M', ascending=False)\n",
    "    # Compute Sales Rate Ix\n",
    "    first_value = comb[f'{prodORitem} Sales Rate_P3M'].iloc[0]\n",
    "    comb['Sales Rate Ix'] = (comb[f'{prodORitem} Sales Rate_P3M'] / first_value)\n",
    "    modified_brand_product_dfs[k] = comb.fillna(0)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide 5_Mix Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixClean(data):\n",
    "    final ={}\n",
    "    for key, val in data.items():\n",
    "        df=val.copy()\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = ' | '.join([key.split(' | ')[0],key.split(' | ')[2],key.split(' | ')[1]])\n",
    "            else:\n",
    "                new_key = key\n",
    "\n",
    "            df.fillna(0,inplace = True)\n",
    "            df['Source'] = new_key.split(' | ')[2]\n",
    "\n",
    "            final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    #         final[new_key] = df.sort_values(by='Value Sales',ascending=False)\n",
    "    sortOrder=final[new_key][final[new_key].columns[0]].unique()\n",
    "\n",
    "    # print(sortOrder,final[new_key].columns[0])\n",
    "    for key,val in final.items():\n",
    "        val['order']=val[val.columns[0]].replace(dict(zip(sortOrder,range(len(sortOrder)))))\n",
    "        final[key]=val\n",
    "\n",
    "\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    sector_P12M_modified = mixMatrixClean(Sector_P12M_client_dfs)\n",
    "if len(segments)!=0:\n",
    "    segment_P12M_modified = mixMatrixClean(Segment_P12M_client_dfs)\n",
    "if len(subcategories)!=0:\n",
    "    subCat_P12M_modified = mixMatrixClean(SubCategory_P12M_client_dfs)\n",
    "if len(subsegments)!=0:\n",
    "    subSeg_P12M_modified = mixMatrixClean(SubSegment_P12M_client_dfs)\n",
    "    \n",
    "    \n",
    "secRetailerDf,segRetailerDf,subCatRetailerDf,subSegRetailerDf,brandsRetailerDf={},{},{},{},{}\n",
    "secChannelDf,segChannelDf,subCatChannelDf,subSegChannelDf,brandsChannelDf={},{},{},{},{}\n",
    "secCustDf,segCustDf,subCatCustDf,subSegCustDf,brandsCustDf={},{},{},{},{}\n",
    "\n",
    "for key,retailerList in {'region':['National'] if national else []+regions_RET,'channel':['National'] if national else []+channels_RET,'market':['National'] if national else []+market_RET}.items():\n",
    "    if len(sectors)!=0:secRetailerDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(segments)!=0:segRetailerDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subcategories)!=0:subCatRetailerDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "    if len(subsegments)!=0:subSegRetailerDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in retailerList)}\n",
    "\n",
    "for key,channelList in {'region':['National'] if national else []+regions_CHAN,'channel':['National'] if national else []+channels_CHAN,'market':['National'] if national else []+market_CHAN}.items():\n",
    "    if len(sectors)!=0:secChannelDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(segments)!=0:segChannelDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subcategories)!=0:subCatChannelDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "    if len(subsegments)!=0:subSegChannelDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in channelList)}\n",
    "\n",
    "for key,custList in {'region':['National'] if national else []+regions_CUST,'channel':['National'] if national else []+channels_CUST,'market':['National'] if national else []+market_CUST}.items():\n",
    "    if len(sectors)!=0:secCustDf[key] = {key: sector_P12M_modified[key] for key in sector_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(segments)!=0:segCustDf[key] = {key: segment_P12M_modified[key] for key in segment_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subcategories)!=0:subCatCustDf[key] = {key: subCat_P12M_modified[key] for key in subCat_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n",
    "    if len(subsegments)!=0:subSegCustDf[key] = {key: subSeg_P12M_modified[key] for key in subSeg_P12M_modified.keys()  if (key.split(' | ')[2] in custList)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "secRetailerClient,segRetailerClient,subCatRetailerClient,subSegRetailerClient={},{},{},{}\n",
    "secChannelClient,segChannelClient,subCatChannelClient,subSegChannelClient={},{},{},{}\n",
    "secCustClient,segCustClient,subCatCustClient,subSegCustClient={},{},{},{}\n",
    "\n",
    "\n",
    "def clientAgg(dic):\n",
    "\n",
    "    clients={}\n",
    "    for marketLevel in ['region','channel','market']:\n",
    "        for manuf in client_manuf:\n",
    "            keys = [dic[marketLevel][key] for key in dic[marketLevel].keys() if manuf in key.split(' | ')]\n",
    "            if keys:\n",
    "                clients[manuf+' | '+marketLevel]=pd.concat(keys).reset_index(drop = True)\n",
    "    return clients\n",
    "\n",
    "if len(sectors)!=0:secRetailerClient = clientAgg(secRetailerDf)\n",
    "if len(segments)!=0:segRetailerClient = clientAgg(segRetailerDf)\n",
    "if len(subcategories)!=0:subCatRetailerClient = clientAgg(subCatRetailerDf)\n",
    "if len(subsegments)!=0:subSegRetailerClient = clientAgg(subSegRetailerDf)\n",
    "\n",
    "if len(sectors)!=0:secChannelClient = clientAgg(secChannelDf)\n",
    "if len(segments)!=0:segChannelClient = clientAgg(segChannelDf)\n",
    "if len(subcategories)!=0:subCatChannelClient = clientAgg(subCatChannelDf)\n",
    "if len(subsegments)!=0:subSegChannelClient = clientAgg(subSegChannelDf)\n",
    "\n",
    "if len(sectors)!=0:secCustClient = clientAgg(secCustDf)\n",
    "if len(segments)!=0:segCustClient = clientAgg(segCustDf)\n",
    "if len(subcategories)!=0:subCatCustClient = clientAgg(subCatCustDf)\n",
    "if len(subsegments)!=0:subSegCustClient = clientAgg(subSegCustDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0, 2)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailerDuplication = sum([len(secRetailerClient)+len(segRetailerClient)+len(subCatRetailerClient)+len(subSegRetailerClient)])\n",
    "channelDuplication = sum([len(secChannelClient)+len(segChannelClient)+len(subCatChannelClient)+len(subSegChannelClient)])\n",
    "custDuplication = sum([len(secCustClient)+len(segCustClient)+len(subCatCustClient)+len(subSegCustClient)])\n",
    "retailerDuplication,channelDuplication,custDuplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "        if 'National' in val['Source'].unique():\n",
    "            val['Net Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].iloc[0]\n",
    "            val['GM Total'] = val[(val.Source=='National')&(val[colToFill].str.contains('Total'))]['Gross Margin %'].iloc[0]\n",
    "        else:\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "                            \n",
    "retailerDic = {'Sec':secRetailerClient,'Seg':segRetailerClient,'SubSeg':subSegRetailerClient,'SubCat':subCatRetailerClient}\n",
    "channelDic = {'Sec':secChannelClient,'Seg':segChannelClient,'SubSeg':subSegChannelClient,'SubCat':subCatChannelClient}\n",
    "custDic = {'Sec':secCustClient,'Seg':segCustClient,'SubSeg':subSegCustClient,'SubCat':subCatCustClient}\n",
    "\n",
    "for key,val in retailerDic.items():\n",
    "    retailerDic[key] = fillMissingValue(val)\n",
    "for key,val in channelDic.items():\n",
    "    channelDic[key] = fillMissingValue(val)\n",
    "for key,val in custDic.items():\n",
    "    custDic[key] = fillMissingValue(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLide6: MixMatrix ByBrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixMatrixbybrandClean(data):\n",
    "    final = {}\n",
    "    for key, val in data.items():\n",
    "        df = val.copy()       \n",
    "        if df.shape[0] != 0:\n",
    "            new_key = key\n",
    "            df.fillna(0, inplace=True)\n",
    "            df['Source'] = new_key.split(' | ')[1]\n",
    "            # Sort the DataFrame by 'Value Sales'\n",
    "            final[new_key] = df.sort_values(by='Value Sales', ascending=False)\n",
    "            # Generate sort order based on sorted unique values of the first column\n",
    "            sortOrder = final[new_key][final[new_key].columns[0]].unique()\n",
    "            # Apply the sort order to the current DataFrame\n",
    "            final[new_key]['order'] = final[new_key][final[new_key].columns[0]].replace(dict(zip(sortOrder, range(len(sortOrder)))))\n",
    " \n",
    "    return final\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissingValue(dfToFill):\n",
    "    for key,val in dfToFill.items():\n",
    "        colToFill = val.columns[0]\n",
    "        uniqueValue = val[~val[colToFill].str.contains('Total')][colToFill].unique()\n",
    "        dfLis = []\n",
    "        for source in val['Source'].unique():\n",
    "            df = val[val.Source==source]\n",
    "            missingValue = list(set(uniqueValue) - set(df[~df[colToFill].str.contains('Total')][colToFill].unique()))\n",
    "            missingValue = pd.DataFrame({colToFill: missingValue,'Source':source})\n",
    "            val = pd.concat([val, missingValue]).replace(np.nan,0).reset_index(drop=True)\n",
    "            \n",
    "        ## Value Identifier on the avg or national value for the color schema on replacement\n",
    "            val['Net Total'] = val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].sum()/val[(val[colToFill].str.contains('Total'))]['Net Sales/Kg'].count()\n",
    "            val['GM Total'] = val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].sum()/val[(val[colToFill].str.contains('Total'))]['Gross Margin %'].count()\n",
    "        dfToFill[key]=val\n",
    "        \n",
    "    return dfToFill\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat,sec,seg,subseg,subcat \n",
    "secbrand,segbrand,subsegbrand,subcatbrand = {},{},{},{}\n",
    "for key in brands_client_dfs.keys():\n",
    "    key_split = key.split(' | ')\n",
    "    if len(sectors) != 0 and len(key_split) > 2 and key_split[1] in sectors or key_split[1] in categories  :secbrand[key] = brands_client_dfs[key]\n",
    "    if len(segments) != 0 and len(key_split) > 2 and key_split[1] in segments or key_split[1] in categories:segbrand[key] = brands_client_dfs[key]\n",
    "    if len(subsegments) != 0 and len(key_split) > 2 and key_split[1] in subsegments or key_split[1] in categories:subsegbrand[key] = brands_client_dfs[key]\n",
    "    if len(subcategories) != 0 and len(key_split) > 2 and key_split[1] in subcategories or key_split[1] in categories:subcatbrand[key] = brands_client_dfs[key]\n",
    " \n",
    "if len(sectors) != 0:\n",
    "        sec_dfclean=mixMatrixbybrandClean(secbrand)\n",
    "        sectorbybrand=fillMissingValue(sec_dfclean)\n",
    "if len(segments) != 0:\n",
    "        seg_dfclean=mixMatrixbybrandClean(segbrand)\n",
    "        segmentbybrand=fillMissingValue(seg_dfclean)\n",
    "\n",
    "if len(subsegments) != 0: \n",
    "        subseg_dfclean=mixMatrixbybrandClean(subsegbrand)\n",
    "        subsegmentbybrand=fillMissingValue(subseg_dfclean)\n",
    "\n",
    "if len(subcategories) != 0:\n",
    "       subcat_dfclean=mixMatrixbybrandClean(subcatbrand)\n",
    "       subcategorybybrand=fillMissingValue(subcat_dfclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatdf(dic,area):\n",
    "    final = {}\n",
    "    for key_part in area:\n",
    "        aligned_dfs = []\n",
    "\n",
    "        # Filter and align DataFrames for the current area\n",
    "        for key, df in dic.items():\n",
    "            key_parts = key.split(\" | \")  # Split key into parts based on \" | \"\n",
    "            if key_part in key_parts:  # Check if the key includes the area (e.g., \"NATIONAL\")\n",
    "                # Set 'Top Brands' as index for alignment, reindex to ensure all brands are present\n",
    "                area_brands = pd.concat([df['Top Brands'] for key, df in dic.items() if key_part in key]).unique()\n",
    "                aligned_df = df.set_index('Top Brands').reindex(area_brands).reset_index()\n",
    "                aligned_df['Source'] = aligned_df['Source'].ffill()  # Track the source of the data\n",
    "                aligned_df = aligned_df.fillna(0)  # Fill missing values with 0\n",
    "                aligned_df.rename(columns={\"Top Brands\": client_manuf[0]}, inplace=True)\n",
    "                aligned_dfs.append(aligned_df)\n",
    "\n",
    "        if aligned_dfs:  # Ensure there's at least one DataFrame to concatenate\n",
    "            final_df = pd.concat(aligned_dfs, ignore_index=True)\n",
    "            final[key_part] = final_df  # Store the concatenated DataFrame in the final dictionary\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    secfinaldic=concatdf(sectorbybrand,area)\n",
    "if len(segments)!=0:\n",
    "    segfinaldic=concatdf(segmentbybrand,area)\n",
    "if len(subsegments)!=0:\n",
    "    subsegfinaldic=concatdf(subsegmentbybrand,area)\n",
    "if len(subcategories)!=0:\n",
    "    subcatfinaldic=concatdf(subcategorybybrand,area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide7:Sector Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Spending Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanProducts(data):\n",
    "    final ={}\n",
    "    for key, df in data.items():\n",
    "        df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "        df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "        df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df[df['Net Sales']>1000]\n",
    "        df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "        df =df.head(12)\n",
    "        df = df.reset_index(drop=True)\n",
    "        if df.shape[0] !=0:\n",
    "            if 'National' in key:\n",
    "                new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "            else:\n",
    "                new_key = key\n",
    "            final[new_key] = df\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m = cleanProducts(product_P12M_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_products_p12m_brand ={}\n",
    "for key, df in modified_brand_product_P12M_dfs.items():\n",
    "    df['Top Brands'] = df['Top Brands'].replace(0, np.nan)\n",
    "    df['Top Brands'] = df['Top Brands'].fillna(method = 'ffill')\n",
    "    df = df[~df['Top Brands'].str.contains('Total', case=False)]\n",
    "    df.fillna(0,inplace = True)\n",
    "    df = df[df['Net Sales']>1000]\n",
    "    df = df[df['Top Brands'].isin(client_brands)]\n",
    "    df = df.sort_values(by= 'Net Sales', ascending=False)\n",
    "    df =df.head(12)\n",
    "    df = df.reset_index(drop=True)\n",
    "    if df.shape[0] !=0:\n",
    "        if 'National' in key:\n",
    "            new_key = key.split(' | ')[0] + ' | ' + key.split(' | ')[2] +' | ' + key.split(' | ')[1]\n",
    "        else:\n",
    "            new_key = key\n",
    "        modified_products_p12m_brand[new_key] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKU Profitability Slide 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "###P12M\n",
    "modified_product_sec_seg_P12M_dfs = {}\n",
    "\n",
    "for k in product_P12M_dfs.keys():\n",
    "    t=product_P12M_dfs[k].copy()\n",
    "    t=t[:-1]\n",
    "    t['Value Sales IYA'] =t['Value Sales IYA'].astype(float).fillna(-199)\n",
    "    t['Net Sales'] =t['Net Sales'].astype(float).fillna(0)\n",
    "    t['Net Sales/Kg'] =t['Net Sales/Kg'].astype(float).fillna(0)\n",
    "\n",
    "    t['Gross Margin %'] =t['Gross Margin %'].astype(float).fillna(0)\n",
    "\n",
    "    t['Top Brands']=t['Top Brands'].ffill()\n",
    "    total= t[(t['Top Brands'].str.contains( ' Total')) & ~(t['Top Brands'].isin(['Grand Total','All Others Total'])) & ~(t['Top Brands'].isin([i+' Total' for i in client_brands]))]\n",
    "    df = t[t['Top Brands'].isin(client_brands)]\n",
    "    df[f'{prodORitem} Sales Rate'] = df[f'{prodORitem} Sales Rate'].fillna(0)\n",
    "    df = df[df['Net Sales'] >= 1000]\n",
    "    if (not df.empty):\n",
    "        modified_product_sec_seg_P12M_dfs[k] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slide9: Trade margin table vs Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By client and competitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_excluding_total(df, Inscope=\"\"):\n",
    "    df = df.fillna(0)\n",
    "    total_row = df[df[f'{ManufOrTopC}'] == 'Total']\n",
    "    df = df[df[f'{ManufOrTopC}'] != 'Total']\n",
    "    df = df.sort_values(by=[Inscope], ascending=[True]).reset_index(drop=True)\n",
    "    df = pd.concat([df, total_row]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_client_copetitor(dictionary,client_dictionary,competitor_dictionary,Inscope=\"\"):\n",
    "    for k in dictionary.keys():\n",
    "        t = dictionary[k].copy()\n",
    "        t=t[:-1]\n",
    "        t[Inscope]=t[Inscope].fillna(t[f'{ManufOrTopC}'])\n",
    "        t['Net Sales'] = t['Net Sales'].astype(float)\n",
    "        total_entries = t[(t[f'{ManufOrTopC}'].str.contains(' Total')) & ~(t[f'{ManufOrTopC}'].isin(['Grand Total',\"All Others Total\"])) & ~(t[f'{ManufOrTopC}'].isin([i+' Total' for i in client_manuf]))]\n",
    "        total_entries['Value Share'] = total_entries['Value Share'].astype(float)\n",
    "        total_entries = total_entries.nlargest(1,columns=\"Value Share\")    \n",
    "        comp_lis = list(total_entries[f'{ManufOrTopC}'].str.replace(\" Total\",'').str.strip())\n",
    "        print(comp_lis)\n",
    "        dc = (t[t[f'{ManufOrTopC}'].isin(client_manuf) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in client_manuf])]).replace([i + \" Total\" for i in client_manuf],\"Total\")\n",
    "        df = (t[t[f'{ManufOrTopC}'].isin(comp_lis) | t[f'{ManufOrTopC}'].isin([i + \" Total\" for i in comp_lis])]).replace([i + \" Total\" for i in comp_lis],\"Total\")\n",
    "        \n",
    "        dc = dc[dc['Net Sales'] > 1000]\n",
    "        unique_scope = dc[Inscope].unique().tolist()\n",
    "\n",
    "        df = df[df[Inscope].isin(unique_scope)]\n",
    "\n",
    "        for subcat in unique_scope:\n",
    "            print(subcat)\n",
    "            if (subcat not in df[Inscope].values) & (subcat!=\"\"):\n",
    "                df = pd.concat([df, pd.DataFrame({f'{ManufOrTopC}': [df[f'{ManufOrTopC}'].unique()[0]], Inscope: [subcat]})])\n",
    "\n",
    "\n",
    "        dc = sort_df_excluding_total(dc, Inscope)\n",
    "        df = sort_df_excluding_total(df, Inscope)\n",
    "\n",
    "        if not dc.empty:\n",
    "            client_dictionary[k]=dc\n",
    "        if not df.empty:\n",
    "            competitor_dictionary[k]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "System\n",
      "Total\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "System\n",
      "Total\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "System\n",
      "Total\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "System\n",
      "Total\n",
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "Razors\n",
      "Refills\n",
      "Total\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "Razors\n",
      "Refills\n",
      "Total\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "Razors\n",
      "Refills\n",
      "Total\n",
      "['Procter & Gamble']\n",
      "Disposables\n",
      "Razors\n",
      "Refills\n",
      "Total\n"
     ]
    }
   ],
   "source": [
    "####Sector_Cleaning \n",
    "client_manuf_sector_dfs_new = {}\n",
    "top_competitor_manuf_sector_dfs_new = {}\n",
    "if len(sectors)!=0:\n",
    "    split_client_copetitor(manuf_Sector_dfs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,Inscope=\"Sector\")\n",
    "\n",
    "####Segment_Cleaning\n",
    "client_manuf_segment_dfs_new = {}\n",
    "top_competitor_manuf_segment_dfs_new = {}\n",
    "if len(segments)!=0:\n",
    "    split_client_copetitor(manuf_Segment_dfs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,Inscope=\"Segment\")\n",
    "\n",
    "####SubSegment_Cleaning\n",
    "client_manuf_subsegment_dfs_new = {}\n",
    "top_competitor_manuf_subsegment_dfs_new = {}\n",
    "if len(subsegments)!=0:\n",
    "    split_client_copetitor(manuf_SubSegment_dfs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,Inscope=\"SubSegment\")\n",
    "\n",
    "####SubCategory_Cleaning\n",
    "client_manuf_subcategory_dfs_new = {}\n",
    "top_competitor_manuf_subcategory_dfs_new = {}\n",
    "if len(subcategories)!=0:\n",
    "    split_client_copetitor(manuf_SubCategory_dfs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,Inscope=\"SubCategory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duplication part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 5, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "index = [\n",
    "    *[0]*((1 if len(client_brands)>1 and len(modified_brand_P12M_dfs)>0 else 0)+(1 if len(modified_retailer_regions)>0 else 0)+(1 if len(modified_retailer_channels)>0 else 0)+(1 if len(modified_retailer_markets)>0 else 0)\n",
    "          +(1 if len(modified_channels_regions)>0 else 0)+(1 if len(modified_channels_channels)>0 else 0)+(1 if len(modified_channels_markets)>0 else 0)\n",
    "          +(1 if len(modified_cust_regions)>0 else 0)+(1 if len(modified_cust_channels)>0 else 0)+(1 if len(modified_cust_markets)>0 else 0)\n",
    "          +(1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)+(1 if len(client_brands)>1 else 0)),\n",
    "          \n",
    "    *[1]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "#     *[2]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[3]*((1 if len(client_brands)>1 else 0)+(1 if len(client_brands)>1 else 0)),\n",
    "    *[4]*((1 if retailerDuplication !=0 else 0)+(1 if channelDuplication !=0 else 0 )+(1 if custDuplication !=0 else 0 )),\n",
    "    *[5]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[6]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0)),\n",
    "    *[7]*(1 if len(client_brands)>1 else 0),\n",
    "    *[8]*( 1 if len(client_brands)>1 else 0),\n",
    "    *[9]*((1 if sectors else 0)+(1 if segments else 0)+(1 if subsegments else 0)+(1 if subcategories else 0))\n",
    "          ]\n",
    "\n",
    "\n",
    "# slide 0\n",
    "duplication_1=[(len(modified_brand_P12M_dfs.keys()) if len(client_brands)>1 else 0)]\n",
    "duplication_2 = [len(modified_retailer_regions.keys()) if len(regions_RET)>0 else 0, len(modified_retailer_channels) if len(channels_RET)>0 else 0, len(modified_retailer_markets) if len(market_RET)>0 else 0,\n",
    "                 len(modified_channels_regions.keys()) if len(regions_CHAN)>0 else 0, len(modified_channels_channels) if len(channels_CHAN)>0 else 0, len(modified_channels_markets) if len(market_CHAN) >0 else 0,\n",
    "                 len(modified_cust_regions.keys()) if len(regions_CUST)>0 else 0, (len(modified_cust_channels) if len(channels_CUST)>0 else 0), (len(modified_cust_markets) if len(market_CUST)>0 else 0)] \n",
    "\n",
    "duplication_3 = [(len(modified_sectors_P12M_mix_analysis_dfs.keys()) if len(sectors)>0 else 0), (len(modified_segment_P12M_mix_analysis_dfs.keys()) if len(segments)>0 else 0), (len(modified_subsegment_P12M_mix_analysis_dfs) if len(subsegments)>0 else 0), (len(modified_subcategory_P12M_mix_analysis_dfs) if len(subcategories)>0 else 0)]\n",
    "\n",
    "duplication_4 = [len(modified_product_sec_seg_P12M_dfs.keys())]\n",
    "\n",
    "# Slide 1\n",
    "duplication_5 = [(len(modified_sector_Trade_Margin_dfs.keys()) if len(sectors)!=0 else 0), (len(modified_segment_Trade_Margin_dfs.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_Trade_Margin_dfs) if len(subsegments)!=0 else 0), (len(modified_subcategory_Trade_Margin_dfs) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "#Slide 2\n",
    "# duplication_6 = [(len(merged_data_sector.keys()) if len(sectors)!=0 else 0), (len(merged_data_segment.keys()) if len(segments)!=0 else 0), (len(merged_data_subsegment) if len(subsegments)!=0 else 0), (len(merged_data_subcategory) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 3\n",
    "duplication_7 = [len(modified_product_dfs.keys()),len(modified_brand_product_dfs.keys())]\n",
    "#slide 4\n",
    "duplication_8 = [retailerDuplication,channelDuplication,custDuplication]\n",
    "\n",
    "# Slide 5\n",
    "duplication_9=[(len(secfinaldic.keys())if len(sectors)!=0 else 0),(len(segfinaldic.keys())if len(segments)!=0 else 0),(len(subsegfinaldic.keys())if len(subsegments)!=0 else 0),(len(subcatfinaldic.keys())if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 5\n",
    "duplication_10 = [(len(modified_sector_P12M.keys()) if len(sectors)!=0 else 0), (len(modified_segment_P12M.keys()) if len(segments)!=0 else 0), (len(modified_subsegment_P12M) if len(subsegments)!=0 else 0), (len(modified_subcategory_P12M) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "# Slide 6\n",
    "duplication_11 = [len(modified_products_p12m)+ len(modified_products_p12m_brand)]\n",
    "\n",
    "# Slide 7 \n",
    "duplication_12 = [len(modified_product_P12M_dfs) + len(modified_brand_product_P12M_dfs)]\n",
    "\n",
    "# Slide 8\n",
    "duplication_13 = [(len(client_manuf_sector_dfs_new.keys()) if len(sectors)!=0 else 0), (len(client_manuf_segment_dfs_new.keys()) if len(segments)!=0 else 0), (len(client_manuf_subsegment_dfs_new) if len(subsegments)!=0 else 0), (len(client_manuf_subcategory_dfs_new) if len(subcategories)!=0 else 0)]\n",
    "\n",
    "\n",
    "duplication = duplication_1 + duplication_2 + duplication_3 + duplication_4 + duplication_5 + duplication_7 + duplication_8+duplication_9 + duplication_10+ duplication_11+duplication_12+duplication_13 #+ duplication_6\n",
    "print(duplication_2)\n",
    "duplication = [item for item in duplication if item !=0]\n",
    "\n",
    "section_1 = ([\"Mix Analysis by brand\"] if len(client_brands)>1 and  len(modified_brand_P12M_dfs)>0 else [])\n",
    "section_2 = ([\"Mix Analysis by Retailer for Region\"] if len(modified_retailer_regions)!=0 else [])+ ([\"Mix Analysis by Retailer for Channel\"] if len(modified_retailer_channels)!=0 else [])+ ([\"Mix Analysis by Retailer for Market\"] if len(modified_retailer_markets)!=0 else [])+([\"Mix Analysis by Channel for Region\"] if len(modified_channels_regions)!=0 else [])+ ([\"Mix Analysis by Channel for Channel\"] if len(modified_channels_channels)!=0 else [])+ ([\"Mix Analysis by Channel for Market\"] if len(modified_channels_markets)!=0 else [])+([f\"Mix Analysis by {customareas} for Region\"] if len(modified_cust_regions)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Channel\"] if len(modified_cust_channels)!=0 else [])+ ([f\"Mix Analysis by {customareas} for Market\"] if len(modified_cust_markets)!=0 else [])\n",
    "section_3 = ([\"Mix Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Mix Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Mix Analysis by SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Mix Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "section_4 = [\"Mix Analysis by\"+ f'{prodORitem}' if len(client_brands)>1 else []]\n",
    "\n",
    "section_5 = ([\"Trade Margin Analysis by Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Analysis by Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Analysis by SubSegment\"] if len(subsegments)!=0 else [])+([\"Trade Margin Analysis by SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "# section_6 = ([\"Sector KPI\"] if len(sectors)!=0 else [])+ ([\"Segment KPI\"] if len(segments)!=0 else [])+ ([\"SubSegment KPI\"] if len(subsegments)!=0 else [])+ ([\"SubCategory KPI\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_7 = (\"SKU KPIs Summary By Manufacture\" if len(client_brands)>1 else [],\"SKU KPIs Summary By Brand\" if len(client_brands)>1 else [])\n",
    "\n",
    "section_8 = ['Mix Matrix By Retailer'if retailerDuplication != 0 else[] ,'Mix Matrix By Channel'if channelDuplication != 0 else[],'Mix Matrix By Custom Region'if custDuplication != 0 else[]]#,*section_names_slide4]#*section_names_slide3,*section_names_slide4]\n",
    "\n",
    "section_9=[\"Mix Matrix By Brands by Sector\" if len(sectors)!=0 else [],\"Mix Matrix By Brands by Segment\" if len(segments)!=0 else [],\"Mix Matrix By Brands by SubSegment\"if len(subsegments)!=0 else [],\"Mix Matrix By Brands by SubCategory\"if len(subcategories)!=0 else []]\n",
    "\n",
    "section_10 = ([\"Sector Spending Pool\"] if len(sectors)!=0 else [])+ ([\"Segment Spending Pool\"] if len(segments)!=0 else [])+ ([\"SubSegment Spending Pool\"] if len(subsegments)!=0 else [])+ ([\"SubCategory Spending Pool\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_11 = ([\"Product Spending Pool\"] if len(client_brands)>1 else [])\n",
    "\n",
    "section_12 = [(\"SKU Profitability\" if len(client_brands)>1 else [])]\n",
    "\n",
    "section_13 = ([\"Trade Margin Table By Sector\"] if len(sectors)!=0 else [])+ ([\"Trade Margin Table By Segment\"] if len(segments)!=0 else [])+ ([\"Trade Margin Table By SubSegment\"] if len(subsegments)!=0 else [])+ ([\"Trade Margin Table By SubCategory\"] if len(subcategories)!=0 else [])\n",
    "\n",
    "section_names = [*section_1 , *section_2 , *section_3 , *section_4 , *section_5  , *section_7 , *section_8, *section_9 , *section_10 , *section_11,*section_12,*section_13]#, *section_6\n",
    "\n",
    "section_names = [item for item in section_names if item !=[]]\n",
    " \n",
    "\n",
    "path = os.getcwd() + \"\\Financials base.pptx\"\n",
    "new_pre = os.getcwd() + '\\Financials Slide Duplicate.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 3, 3, 4, 4, 5, 5, 6, 6, 7, 8, 9, 9]\n",
      "[5, 4, 4, 20, 12, 12, 20, 20, 4, 2, 9, 9, 4, 4, 40, 40, 4, 4]\n",
      "['Mix Analysis by Retailer for Market', 'Mix Analysis by Sector', 'Mix Analysis by Segment', 'Mix Analysis bySKU', 'Trade Margin Analysis by Sector', 'Trade Margin Analysis by Segment', 'SKU KPIs Summary By Manufacture', 'SKU KPIs Summary By Brand', 'Mix Matrix By Retailer', 'Mix Matrix By Custom Region', 'Mix Matrix By Brands by Sector', 'Mix Matrix By Brands by Segment', 'Sector Spending Pool', 'Segment Spending Pool', 'Product Spending Pool', 'SKU Profitability', 'Trade Margin Table By Sector', 'Trade Margin Table By Segment']\n",
      "18\n",
      "18\n",
      "18\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(duplication)\n",
    "print(section_names)\n",
    "print(len(index))\n",
    "print(len(duplication))\n",
    "print(len(section_names))\n",
    "print(sum(duplication))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(slides_name) >0:\n",
    "    valid_sections = [(i, s) for i, s in enumerate(section_names) if s is not None]\n",
    "    indices = [i for i, s in valid_sections if any(sub.lower() == s.lower() for sub in slides_name)]\n",
    "    filtered_section_names = [section_names[i] for i in indices]\n",
    "    filtered_duplication = [duplication[i] for i in indices]\n",
    "    filtered_index = [index[i] for i in indices]\n",
    "    slideDuplication(filtered_index,filtered_duplication,filtered_section_names,path,new_pre)\n",
    "else:\n",
    "\n",
    "    slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slideDuplication(index,duplication,section_names,path,new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_position(end):\n",
    "#     return sum(duplication[i] * (1 if isinstance(index[i], int) else len(index[i])) for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(end, use_filtered=False):\n",
    "    \"\"\"\n",
    "    Calculate position based on duplication values.\n",
    "    \n",
    "    Args:\n",
    "        end: The end index to calculate position up to\n",
    "        use_filtered: Whether to use filtered lists (when slides_name is specified)\n",
    "    \"\"\"\n",
    "    if use_filtered:\n",
    "        try:\n",
    "            # Use filtered lists when slides are specifically requested\n",
    "            duplication_list = filtered_duplication\n",
    "            index_list = filtered_index\n",
    "        except NameError:\n",
    "            # Fall back to original lists if filtered ones don't exist\n",
    "            duplication_list = duplication\n",
    "            index_list = index\n",
    "    else:\n",
    "        # Use original lists\n",
    "        duplication_list = duplication\n",
    "        index_list = index\n",
    "    \n",
    "    return sum(duplication_list[i] * (1 if isinstance(index_list[i], int) else len(index_list[i])) \n",
    "               for i in range(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation(new_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "if len(client_brands)>1 and len(modified_brand_P12M_dfs) >0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by brand' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_brand_P12M_dfs,dup_list[p],Inscop='Brand',position = calculate_position(p,use_filtered),label_col='Top Brands')\n",
    "        p+=1\n",
    "\n",
    "if len(regions_RET)!=0 and len(modified_retailer_regions) !=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Retailer for Channel' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        print(p, dup_list[p], calculate_position(p))\n",
    "        Mixanalysis(prs,modified_retailer_regions,dup_list[p],Inscop='Retailer',position = calculate_position(p,use_filtered),label_col='Region')\n",
    "        p+=1\n",
    "\n",
    "if len(channels_RET)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Retailer for Region' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_retailer_channels,dup_list[p],Inscop='Retailer',position = calculate_position(p,use_filtered),label_col='Channel')\n",
    "        p+=1\n",
    "        \n",
    "if len(market_RET)!=0 and len(modified_retailer_markets)>0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Retailer for Market' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_retailer_markets,dup_list[p],Inscop='Retailer',position = calculate_position(p,use_filtered),label_col='Market')\n",
    "        p+=1\n",
    "\n",
    "if len(regions_CHAN)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Channel for Region' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_channels_regions,dup_list[p],Inscop='Channel',position = calculate_position(p,use_filtered),label_col='Region')\n",
    "        p+=1\n",
    "\n",
    "if len(channels_CHAN)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Channel for Channel' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_channels_channels,dup_list[p],Inscop='Channel',position = calculate_position(p,use_filtered),label_col='Channel')\n",
    "        p+=1\n",
    "\n",
    "if len(market_CHAN)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Channel for Market' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_channels_markets,dup_list[p],Inscop='Channel',position = calculate_position(p,use_filtered),label_col='Market')\n",
    "        p+=1\n",
    "\n",
    "\n",
    "if len(regions_CUST)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by {customareas} for Region' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_cust_regions,dup_list[p],Inscop=f\"{customareas}\",position = calculate_position(p,use_filtered),label_col='Region')\n",
    "        p+=1\n",
    "\n",
    "if len(channels_CUST)!=0 and len(modified_cust_channels)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by {customareas} for Channel' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_cust_channels,dup_list[p],Inscop=f\"{customareas}\",position = calculate_position(p,use_filtered),label_col='Channel')\n",
    "        p+=1\n",
    "\n",
    "if len(market_CUST)!=0 and len(modified_cust_markets)>0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by {customareas} for Market' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "\n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_cust_markets,dup_list[p],Inscop=f\"{customareas}\",position = calculate_position(p,use_filtered),label_col='Market')\n",
    "        p+=1\n",
    "\n",
    "if len(sectors)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Sector' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_sectors_P12M_mix_analysis_dfs,dup_list[p],Inscop='Sector',position = calculate_position(p,use_filtered),label_col='Sector')\n",
    "        p+=1\n",
    "if len(segments)!=0:    \n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Segment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:     \n",
    "        Mixanalysis(prs,modified_segment_P12M_mix_analysis_dfs,dup_list[p],Inscop=\"Segment\",position = calculate_position(p,use_filtered),label_col=\"Segment\")\n",
    "        p+=1\n",
    "if len(subsegments)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Subsegment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_subsegment_P12M_mix_analysis_dfs,dup_list[p],Inscop=\"SubSegment\",position = calculate_position(p,use_filtered),label_col=\"SubSegment\")\n",
    "        p+=1\n",
    "if len(subcategories)!=0:\n",
    "    try:\n",
    "        if 0 in filtered_index and 'Mix Analysis by Subcategory' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_subcategory_P12M_mix_analysis_dfs,dup_list[p],Inscop=\"SubCategory\",position = calculate_position(p,use_filtered),label_col=\"SubCategory\")\n",
    "        p+=1\n",
    "if len(client_brands)>1:\n",
    "    try:\n",
    "        if 0 in filtered_index and \"Mix Analysis by\"+ f'{prodORitem}' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        Mixanalysis(prs,modified_product_sec_seg_P12M_dfs,dup_list[p],Inscop=f'{prodORitem}',position = calculate_position(p,use_filtered),label_col=f'{prodORitem}')\n",
    "        p+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    try:\n",
    "        if 1 in filtered_index and 'Trade Margin Analysis by Sector' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMargin(prs,modified_sector_Trade_Margin_dfs,dup_list[p],position = calculate_position(p,use_filtered),InScope='Sector')\n",
    "        p+=1\n",
    "if len(segments)!=0:\n",
    "    try:\n",
    "        if 1 in filtered_index and 'Trade Margin Analysis by Segment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMargin(prs,modified_segment_Trade_Margin_dfs,dup_list[p],position = calculate_position(p,use_filtered),InScope=\"Segment\")\n",
    "        p+=1\n",
    "if len(subsegments)!=0:\n",
    "    try:\n",
    "        if 1 in filtered_index and 'Trade Margin Analysis by Subsegment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMargin(prs,modified_subsegment_Trade_Margin_dfs,dup_list[p],position = calculate_position(p,use_filtered),InScope=\"SubSegment\")\n",
    "        p+=1\n",
    "if len(subcategories)!=0:\n",
    "    try:\n",
    "        if 1 in filtered_index and 'Trade Margin Analysis by Subcategory' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMargin(prs,modified_subcategory_Trade_Margin_dfs,dup_list[p],position = calculate_position(p,use_filtered),InScope=\"SubCategory\")\n",
    "        p+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(sectors)!=0:\n",
    "#     sectorKPI(prs, merged_data_sector, duplication[p], position=calculate_position(p),Scope= \"Sector\")\n",
    "#     p+=1\n",
    "# if len(segments)!=0:\n",
    "#     sectorKPI(prs, merged_data_segment, duplication[p], position=calculate_position(p),Scope= \"Segment\")\n",
    "#     p+=1\n",
    "\n",
    "# if len(subsegments)!=0:\n",
    "#     sectorKPI(prs, merged_data_subsegment, duplication[p], position=calculate_position(p),Scope= \"SubSegment\")\n",
    "#     p+=1\n",
    "\n",
    "# if len(subcategories)!=0:\n",
    "#     sectorKPI(prs, merged_data_subcategory, duplication[p], position=calculate_position(p),Scope= \"SubCategory\") \n",
    "#     p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>1:\n",
    "    try:\n",
    "        if 3 in filtered_index and 'SKU KPIs Summary By Manufacture' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        SkuKpis(prs,modified_product_dfs,dup_list[p],position = calculate_position(p,use_filtered))\n",
    "        p+=1\n",
    "\n",
    "    try:\n",
    "        if 3 in filtered_index and 'SKU KPIs Summary By Brand' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        SkuKpis(prs,modified_brand_product_dfs,dup_list[p],position = calculate_position(p,use_filtered))\n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixMatrix(prs,secretailerTotal,position = 0)\n",
    "pos = calculate_position(p)\n",
    "if retailerDuplication!=0:\n",
    "    try:\n",
    "        if 4 in filtered_index and 'Mix Matrix By Retailer' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        for key,val in retailerDic.items():\n",
    "            if val:\n",
    "                pos = calculate_position(p,use_filtered)\n",
    "                mixMatrix(prs,val,position = pos)\n",
    "                pos +=len(retailerDic[key].keys())\n",
    "\n",
    "        p+=1        \n",
    "if channelDuplication!=0:\n",
    "    try:\n",
    "        if 4 in filtered_index and 'Mix Matrix By Channel' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        for key,val in channelDic.items():\n",
    "            if val:\n",
    "                pos = calculate_position(p,use_filtered)\n",
    "                mixMatrix(prs,val,position = pos)\n",
    "                pos +=len(channelDic[key].keys())\n",
    "        p+=1       \n",
    "if custDuplication!=0:\n",
    "    try:\n",
    "        if 4 in filtered_index and 'Mix Matrix By Custom Region' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        for key,val in custDic.items():\n",
    "            if val:\n",
    "                pos = calculate_position(p,use_filtered)\n",
    "                mixMatrix(prs,val,position = pos)\n",
    "                pos +=len(custDic[key].keys())\n",
    "        p+=1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    try:\n",
    "        if 5 in filtered_index and 'Mix Matrix by Brands by Sector' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        mixMatrix(prs,secfinaldic,position = calculate_position(p,use_filtered),slideby=\"bybrand\")\n",
    "        p+=1\n",
    "if len(segments)!=0:\n",
    "    try:\n",
    "        if 5 in filtered_index and 'Mix Matrix by Brands by Segment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        mixMatrix(prs,segfinaldic,position = calculate_position(p,use_filtered),slideby=\"bybrand\")\n",
    "        p+=1\n",
    "if len(subsegments)!=0:\n",
    "    try:\n",
    "        if 5 in filtered_index and 'Mix Matrix by Brands by Subsegment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        mixMatrix(prs,subsegfinaldic,position = calculate_position(p,use_filtered),slideby=\"bybrand\")\n",
    "        p+=1\n",
    "if len(subcategories)!=0:\n",
    "    try:\n",
    "        if 5 in filtered_index and 'Mix Matrix by Brands by Subcategory' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        mixMatrix(prs,subcatfinaldic,position = calculate_position(p,use_filtered),slideby=\"bybrand\")\n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sectors)!=0:\n",
    "    try:\n",
    "        if 6 in filtered_index and 'Sector Spending Pool' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        sectorSpendingPool(prs, modified_sector_P12M,dup_list[p], position =calculate_position(p,use_filtered),Scope= \"Sector\")\n",
    "        p+=1\n",
    "\n",
    "if len(segments)!=0:\n",
    "    try:\n",
    "        if 6 in filtered_index and 'Segment Spending Pool' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        sectorSpendingPool(prs, modified_segment_P12M,dup_list[p], position =calculate_position(p,use_filtered),Scope=\"Segment\")\n",
    "        p+=1\n",
    "\n",
    "if len(subsegments)!=0:\n",
    "    try:\n",
    "        if 6 in filtered_index and 'Subsegment Spending Pool' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        sectorSpendingPool(prs, modified_subsegment_P12M,dup_list[p], position =calculate_position(p,use_filtered),Scope=\"SubSegment\")\n",
    "        p+=1\n",
    "\n",
    "if len(subcategories)!=0:\n",
    "    try:\n",
    "        if 6 in filtered_index and 'Subcategory Spending Pool' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        sectorSpendingPool(prs, modified_subcategory_P12M,dup_list[p], position =calculate_position(p,use_filtered),Scope= \"SubCategory\")    \n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>1:\n",
    "    combinedmanufbranddfpool=modified_products_p12m\n",
    "    combinedmanufbranddfpool.update(modified_products_p12m_brand)\n",
    "    try:\n",
    "        if 7 in filtered_index: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        productSpendingPool(prs,combinedmanufbranddfpool, dup_list[p], position= calculate_position(p,use_filtered))\n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(client_brands)>1:\n",
    "    combinedmanufbranddf=modified_product_P12M_dfs\n",
    "    combinedmanufbranddf.update(modified_brand_product_P12M_dfs)\n",
    "    try:\n",
    "        if 8 in filtered_index: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        SKUProfitability(prs,combinedmanufbranddf,dup_list[p],position = calculate_position(p,use_filtered))\n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 4\n"
     ]
    }
   ],
   "source": [
    "if len(sectors)!=0:\n",
    "    try:\n",
    "        if 9 in filtered_index and 'Trade Margin Table By Sector' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMarginTable(prs,client_manuf_sector_dfs_new,top_competitor_manuf_sector_dfs_new,dup_list[p],position = calculate_position(p,use_filtered),Inscope=\"Sector\")\n",
    "        p+=1\n",
    "if len(segments)!=0: \n",
    "    try:\n",
    "        if 9 in filtered_index and 'Trade Margin Table By Segment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide: \n",
    "        print(p,calculate_position(p), dup_list[p])\n",
    "        TradeMarginTable(prs,client_manuf_segment_dfs_new,top_competitor_manuf_segment_dfs_new,dup_list[p],position = calculate_position(p,use_filtered),Inscope=\"Segment\")\n",
    "        p+=1\n",
    "if len(subsegments)!=0: \n",
    "    try:\n",
    "        if 9 in filtered_index and 'Trade Margin Table By Subsegment' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide: \n",
    "        TradeMarginTable(prs,client_manuf_subsegment_dfs_new,top_competitor_manuf_subsegment_dfs_new,dup_list[p],position = calculate_position(p,use_filtered),Inscope=\"SubSegment\")\n",
    "        p+=1   \n",
    "if len(subcategories)!=0:\n",
    "    try:\n",
    "        if 9 in filtered_index and 'Trade Margin Table By Subcategory' in filtered_section_names: \n",
    "            dup_list = filtered_duplication\n",
    "            run_slide = True\n",
    "            use_filtered = True\n",
    "        else:\n",
    "            run_slide = False\n",
    "    except NameError:\n",
    "        dup_list = duplication\n",
    "        run_slide = True \n",
    "    if run_slide:\n",
    "        TradeMarginTable(prs,client_manuf_subcategory_dfs_new,top_competitor_manuf_subcategory_dfs_new,dup_list[p],position = calculate_position(p,use_filtered),Inscope=\"SubCategory\")\n",
    "        p+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath=os.getcwd() +f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\"\n",
    "prs.save(outputPath)\n",
    "# app = win32.Dispatch(\"PowerPoint.Application\")/\n",
    "# presentation = app.Presentations.Open(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=os.getcwd() +f\"\\\\Financials_Output_{datetime.today().strftime(\"%d-%m\")}.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pptx_path = outputPath  # Replace with the actual path to your PPTX file\n",
    "output_pptx_path=final\n",
    "# open_chart_data_in_excel(pptx_path,output_pptx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
